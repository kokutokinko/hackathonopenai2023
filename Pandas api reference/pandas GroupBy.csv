ライブラリ名,章,節,内容
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.__iter__,"pandas.core.groupby.DataFrameGroupBy.__iter__#DataFrameGroupBy.__iter__()[source]#Groupby iterator.Returns:Generator yielding sequence of (name, subsetted object)for each groupExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,3],index=lst)>>>sera    1a    2b    3dtype: int64>>>forx,yinser.groupby(level=0):...print(f'{x}\n{y}\n')aa    1a    2dtype: int64bb    3dtype: int64For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""])>>>dfa  b  c0  1  2  31  1  5  62  7  8  9>>>forx,yindf.groupby(by=[""a""]):...print(f'{x}\n{y}\n')(1,)a  b  c0  1  2  31  1  5  6(7,)a  b  c2  7  8  9For Resampler:>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>forx,yinser.resample('MS'):...print(f'{x}\n{y}\n')2023-01-01 00:00:002023-01-01    12023-01-15    2dtype: int642023-02-01 00:00:002023-02-01    32023-02-15    4dtype: int64"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.__iter__,"pandas.core.groupby.SeriesGroupBy.__iter__#SeriesGroupBy.__iter__()[source]#Groupby iterator.Returns:Generator yielding sequence of (name, subsetted object)for each groupExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,3],index=lst)>>>sera    1a    2b    3dtype: int64>>>forx,yinser.groupby(level=0):...print(f'{x}\n{y}\n')aa    1a    2dtype: int64bb    3dtype: int64For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""])>>>dfa  b  c0  1  2  31  1  5  62  7  8  9>>>forx,yindf.groupby(by=[""a""]):...print(f'{x}\n{y}\n')(1,)a  b  c0  1  2  31  1  5  6(7,)a  b  c2  7  8  9For Resampler:>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>forx,yinser.resample('MS'):...print(f'{x}\n{y}\n')2023-01-01 00:00:002023-01-01    12023-01-15    2dtype: int642023-02-01 00:00:002023-02-01    32023-02-15    4dtype: int64"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.groups,"pandas.core.groupby.DataFrameGroupBy.groups#propertyDataFrameGroupBy.groups[source]#Dict {group name -> group labels}.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,3],index=lst)>>>sera    1a    2b    3dtype: int64>>>ser.groupby(level=0).groups{'a': ['a', 'a'], 'b': ['b']}For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""])>>>dfa  b  c0  1  2  31  1  5  62  7  8  9>>>df.groupby(by=[""a""]).groups{1: [0, 1], 7: [2]}For Resampler:>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').groups{Timestamp('2023-01-01 00:00:00'): 2, Timestamp('2023-02-01 00:00:00'): 4}"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.groups,"pandas.core.groupby.SeriesGroupBy.groups#propertySeriesGroupBy.groups[source]#Dict {group name -> group labels}.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,3],index=lst)>>>sera    1a    2b    3dtype: int64>>>ser.groupby(level=0).groups{'a': ['a', 'a'], 'b': ['b']}For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""])>>>dfa  b  c0  1  2  31  1  5  62  7  8  9>>>df.groupby(by=[""a""]).groups{1: [0, 1], 7: [2]}For Resampler:>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').groups{Timestamp('2023-01-01 00:00:00'): 2, Timestamp('2023-02-01 00:00:00'): 4}"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.indices,"pandas.core.groupby.DataFrameGroupBy.indices#propertyDataFrameGroupBy.indices[source]#Dict {group name -> group indices}.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,3],index=lst)>>>sera    1a    2b    3dtype: int64>>>ser.groupby(level=0).indices{'a': array([0, 1]), 'b': array([2])}For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""owl"",""toucan"",""eagle""])>>>dfa  b  cowl     1  2  3toucan  1  5  6eagle   7  8  9>>>df.groupby(by=[""a""]).indices{1: array([0, 1]), 7: array([2])}For Resampler:>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').indicesdefaultdict(<class 'list'>, {Timestamp('2023-01-01 00:00:00'): [0, 1],Timestamp('2023-02-01 00:00:00'): [2, 3]})"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.indices,"pandas.core.groupby.SeriesGroupBy.indices#propertySeriesGroupBy.indices[source]#Dict {group name -> group indices}.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,3],index=lst)>>>sera    1a    2b    3dtype: int64>>>ser.groupby(level=0).indices{'a': array([0, 1]), 'b': array([2])}For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""owl"",""toucan"",""eagle""])>>>dfa  b  cowl     1  2  3toucan  1  5  6eagle   7  8  9>>>df.groupby(by=[""a""]).indices{1: array([0, 1]), 7: array([2])}For Resampler:>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').indicesdefaultdict(<class 'list'>, {Timestamp('2023-01-01 00:00:00'): [0, 1],Timestamp('2023-02-01 00:00:00'): [2, 3]})"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.get_group,"pandas.core.groupby.DataFrameGroupBy.get_group#DataFrameGroupBy.get_group(name,obj=None)[source]#Construct DataFrame from group with provided name.Parameters:nameobjectThe name of the group to get as a DataFrame.objDataFrame, default NoneThe DataFrame to take the DataFrame out of. If
it is None, the object groupby was called on will
be used.Deprecated since version 2.1.0:The obj is deprecated and will be removed in a future version.
Dodf.iloc[gb.indices.get(name)]instead ofgb.get_group(name,obj=df).Returns:same type as objExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,3],index=lst)>>>sera    1a    2b    3dtype: int64>>>ser.groupby(level=0).get_group(""a"")a    1a    2dtype: int64For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""owl"",""toucan"",""eagle""])>>>dfa  b  cowl     1  2  3toucan  1  5  6eagle   7  8  9>>>df.groupby(by=[""a""]).get_group(1)a  b  cowl     1  2  3toucan  1  5  6For Resampler:>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').get_group('2023-01-01')2023-01-01    12023-01-15    2dtype: int64"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.get_group,"pandas.core.groupby.SeriesGroupBy.get_group#SeriesGroupBy.get_group(name,obj=None)[source]#Construct DataFrame from group with provided name.Parameters:nameobjectThe name of the group to get as a DataFrame.objDataFrame, default NoneThe DataFrame to take the DataFrame out of. If
it is None, the object groupby was called on will
be used.Deprecated since version 2.1.0:The obj is deprecated and will be removed in a future version.
Dodf.iloc[gb.indices.get(name)]instead ofgb.get_group(name,obj=df).Returns:same type as objExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,3],index=lst)>>>sera    1a    2b    3dtype: int64>>>ser.groupby(level=0).get_group(""a"")a    1a    2dtype: int64For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""owl"",""toucan"",""eagle""])>>>dfa  b  cowl     1  2  3toucan  1  5  6eagle   7  8  9>>>df.groupby(by=[""a""]).get_group(1)a  b  cowl     1  2  3toucan  1  5  6For Resampler:>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').get_group('2023-01-01')2023-01-01    12023-01-15    2dtype: int64"
Pandas,GroupBy,pandas.Grouper,"pandas.Grouper#classpandas.Grouper(*args,**kwargs)[source]#A Grouper allows the user to specify a groupby instruction for an object.This specification will select a column via the key parameter, or if the
level and/or axis parameters are given, a level of the index of the target
object.Ifaxisand/orlevelare passed as keywords to bothGrouperandgroupby, the values passed toGroupertake precedence.Parameters:keystr, defaults to NoneGroupby key, which selects the grouping column of the target.levelname/number, defaults to NoneThe level for the target index.freqstr / frequency object, defaults to NoneThis will groupby the specified frequency if the target selection
(via key or level) is a datetime-like object. For full specification
of available frequencies, please seehere.axisstr, int, defaults to 0Number/name of the axis.sortbool, default to FalseWhether to sort the resulting labels.closed{‘left’ or ‘right’}Closed end of interval. Only whenfreqparameter is passed.label{‘left’ or ‘right’}Interval boundary to use for labeling.
Only whenfreqparameter is passed.convention{‘start’, ‘end’, ‘e’, ‘s’}If grouper is PeriodIndex andfreqparameter is passed.originTimestamp or str, default ‘start_day’The timestamp on which to adjust the grouping. The timezone of origin must
match the timezone of the index.
If string, must be one of the following:‘epoch’:originis 1970-01-01‘start’:originis the first value of the timeseries‘start_day’:originis the first day at midnight of the timeseries‘end’:originis the last value of the timeseries‘end_day’:originis the ceiling midnight of the last dayNew in version 1.3.0.offsetTimedelta or str, default is NoneAn offset timedelta added to the origin.dropnabool, default TrueIf True, and if group keys contain NA values, NA values together with
row/column will be dropped. If False, NA values will also be treated as
the key in groups.New in version 1.2.0.Returns:Grouper or pandas.api.typing.TimeGrouperA TimeGrouper is returned iffreqis notNone. Otherwise, a Grouper
is returned.Examplesdf.groupby(pd.Grouper(key=""Animal""))is equivalent todf.groupby('Animal')>>>df=pd.DataFrame(...{...""Animal"":[""Falcon"",""Parrot"",""Falcon"",""Falcon"",""Parrot""],...""Speed"":[100,5,200,300,15],...}...)>>>dfAnimal  Speed0  Falcon    1001  Parrot      52  Falcon    2003  Falcon    3004  Parrot     15>>>df.groupby(pd.Grouper(key=""Animal"")).mean()SpeedAnimalFalcon  200.0Parrot   10.0Specify a resample operation on the column ‘Publish date’>>>df=pd.DataFrame(...{...""Publish date"":[...pd.Timestamp(""2000-01-02""),...pd.Timestamp(""2000-01-02""),...pd.Timestamp(""2000-01-09""),...pd.Timestamp(""2000-01-16"")...],...""ID"":[0,1,2,3],...""Price"":[10,20,30,40]...}...)>>>dfPublish date  ID  Price0   2000-01-02   0     101   2000-01-02   1     202   2000-01-09   2     303   2000-01-16   3     40>>>df.groupby(pd.Grouper(key=""Publish date"",freq=""1W"")).mean()ID  PricePublish date2000-01-02    0.5   15.02000-01-09    2.0   30.02000-01-16    3.0   40.0If you want to adjust the start of the bins based on a fixed timestamp:>>>start,end='2000-10-01 23:30:00','2000-10-02 00:30:00'>>>rng=pd.date_range(start,end,freq='7min')>>>ts=pd.Series(np.arange(len(rng))*3,index=rng)>>>ts2000-10-01 23:30:00     02000-10-01 23:37:00     32000-10-01 23:44:00     62000-10-01 23:51:00     92000-10-01 23:58:00    122000-10-02 00:05:00    152000-10-02 00:12:00    182000-10-02 00:19:00    212000-10-02 00:26:00    24Freq: 7T, dtype: int64>>>ts.groupby(pd.Grouper(freq='17min')).sum()2000-10-01 23:14:00     02000-10-01 23:31:00     92000-10-01 23:48:00    212000-10-02 00:05:00    542000-10-02 00:22:00    24Freq: 17T, dtype: int64>>>ts.groupby(pd.Grouper(freq='17min',origin='epoch')).sum()2000-10-01 23:18:00     02000-10-01 23:35:00    182000-10-01 23:52:00    272000-10-02 00:09:00    392000-10-02 00:26:00    24Freq: 17T, dtype: int64>>>ts.groupby(pd.Grouper(freq='17min',origin='2000-01-01')).sum()2000-10-01 23:24:00     32000-10-01 23:41:00    152000-10-01 23:58:00    452000-10-02 00:15:00    45Freq: 17T, dtype: int64If you want to adjust the start of the bins with anoffsetTimedelta, the two
following lines are equivalent:>>>ts.groupby(pd.Grouper(freq='17min',origin='start')).sum()2000-10-01 23:30:00     92000-10-01 23:47:00    212000-10-02 00:04:00    542000-10-02 00:21:00    24Freq: 17T, dtype: int64>>>ts.groupby(pd.Grouper(freq='17min',offset='23h30min')).sum()2000-10-01 23:30:00     92000-10-01 23:47:00    212000-10-02 00:04:00    542000-10-02 00:21:00    24Freq: 17T, dtype: int64To replace the use of the deprecatedbaseargument, you can now useoffset,
in this example it is equivalent to havebase=2:>>>ts.groupby(pd.Grouper(freq='17min',offset='2min')).sum()2000-10-01 23:16:00     02000-10-01 23:33:00     92000-10-01 23:50:00    362000-10-02 00:07:00    392000-10-02 00:24:00    24Freq: 17T, dtype: int64Attributesaxgroupergroupsindexerobj"
Pandas,GroupBy,pandas.NamedAgg,"pandas.NamedAgg#classpandas.NamedAgg(column,aggfunc)[source]#Helper for column specific aggregation with control over output column names.Subclass of typing.NamedTuple.Parameters:columnHashableColumn label in the DataFrame to apply aggfunc.aggfuncfunction or strFunction to apply to the provided column. If string, the name of a built-in
pandas function.Examples>>>df=pd.DataFrame({""key"":[1,1,2],""a"":[-1,0,1],1:[10,11,12]})>>>agg_a=pd.NamedAgg(column=""a"",aggfunc=""min"")>>>agg_1=pd.NamedAgg(column=1,aggfunc=lambdax:np.mean(x))>>>df.groupby(""key"").agg(result_a=agg_a,result_1=agg_1)result_a  result_1key1          -1      10.52           1      12.0AttributesaggfuncAlias for field number 1columnAlias for field number 0Methodscount(value, /)Return number of occurrences of value.index(value[, start, stop])Return first index of value."
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.apply,"pandas.core.groupby.SeriesGroupBy.apply#SeriesGroupBy.apply(func,*args,**kwargs)[source]#Apply functionfuncgroup-wise and combine the results together.The function passed toapplymust take a series as its first
argument and return a DataFrame, Series or scalar.applywill
then take care of combining the results back together into a single
dataframe or series.applyis therefore a highly flexible
grouping method.Whileapplyis a very flexible method, its downside is that
using it can be quite a bit slower than using more specific methods
likeaggortransform. Pandas offers a wide range of method that will
be much faster than usingapplyfor their specific purposes, so try to
use them before reaching forapply.Parameters:funccallableA callable that takes a series as its first argument, and
returns a dataframe, a series or a scalar. In addition the
callable may take positional and keyword arguments.args, kwargstuple and dictOptional positional and keyword arguments to pass tofunc.Returns:Series or DataFrameSee alsopipeApply function to the full GroupBy object instead of to each group.aggregateApply aggregate function to the GroupBy object.transformApply function column-by-column to the GroupBy object.Series.applyApply a function to a Series.DataFrame.applyApply a function to each row or column of a DataFrame.NotesChanged in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,
see the examples below.Functions that mutate the passed object can produce unexpected
behavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.Examples>>>s=pd.Series([0,1,2],index='a a b'.split())>>>g1=s.groupby(s.index,group_keys=False)>>>g2=s.groupby(s.index,group_keys=True)Fromsabove we can see thatghas two groups,aandb.
Notice thatg1haveg2have two groups,aandb, and only
differ in theirgroup_keysargument. Callingapplyin various ways,
we can get different grouping results:Example 1: The function passed toapplytakes a Series as
its argument and returns a Series.applycombines the result for
each group together into a new Series.Changed in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc.>>>g1.apply(lambdax:x*2ifx.name=='a'elsex/2)a    0.0a    2.0b    1.0dtype: float64In the above, the groups are not part of the index. We can have them included
by usingg2wheregroup_keys=True:>>>g2.apply(lambdax:x*2ifx.name=='a'elsex/2)a  a    0.0a    2.0b  b    1.0dtype: float64Example 2: The function passed toapplytakes a Series as
its argument and returns a scalar.applycombines the result for
each group together into a Series, including setting the index as
appropriate:>>>g1.apply(lambdax:x.max()-x.min())a    1b    0dtype: int64Thegroup_keysargument has no effect here because the result is not
like-indexed (i.e.a transform) when compared
to the input.>>>g2.apply(lambdax:x.max()-x.min())a    1b    0dtype: int64"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.apply,"pandas.core.groupby.DataFrameGroupBy.apply#DataFrameGroupBy.apply(func,*args,**kwargs)[source]#Apply functionfuncgroup-wise and combine the results together.The function passed toapplymust take a dataframe as its first
argument and return a DataFrame, Series or scalar.applywill
then take care of combining the results back together into a single
dataframe or series.applyis therefore a highly flexible
grouping method.Whileapplyis a very flexible method, its downside is that
using it can be quite a bit slower than using more specific methods
likeaggortransform. Pandas offers a wide range of method that will
be much faster than usingapplyfor their specific purposes, so try to
use them before reaching forapply.Parameters:funccallableA callable that takes a dataframe as its first argument, and
returns a dataframe, a series or a scalar. In addition the
callable may take positional and keyword arguments.args, kwargstuple and dictOptional positional and keyword arguments to pass tofunc.Returns:Series or DataFrameSee alsopipeApply function to the full GroupBy object instead of to each group.aggregateApply aggregate function to the GroupBy object.transformApply function column-by-column to the GroupBy object.Series.applyApply a function to a Series.DataFrame.applyApply a function to each row or column of a DataFrame.NotesChanged in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,
see the examples below.Functions that mutate the passed object can produce unexpected
behavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.Examples>>>df=pd.DataFrame({'A':'a a b'.split(),...'B':[1,2,3],...'C':[4,6,5]})>>>g1=df.groupby('A',group_keys=False)>>>g2=df.groupby('A',group_keys=True)Notice thatg1andg2have two groups,aandb, and only
differ in theirgroup_keysargument. Callingapplyin various ways,
we can get different grouping results:Example 1: below the function passed toapplytakes a DataFrame as
its argument and returns a DataFrame.applycombines the result for
each group together into a new DataFrame:>>>g1[['B','C']].apply(lambdax:x/x.sum())B    C0  0.333333  0.41  0.666667  0.62  1.000000  1.0In the above, the groups are not part of the index. We can have them included
by usingg2wheregroup_keys=True:>>>g2[['B','C']].apply(lambdax:x/x.sum())B    CAa 0  0.333333  0.41  0.666667  0.6b 2  1.000000  1.0Example 2: The function passed toapplytakes a DataFrame as
its argument and returns a Series.applycombines the result for
each group together into a new DataFrame.Changed in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc.>>>g1[['B','C']].apply(lambdax:x.astype(float).max()-x.min())B    CAa  1.0  2.0b  0.0  0.0>>>g2[['B','C']].apply(lambdax:x.astype(float).max()-x.min())B    CAa  1.0  2.0b  0.0  0.0Thegroup_keysargument has no effect here because the result is not
like-indexed (i.e.a transform) when compared
to the input.Example 3: The function passed toapplytakes a DataFrame as
its argument and returns a scalar.applycombines the result for
each group together into a Series, including setting the index as
appropriate:>>>g1.apply(lambdax:x.C.max()-x.B.min())Aa    5b    2dtype: int64"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.agg,"pandas.core.groupby.SeriesGroupBy.agg#SeriesGroupBy.agg(func=None,*args,engine=None,engine_kwargs=None,**kwargs)[source]#Aggregate using one or more operations over the specified axis.Parameters:funcfunction, str, list, dict or NoneFunction to use for aggregating the data. If a function, must either
work when passed a Series or when passed to Series.apply.Accepted combinations are:functionstring function namelist of functions and/or function names, e.g.[np.sum,'mean']None, in which case**kwargsare used with Named Aggregation. Here the
output has one column for each element in**kwargs. The name of the
column is keyword, whereas the value determines the aggregation used to compute
the values in the column.Can also accept a Numba JIT function withengine='numba'specified. Only passing a single function is supported
with this engine.If the'numba'engine is chosen, the function must be
a user defined function withvaluesandindexas the
first and second arguments respectively in the function signature.
Each group’s index will be passed to the user defined function
and optionally available for use.Deprecated since version 2.1.0:Passing a dictionary is deprecated and will raise in a future version
of pandas. Pass a list of aggregations instead.*argsPositional arguments to pass to func.enginestr, default None'cython': Runs the function through C-extensions from cython.'numba': Runs the function through JIT compiled code from numba.None: Defaults to'cython'or globally settingcompute.use_numbaengine_kwargsdict, default NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{'nopython':True,'nogil':False,'parallel':False}and will be
applied to the function**kwargsIffuncis None,**kwargsare used to define the output names and
aggregations via Named Aggregation. Seefuncentry.Otherwise, keyword arguments to be passed into func.Returns:SeriesSee alsoSeries.groupby.applyApply function func group-wise and combine the results together.Series.groupby.transformTransforms the Series on each group based on the given function.Series.aggregateAggregate using one or more operations over the specified axis.NotesWhen usingengine='numba', there will be no “fall back” behavior internally.
The group data and group index will be passed as numpy arrays to the JITed
user defined function, and no alternative execution attempts will be tried.Functions that mutate the passed object can produce unexpected
behavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.Changed in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,
see the examples below.Examples>>>s=pd.Series([1,2,3,4])>>>s0    11    22    33    4dtype: int64>>>s.groupby([1,1,2,2]).min()1    12    3dtype: int64>>>s.groupby([1,1,2,2]).agg('min')1    12    3dtype: int64>>>s.groupby([1,1,2,2]).agg(['min','max'])min  max1    1    22    3    4The output column names can be controlled by passing
the desired column names and aggregations as keyword arguments.>>>s.groupby([1,1,2,2]).agg(...minimum='min',...maximum='max',...)minimum  maximum1        1        22        3        4Changed in version 1.3.0:The resulting dtype will reflect the return value of the aggregating function.>>>s.groupby([1,1,2,2]).agg(lambdax:x.astype(float).min())1    1.02    3.0dtype: float64"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.agg,"pandas.core.groupby.DataFrameGroupBy.agg#DataFrameGroupBy.agg(func=None,*args,engine=None,engine_kwargs=None,**kwargs)[source]#Aggregate using one or more operations over the specified axis.Parameters:funcfunction, str, list, dict or NoneFunction to use for aggregating the data. If a function, must either
work when passed a DataFrame or when passed to DataFrame.apply.Accepted combinations are:functionstring function namelist of functions and/or function names, e.g.[np.sum,'mean']dict of axis labels -> functions, function names or list of such.None, in which case**kwargsare used with Named Aggregation. Here the
output has one column for each element in**kwargs. The name of the
column is keyword, whereas the value determines the aggregation used to compute
the values in the column.Can also accept a Numba JIT function withengine='numba'specified. Only passing a single function is supported
with this engine.If the'numba'engine is chosen, the function must be
a user defined function withvaluesandindexas the
first and second arguments respectively in the function signature.
Each group’s index will be passed to the user defined function
and optionally available for use.*argsPositional arguments to pass to func.enginestr, default None'cython': Runs the function through C-extensions from cython.'numba': Runs the function through JIT compiled code from numba.None: Defaults to'cython'or globally settingcompute.use_numbaengine_kwargsdict, default NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{'nopython':True,'nogil':False,'parallel':False}and will be
applied to the function**kwargsIffuncis None,**kwargsare used to define the output names and
aggregations via Named Aggregation. Seefuncentry.Otherwise, keyword arguments to be passed into func.Returns:DataFrameSee alsoDataFrame.groupby.applyApply function func group-wise and combine the results together.DataFrame.groupby.transformTransforms the Series on each group based on the given function.DataFrame.aggregateAggregate using one or more operations over the specified axis.NotesWhen usingengine='numba', there will be no “fall back” behavior internally.
The group data and group index will be passed as numpy arrays to the JITed
user defined function, and no alternative execution attempts will be tried.Functions that mutate the passed object can produce unexpected
behavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.Changed in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,
see the examples below.Examples>>>df=pd.DataFrame(...{...""A"":[1,1,2,2],...""B"":[1,2,3,4],...""C"":[0.362838,0.227877,1.267767,-0.562860],...}...)>>>dfA  B         C0  1  1  0.3628381  1  2  0.2278772  2  3  1.2677673  2  4 -0.562860The aggregation is for each column.>>>df.groupby('A').agg('min')B         CA1  1  0.2278772  3 -0.562860Multiple aggregations>>>df.groupby('A').agg(['min','max'])B             Cmin max       min       maxA1   1   2  0.227877  0.3628382   3   4 -0.562860  1.267767Select a column for aggregation>>>df.groupby('A').B.agg(['min','max'])min  maxA1    1    22    3    4User-defined function for aggregation>>>df.groupby('A').agg(lambdax:sum(x)+2)B          CA1       5       2.5907152       9       2.704907Different aggregations per column>>>df.groupby('A').agg({'B':['min','max'],'C':'sum'})B             Cmin max       sumA1   1   2  0.5907152   3   4  0.704907To control the output names with different aggregations per column,
pandas supports “named aggregation”>>>df.groupby(""A"").agg(...b_min=pd.NamedAgg(column=""B"",aggfunc=""min""),...c_sum=pd.NamedAgg(column=""C"",aggfunc=""sum""))b_min     c_sumA1      1  0.5907152      3  0.704907The keywords are theoutputcolumn namesThe values are tuples whose first element is the column to select
and the second element is the aggregation to apply to that column.
Pandas provides thepandas.NamedAggnamedtuple with the fields['column','aggfunc']to make it clearer what the arguments are.
As usual, the aggregation can be a callable or a string alias.SeeNamed aggregationfor more.Changed in version 1.3.0:The resulting dtype will reflect the return value of the aggregating function.>>>df.groupby(""A"")[[""B""]].agg(lambdax:x.astype(float).min())BA1   1.02   3.0"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.aggregate,"pandas.core.groupby.SeriesGroupBy.aggregate#SeriesGroupBy.aggregate(func=None,*args,engine=None,engine_kwargs=None,**kwargs)[source]#Aggregate using one or more operations over the specified axis.Parameters:funcfunction, str, list, dict or NoneFunction to use for aggregating the data. If a function, must either
work when passed a Series or when passed to Series.apply.Accepted combinations are:functionstring function namelist of functions and/or function names, e.g.[np.sum,'mean']None, in which case**kwargsare used with Named Aggregation. Here the
output has one column for each element in**kwargs. The name of the
column is keyword, whereas the value determines the aggregation used to compute
the values in the column.Can also accept a Numba JIT function withengine='numba'specified. Only passing a single function is supported
with this engine.If the'numba'engine is chosen, the function must be
a user defined function withvaluesandindexas the
first and second arguments respectively in the function signature.
Each group’s index will be passed to the user defined function
and optionally available for use.Deprecated since version 2.1.0:Passing a dictionary is deprecated and will raise in a future version
of pandas. Pass a list of aggregations instead.*argsPositional arguments to pass to func.enginestr, default None'cython': Runs the function through C-extensions from cython.'numba': Runs the function through JIT compiled code from numba.None: Defaults to'cython'or globally settingcompute.use_numbaengine_kwargsdict, default NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{'nopython':True,'nogil':False,'parallel':False}and will be
applied to the function**kwargsIffuncis None,**kwargsare used to define the output names and
aggregations via Named Aggregation. Seefuncentry.Otherwise, keyword arguments to be passed into func.Returns:SeriesSee alsoSeries.groupby.applyApply function func group-wise and combine the results together.Series.groupby.transformTransforms the Series on each group based on the given function.Series.aggregateAggregate using one or more operations over the specified axis.NotesWhen usingengine='numba', there will be no “fall back” behavior internally.
The group data and group index will be passed as numpy arrays to the JITed
user defined function, and no alternative execution attempts will be tried.Functions that mutate the passed object can produce unexpected
behavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.Changed in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,
see the examples below.Examples>>>s=pd.Series([1,2,3,4])>>>s0    11    22    33    4dtype: int64>>>s.groupby([1,1,2,2]).min()1    12    3dtype: int64>>>s.groupby([1,1,2,2]).agg('min')1    12    3dtype: int64>>>s.groupby([1,1,2,2]).agg(['min','max'])min  max1    1    22    3    4The output column names can be controlled by passing
the desired column names and aggregations as keyword arguments.>>>s.groupby([1,1,2,2]).agg(...minimum='min',...maximum='max',...)minimum  maximum1        1        22        3        4Changed in version 1.3.0:The resulting dtype will reflect the return value of the aggregating function.>>>s.groupby([1,1,2,2]).agg(lambdax:x.astype(float).min())1    1.02    3.0dtype: float64"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.aggregate,"pandas.core.groupby.DataFrameGroupBy.aggregate#DataFrameGroupBy.aggregate(func=None,*args,engine=None,engine_kwargs=None,**kwargs)[source]#Aggregate using one or more operations over the specified axis.Parameters:funcfunction, str, list, dict or NoneFunction to use for aggregating the data. If a function, must either
work when passed a DataFrame or when passed to DataFrame.apply.Accepted combinations are:functionstring function namelist of functions and/or function names, e.g.[np.sum,'mean']dict of axis labels -> functions, function names or list of such.None, in which case**kwargsare used with Named Aggregation. Here the
output has one column for each element in**kwargs. The name of the
column is keyword, whereas the value determines the aggregation used to compute
the values in the column.Can also accept a Numba JIT function withengine='numba'specified. Only passing a single function is supported
with this engine.If the'numba'engine is chosen, the function must be
a user defined function withvaluesandindexas the
first and second arguments respectively in the function signature.
Each group’s index will be passed to the user defined function
and optionally available for use.*argsPositional arguments to pass to func.enginestr, default None'cython': Runs the function through C-extensions from cython.'numba': Runs the function through JIT compiled code from numba.None: Defaults to'cython'or globally settingcompute.use_numbaengine_kwargsdict, default NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{'nopython':True,'nogil':False,'parallel':False}and will be
applied to the function**kwargsIffuncis None,**kwargsare used to define the output names and
aggregations via Named Aggregation. Seefuncentry.Otherwise, keyword arguments to be passed into func.Returns:DataFrameSee alsoDataFrame.groupby.applyApply function func group-wise and combine the results together.DataFrame.groupby.transformTransforms the Series on each group based on the given function.DataFrame.aggregateAggregate using one or more operations over the specified axis.NotesWhen usingengine='numba', there will be no “fall back” behavior internally.
The group data and group index will be passed as numpy arrays to the JITed
user defined function, and no alternative execution attempts will be tried.Functions that mutate the passed object can produce unexpected
behavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.Changed in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,
see the examples below.Examples>>>df=pd.DataFrame(...{...""A"":[1,1,2,2],...""B"":[1,2,3,4],...""C"":[0.362838,0.227877,1.267767,-0.562860],...}...)>>>dfA  B         C0  1  1  0.3628381  1  2  0.2278772  2  3  1.2677673  2  4 -0.562860The aggregation is for each column.>>>df.groupby('A').agg('min')B         CA1  1  0.2278772  3 -0.562860Multiple aggregations>>>df.groupby('A').agg(['min','max'])B             Cmin max       min       maxA1   1   2  0.227877  0.3628382   3   4 -0.562860  1.267767Select a column for aggregation>>>df.groupby('A').B.agg(['min','max'])min  maxA1    1    22    3    4User-defined function for aggregation>>>df.groupby('A').agg(lambdax:sum(x)+2)B          CA1       5       2.5907152       9       2.704907Different aggregations per column>>>df.groupby('A').agg({'B':['min','max'],'C':'sum'})B             Cmin max       sumA1   1   2  0.5907152   3   4  0.704907To control the output names with different aggregations per column,
pandas supports “named aggregation”>>>df.groupby(""A"").agg(...b_min=pd.NamedAgg(column=""B"",aggfunc=""min""),...c_sum=pd.NamedAgg(column=""C"",aggfunc=""sum""))b_min     c_sumA1      1  0.5907152      3  0.704907The keywords are theoutputcolumn namesThe values are tuples whose first element is the column to select
and the second element is the aggregation to apply to that column.
Pandas provides thepandas.NamedAggnamedtuple with the fields['column','aggfunc']to make it clearer what the arguments are.
As usual, the aggregation can be a callable or a string alias.SeeNamed aggregationfor more.Changed in version 1.3.0:The resulting dtype will reflect the return value of the aggregating function.>>>df.groupby(""A"")[[""B""]].agg(lambdax:x.astype(float).min())BA1   1.02   3.0"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.transform,"pandas.core.groupby.SeriesGroupBy.transform#SeriesGroupBy.transform(func,*args,engine=None,engine_kwargs=None,**kwargs)[source]#Call function producing a same-indexed Series on each group.Returns a Series having the same indexes as the original object
filled with the transformed values.Parameters:ffunction, strFunction to apply to each group. See the Notes section below for requirements.Accepted inputs are:StringPython functionNumba JIT function withengine='numba'specified.Only passing a single function is supported with this engine.
If the'numba'engine is chosen, the function must be
a user defined function withvaluesandindexas the
first and second arguments respectively in the function signature.
Each group’s index will be passed to the user defined function
and optionally available for use.If a string is chosen, then it needs to be the name
of the groupby method you want to use.*argsPositional arguments to pass to func.enginestr, default None'cython': Runs the function through C-extensions from cython.'numba': Runs the function through JIT compiled code from numba.None: Defaults to'cython'or the global settingcompute.use_numbaengine_kwargsdict, default NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{'nopython':True,'nogil':False,'parallel':False}and will be
applied to the function**kwargsKeyword arguments to be passed into func.Returns:SeriesSee alsoSeries.groupby.applyApply functionfuncgroup-wise and combine the results together.Series.groupby.aggregateAggregate using one or more operations over the specified axis.Series.transformCallfuncon self producing a Series with the same axis shape as self.NotesEach group is endowed the attribute ‘name’ in case you need to know
which group you are working on.The current implementation imposes three requirements on f:f must return a value that either has the same shape as the input
subframe or can be broadcast to the shape of the input subframe.
For example, iffreturns a scalar it will be broadcast to have the
same shape as the input subframe.if this is a DataFrame, f must support application column-by-column
in the subframe. If f also supports application to the entire subframe,
then a fast path is used starting from the second chunk.f must not mutate groups. Mutation is not supported and may
produce unexpected results. SeeMutating with User Defined Function (UDF) methodsfor more details.When usingengine='numba', there will be no “fall back” behavior internally.
The group data and group index will be passed as numpy arrays to the JITed
user defined function, and no alternative execution attempts will be tried.Changed in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,
see the examples below.Changed in version 2.0.0:When using.transformon a grouped DataFrame and the transformation function
returns a DataFrame, pandas now aligns the result’s index
with the input’s index. You can call.to_numpy()on the
result of the transformation function to avoid alignment.Examples>>>ser=pd.Series(...[390.0,350.0,30.0,20.0],...index=[""Falcon"",""Falcon"",""Parrot"",""Parrot""],...name=""Max Speed"")>>>grouped=ser.groupby([1,1,2,2])>>>grouped.transform(lambdax:(x-x.mean())/x.std())Falcon    0.707107Falcon   -0.707107Parrot    0.707107Parrot   -0.707107Name: Max Speed, dtype: float64Broadcast result of the transformation>>>grouped.transform(lambdax:x.max()-x.min())Falcon    40.0Falcon    40.0Parrot    10.0Parrot    10.0Name: Max Speed, dtype: float64>>>grouped.transform(""mean"")Falcon    370.0Falcon    370.0Parrot     25.0Parrot     25.0Name: Max Speed, dtype: float64Changed in version 1.3.0.The resulting dtype will reflect the return value of the passedfunc,
for example:>>>grouped.transform(lambdax:x.astype(int).max())Falcon    390Falcon    390Parrot     30Parrot     30Name: Max Speed, dtype: int64"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.transform,"pandas.core.groupby.DataFrameGroupBy.transform#DataFrameGroupBy.transform(func,*args,engine=None,engine_kwargs=None,**kwargs)[source]#Call function producing a same-indexed DataFrame on each group.Returns a DataFrame having the same indexes as the original object
filled with the transformed values.Parameters:ffunction, strFunction to apply to each group. See the Notes section below for requirements.Accepted inputs are:StringPython functionNumba JIT function withengine='numba'specified.Only passing a single function is supported with this engine.
If the'numba'engine is chosen, the function must be
a user defined function withvaluesandindexas the
first and second arguments respectively in the function signature.
Each group’s index will be passed to the user defined function
and optionally available for use.If a string is chosen, then it needs to be the name
of the groupby method you want to use.*argsPositional arguments to pass to func.enginestr, default None'cython': Runs the function through C-extensions from cython.'numba': Runs the function through JIT compiled code from numba.None: Defaults to'cython'or the global settingcompute.use_numbaengine_kwargsdict, default NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{'nopython':True,'nogil':False,'parallel':False}and will be
applied to the function**kwargsKeyword arguments to be passed into func.Returns:DataFrameSee alsoDataFrame.groupby.applyApply functionfuncgroup-wise and combine the results together.DataFrame.groupby.aggregateAggregate using one or more operations over the specified axis.DataFrame.transformCallfuncon self producing a DataFrame with the same axis shape as self.NotesEach group is endowed the attribute ‘name’ in case you need to know
which group you are working on.The current implementation imposes three requirements on f:f must return a value that either has the same shape as the input
subframe or can be broadcast to the shape of the input subframe.
For example, iffreturns a scalar it will be broadcast to have the
same shape as the input subframe.if this is a DataFrame, f must support application column-by-column
in the subframe. If f also supports application to the entire subframe,
then a fast path is used starting from the second chunk.f must not mutate groups. Mutation is not supported and may
produce unexpected results. SeeMutating with User Defined Function (UDF) methodsfor more details.When usingengine='numba', there will be no “fall back” behavior internally.
The group data and group index will be passed as numpy arrays to the JITed
user defined function, and no alternative execution attempts will be tried.Changed in version 1.3.0:The resulting dtype will reflect the return value of the passedfunc,
see the examples below.Changed in version 2.0.0:When using.transformon a grouped DataFrame and the transformation function
returns a DataFrame, pandas now aligns the result’s index
with the input’s index. You can call.to_numpy()on the
result of the transformation function to avoid alignment.Examples>>>df=pd.DataFrame({'A':['foo','bar','foo','bar',...'foo','bar'],...'B':['one','one','two','three',...'two','two'],...'C':[1,5,5,2,5,5],...'D':[2.0,5.,8.,1.,2.,9.]})>>>grouped=df.groupby('A')[['C','D']]>>>grouped.transform(lambdax:(x-x.mean())/x.std())C         D0 -1.154701 -0.5773501  0.577350  0.0000002  0.577350  1.1547013 -1.154701 -1.0000004  0.577350 -0.5773505  0.577350  1.000000Broadcast result of the transformation>>>grouped.transform(lambdax:x.max()-x.min())C    D0  4.0  6.01  3.0  8.02  4.0  6.03  3.0  8.04  4.0  6.05  3.0  8.0>>>grouped.transform(""mean"")C    D0  3.666667  4.01  4.000000  5.02  3.666667  4.03  4.000000  5.04  3.666667  4.05  4.000000  5.0Changed in version 1.3.0.The resulting dtype will reflect the return value of the passedfunc,
for example:>>>grouped.transform(lambdax:x.astype(int).max())C  D0  5  81  5  92  5  83  5  94  5  85  5  9"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.pipe,"pandas.core.groupby.SeriesGroupBy.pipe#SeriesGroupBy.pipe(func,*args,**kwargs)[source]#Apply afuncwith arguments to this GroupBy object and return its result.Use.pipewhen you want to improve readability by chaining together
functions that expect Series, DataFrames, GroupBy or Resampler objects.
Instead of writing>>>h(g(f(df.groupby('group')),arg1=a),arg2=b,arg3=c)You can write>>>(df.groupby('group')....pipe(f)....pipe(g,arg1=a)....pipe(h,arg2=b,arg3=c))which is much more readable.Parameters:funccallable or tuple of (callable, str)Function to apply to this GroupBy object or, alternatively,
a(callable, data_keyword)tuple wheredata_keywordis a
string indicating the keyword ofcallablethat expects the
GroupBy object.argsiterable, optionalPositional arguments passed intofunc.kwargsdict, optionalA dictionary of keyword arguments passed intofunc.Returns:the return type offunc.See alsoSeries.pipeApply a function with arguments to a series.DataFrame.pipeApply a function with arguments to a dataframe.applyApply function to each group instead of to the full GroupBy object.NotesSee morehereExamples>>>df=pd.DataFrame({'A':'a b a b'.split(),'B':[1,2,3,4]})>>>dfA  B0  a  11  b  22  a  33  b  4To get the difference between each groups maximum and minimum value in one
pass, you can do>>>df.groupby('A').pipe(lambdax:x.max()-x.min())BAa  2b  2"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.pipe,"pandas.core.groupby.DataFrameGroupBy.pipe#DataFrameGroupBy.pipe(func,*args,**kwargs)[source]#Apply afuncwith arguments to this GroupBy object and return its result.Use.pipewhen you want to improve readability by chaining together
functions that expect Series, DataFrames, GroupBy or Resampler objects.
Instead of writing>>>h(g(f(df.groupby('group')),arg1=a),arg2=b,arg3=c)You can write>>>(df.groupby('group')....pipe(f)....pipe(g,arg1=a)....pipe(h,arg2=b,arg3=c))which is much more readable.Parameters:funccallable or tuple of (callable, str)Function to apply to this GroupBy object or, alternatively,
a(callable, data_keyword)tuple wheredata_keywordis a
string indicating the keyword ofcallablethat expects the
GroupBy object.argsiterable, optionalPositional arguments passed intofunc.kwargsdict, optionalA dictionary of keyword arguments passed intofunc.Returns:the return type offunc.See alsoSeries.pipeApply a function with arguments to a series.DataFrame.pipeApply a function with arguments to a dataframe.applyApply function to each group instead of to the full GroupBy object.NotesSee morehereExamples>>>df=pd.DataFrame({'A':'a b a b'.split(),'B':[1,2,3,4]})>>>dfA  B0  a  11  b  22  a  33  b  4To get the difference between each groups maximum and minimum value in one
pass, you can do>>>df.groupby('A').pipe(lambdax:x.max()-x.min())BAa  2b  2"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.filter,"pandas.core.groupby.DataFrameGroupBy.filter#DataFrameGroupBy.filter(func,dropna=True,*args,**kwargs)[source]#Filter elements from groups that don’t satisfy a criterion.Elements from groups are filtered if they do not satisfy the
boolean criterion specified by func.Parameters:funcfunctionCriterion to apply to each group. Should return True or False.dropnaboolDrop groups that do not pass the filter. True by default; if False,
groups that evaluate False are filled with NaNs.Returns:DataFrameNotesEach subframe is endowed the attribute ‘name’ in case you need to know
which group you are working on.Functions that mutate the passed object can produce unexpected
behavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.Examples>>>df=pd.DataFrame({'A':['foo','bar','foo','bar',...'foo','bar'],...'B':[1,2,3,4,5,6],...'C':[2.0,5.,8.,1.,2.,9.]})>>>grouped=df.groupby('A')>>>grouped.filter(lambdax:x['B'].mean()>3.)A  B    C1  bar  2  5.03  bar  4  1.05  bar  6  9.0"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.filter,"pandas.core.groupby.SeriesGroupBy.filter#SeriesGroupBy.filter(func,dropna=True,*args,**kwargs)[source]#Filter elements from groups that don’t satisfy a criterion.Elements from groups are filtered if they do not satisfy the
boolean criterion specified by func.Parameters:funcfunctionCriterion to apply to each group. Should return True or False.dropnaboolDrop groups that do not pass the filter. True by default; if False,
groups that evaluate False are filled with NaNs.Returns:SeriesNotesFunctions that mutate the passed object can produce unexpected
behavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.Examples>>>df=pd.DataFrame({'A':['foo','bar','foo','bar',...'foo','bar'],...'B':[1,2,3,4,5,6],...'C':[2.0,5.,8.,1.,2.,9.]})>>>grouped=df.groupby('A')>>>df.groupby('A').B.filter(lambdax:x.mean()>3.)1    23    45    6Name: B, dtype: int64"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.all,"pandas.core.groupby.DataFrameGroupBy.all#DataFrameGroupBy.all(skipna=True)[source]#Return True if all values in the group are truthful, else False.Parameters:skipnabool, default TrueFlag to ignore nan values during truth testing.Returns:Series or DataFrameDataFrame or Series of boolean values, where a value is True if all elements
are True within its respective group, False otherwise.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,0],index=lst)>>>sera    1a    2b    0dtype: int64>>>ser.groupby(level=0).all()a     Trueb    Falsedtype: boolFor DataFrameGroupBy:>>>data=[[1,0,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""ostrich"",""penguin"",""parrot""])>>>dfa  b  costrich  1  0  3penguin  1  5  6parrot   7  8  9>>>df.groupby(by=[""a""]).all()b      ca1  False   True7   True   True"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.any,"pandas.core.groupby.DataFrameGroupBy.any#DataFrameGroupBy.any(skipna=True)[source]#Return True if any value in the group is truthful, else False.Parameters:skipnabool, default TrueFlag to ignore nan values during truth testing.Returns:Series or DataFrameDataFrame or Series of boolean values, where a value is True if any element
is True within its respective group, False otherwise.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,0],index=lst)>>>sera    1a    2b    0dtype: int64>>>ser.groupby(level=0).any()a     Trueb    Falsedtype: boolFor DataFrameGroupBy:>>>data=[[1,0,3],[1,0,6],[7,1,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""ostrich"",""penguin"",""parrot""])>>>dfa  b  costrich  1  0  3penguin  1  0  6parrot   7  1  9>>>df.groupby(by=[""a""]).any()b      ca1  False   True7   True   True"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.bfill,"pandas.core.groupby.DataFrameGroupBy.bfill#DataFrameGroupBy.bfill(limit=None)[source]#Backward fill the values.Parameters:limitint, optionalLimit of how many values to fill.Returns:Series or DataFrameObject with missing values filled.See alsoSeries.bfillBackward fill the missing values in the dataset.DataFrame.bfillBackward fill the missing values in the dataset.Series.fillnaFill NaN values of a Series.DataFrame.fillnaFill NaN values of a DataFrame.ExamplesWith Series:>>>index=['Falcon','Falcon','Parrot','Parrot','Parrot']>>>s=pd.Series([None,1,None,None,3],index=index)>>>sFalcon    NaNFalcon    1.0Parrot    NaNParrot    NaNParrot    3.0dtype: float64>>>s.groupby(level=0).bfill()Falcon    1.0Falcon    1.0Parrot    3.0Parrot    3.0Parrot    3.0dtype: float64>>>s.groupby(level=0).bfill(limit=1)Falcon    1.0Falcon    1.0Parrot    NaNParrot    3.0Parrot    3.0dtype: float64With DataFrame:>>>df=pd.DataFrame({'A':[1,None,None,None,4],...'B':[None,None,5,None,7]},index=index)>>>dfA         BFalcon  1.0       NaNFalcon  NaN       NaNParrot  NaN       5.0Parrot  NaN       NaNParrot  4.0       7.0>>>df.groupby(level=0).bfill()A         BFalcon  1.0       NaNFalcon  NaN       NaNParrot  4.0       5.0Parrot  4.0       7.0Parrot  4.0       7.0>>>df.groupby(level=0).bfill(limit=1)A         BFalcon  1.0       NaNFalcon  NaN       NaNParrot  NaN       5.0Parrot  4.0       7.0Parrot  4.0       7.0"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.corr,"pandas.core.groupby.DataFrameGroupBy.corr#DataFrameGroupBy.corr(method='pearson',min_periods=1,numeric_only=False)[source]#Compute pairwise correlation of columns, excluding NA/null values.Parameters:method{‘pearson’, ‘kendall’, ‘spearman’} or callableMethod of correlation:pearson : standard correlation coefficientkendall : Kendall Tau correlation coefficientspearman : Spearman rank correlationcallable: callable with input two 1d ndarraysand returning a float. Note that the returned matrix from corr
will have 1 along the diagonals and will be symmetric
regardless of the callable’s behavior.min_periodsint, optionalMinimum number of observations required per pair of columns
to have a valid result. Currently only available for Pearson
and Spearman correlation.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:The default value ofnumeric_onlyis nowFalse.Returns:DataFrameCorrelation matrix.See alsoDataFrame.corrwithCompute pairwise correlation with another DataFrame or Series.Series.corrCompute the correlation between two Series.NotesPearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.Pearson correlation coefficientKendall rank correlation coefficientSpearman’s rank correlation coefficientExamples>>>defhistogram_intersection(a,b):...v=np.minimum(a,b).sum().round(decimals=1)...returnv>>>df=pd.DataFrame([(.2,.3),(.0,.6),(.6,.0),(.2,.1)],...columns=['dogs','cats'])>>>df.corr(method=histogram_intersection)dogs  catsdogs   1.0   0.3cats   0.3   1.0>>>df=pd.DataFrame([(1,1),(2,np.nan),(np.nan,3),(4,4)],...columns=['dogs','cats'])>>>df.corr(min_periods=3)dogs  catsdogs   1.0   NaNcats   NaN   1.0"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.corrwith,"pandas.core.groupby.DataFrameGroupBy.corrwith#DataFrameGroupBy.corrwith(other,axis=_NoDefault.no_default,drop=False,method='pearson',numeric_only=False)[source]#Compute pairwise correlation.Pairwise correlation is computed between rows or columns of
DataFrame with rows or columns of Series or DataFrame. DataFrames
are first aligned along both axes before computing the
correlations.Parameters:otherDataFrame, SeriesObject with which to compute correlations.axis{0 or ‘index’, 1 or ‘columns’}, default 0The axis to use. 0 or ‘index’ to compute row-wise, 1 or ‘columns’ for
column-wise.dropbool, default FalseDrop missing indices from result.method{‘pearson’, ‘kendall’, ‘spearman’} or callableMethod of correlation:pearson : standard correlation coefficientkendall : Kendall Tau correlation coefficientspearman : Spearman rank correlationcallable: callable with input two 1d ndarraysand returning a float.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:The default value ofnumeric_onlyis nowFalse.Returns:SeriesPairwise correlations.See alsoDataFrame.corrCompute pairwise correlation of columns.Examples>>>index=[""a"",""b"",""c"",""d"",""e""]>>>columns=[""one"",""two"",""three"",""four""]>>>df1=pd.DataFrame(np.arange(20).reshape(5,4),index=index,columns=columns)>>>df2=pd.DataFrame(np.arange(16).reshape(4,4),index=index[:4],columns=columns)>>>df1.corrwith(df2)one      1.0two      1.0three    1.0four     1.0dtype: float64>>>df2.corrwith(df1,axis=1)a    1.0b    1.0c    1.0d    1.0e    NaNdtype: float64"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.count,"pandas.core.groupby.DataFrameGroupBy.count#DataFrameGroupBy.count()[source]#Compute count of group, excluding missing values.Returns:Series or DataFrameCount of values within each group.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,np.nan],index=lst)>>>sera    1.0a    2.0b    NaNdtype: float64>>>ser.groupby(level=0).count()a    2b    0dtype: int64For DataFrameGroupBy:>>>data=[[1,np.nan,3],[1,np.nan,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""cow"",""horse"",""bull""])>>>dfa         b     ccow     1       NaN     3horse   1       NaN     6bull    7       8.0     9>>>df.groupby(""a"").count()b   ca1   0   27   1   1For Resampler:>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').count()2023-01-01    22023-02-01    2Freq: MS, dtype: int64"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.cov,"pandas.core.groupby.DataFrameGroupBy.cov#DataFrameGroupBy.cov(min_periods=None,ddof=1,numeric_only=False)[source]#Compute pairwise covariance of columns, excluding NA/null values.Compute the pairwise covariance among the series of a DataFrame.
The returned data frame is thecovariance matrixof the columns
of the DataFrame.Both NA and null values are automatically excluded from the
calculation. (See the note below about bias from missing values.)
A threshold can be set for the minimum number of
observations for each value created. Comparisons with observations
below this threshold will be returned asNaN.This method is generally used for the analysis of time series data to
understand the relationship between different measures
across time.Parameters:min_periodsint, optionalMinimum number of observations required per pair of columns
to have a valid result.ddofint, default 1Delta degrees of freedom. The divisor used in calculations
isN-ddof, whereNrepresents the number of elements.
This argument is applicable only when nonanis in the dataframe.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:The default value ofnumeric_onlyis nowFalse.Returns:DataFrameThe covariance matrix of the series of the DataFrame.See alsoSeries.covCompute covariance with another Series.core.window.ewm.ExponentialMovingWindow.covExponential weighted sample covariance.core.window.expanding.Expanding.covExpanding sample covariance.core.window.rolling.Rolling.covRolling sample covariance.NotesReturns the covariance matrix of the DataFrame’s time series.
The covariance is normalized by N-ddof.For DataFrames that have Series that are missing data (assuming that
data ismissing at random)
the returned covariance matrix will be an unbiased estimate
of the variance and covariance between the member Series.However, for many applications this estimate may not be acceptable
because the estimate covariance matrix is not guaranteed to be positive
semi-definite. This could lead to estimate correlations having
absolute values which are greater than one, and/or a non-invertible
covariance matrix. SeeEstimation of covariance matricesfor more details.Examples>>>df=pd.DataFrame([(1,2),(0,3),(2,0),(1,1)],...columns=['dogs','cats'])>>>df.cov()dogs      catsdogs  0.666667 -1.000000cats -1.000000  1.666667>>>np.random.seed(42)>>>df=pd.DataFrame(np.random.randn(1000,5),...columns=['a','b','c','d','e'])>>>df.cov()a         b         c         d         ea  0.998438 -0.020161  0.059277 -0.008943  0.014144b -0.020161  1.059352 -0.008543 -0.024738  0.009826c  0.059277 -0.008543  1.010670 -0.001486 -0.000271d -0.008943 -0.024738 -0.001486  0.921297 -0.013692e  0.014144  0.009826 -0.000271 -0.013692  0.977795Minimum number of periodsThis method also supports an optionalmin_periodskeyword
that specifies the required minimum number of non-NA observations for
each column pair in order to have a valid result:>>>np.random.seed(42)>>>df=pd.DataFrame(np.random.randn(20,3),...columns=['a','b','c'])>>>df.loc[df.index[:5],'a']=np.nan>>>df.loc[df.index[5:10],'b']=np.nan>>>df.cov(min_periods=12)a         b         ca  0.316741       NaN -0.150812b       NaN  1.248003  0.191417c -0.150812  0.191417  0.895202"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.cumcount,"pandas.core.groupby.DataFrameGroupBy.cumcount#DataFrameGroupBy.cumcount(ascending=True)[source]#Number each item in each group from 0 to the length of that group - 1.Essentially this is equivalent toself.apply(lambdax:pd.Series(np.arange(len(x)),x.index))Parameters:ascendingbool, default TrueIf False, number in reverse, from length of group - 1 to 0.Returns:SeriesSequence number of each element within each group.See alsongroupNumber the groups themselves.Examples>>>df=pd.DataFrame([['a'],['a'],['a'],['b'],['b'],['a']],...columns=['A'])>>>dfA0  a1  a2  a3  b4  b5  a>>>df.groupby('A').cumcount()0    01    12    23    04    15    3dtype: int64>>>df.groupby('A').cumcount(ascending=False)0    31    22    13    14    05    0dtype: int64"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.cummax,"pandas.core.groupby.DataFrameGroupBy.cummax#DataFrameGroupBy.cummax(axis=_NoDefault.no_default,numeric_only=False,**kwargs)[source]#Cumulative max for each group.Returns:Series or DataFrameSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','a','b','b','b']>>>ser=pd.Series([1,6,2,3,1,4],index=lst)>>>sera    1a    6a    2b    3b    1b    4dtype: int64>>>ser.groupby(level=0).cummax()a    1a    6a    6b    3b    3b    4dtype: int64For DataFrameGroupBy:>>>data=[[1,8,2],[1,1,0],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""cow"",""horse"",""bull""])>>>dfa   b   ccow     1   8   2horse   1   1   0bull    2   6   9>>>df.groupby(""a"").groups{1: ['cow', 'horse'], 2: ['bull']}>>>df.groupby(""a"").cummax()b   ccow     8   2horse   8   2bull    6   9"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.cummin,"pandas.core.groupby.DataFrameGroupBy.cummin#DataFrameGroupBy.cummin(axis=_NoDefault.no_default,numeric_only=False,**kwargs)[source]#Cumulative min for each group.Returns:Series or DataFrameSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','a','b','b','b']>>>ser=pd.Series([1,6,2,3,0,4],index=lst)>>>sera    1a    6a    2b    3b    0b    4dtype: int64>>>ser.groupby(level=0).cummin()a    1a    1a    1b    3b    0b    0dtype: int64For DataFrameGroupBy:>>>data=[[1,0,2],[1,1,5],[6,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""snake"",""rabbit"",""turtle""])>>>dfa   b   csnake   1   0   2rabbit  1   1   5turtle  6   6   9>>>df.groupby(""a"").groups{1: ['snake', 'rabbit'], 6: ['turtle']}>>>df.groupby(""a"").cummin()b   csnake   0   2rabbit  0   2turtle  6   9"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.cumprod,"pandas.core.groupby.DataFrameGroupBy.cumprod#DataFrameGroupBy.cumprod(axis=_NoDefault.no_default,*args,**kwargs)[source]#Cumulative product for each group.Returns:Series or DataFrameSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([6,2,0],index=lst)>>>sera    6a    2b    0dtype: int64>>>ser.groupby(level=0).cumprod()a    6a   12b    0dtype: int64For DataFrameGroupBy:>>>data=[[1,8,2],[1,2,5],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""cow"",""horse"",""bull""])>>>dfa   b   ccow     1   8   2horse   1   2   5bull    2   6   9>>>df.groupby(""a"").groups{1: ['cow', 'horse'], 2: ['bull']}>>>df.groupby(""a"").cumprod()b   ccow     8   2horse  16  10bull    6   9"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.cumsum,"pandas.core.groupby.DataFrameGroupBy.cumsum#DataFrameGroupBy.cumsum(axis=_NoDefault.no_default,*args,**kwargs)[source]#Cumulative sum for each group.Returns:Series or DataFrameSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([6,2,0],index=lst)>>>sera    6a    2b    0dtype: int64>>>ser.groupby(level=0).cumsum()a    6a    8b    0dtype: int64For DataFrameGroupBy:>>>data=[[1,8,2],[1,2,5],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""fox"",""gorilla"",""lion""])>>>dfa   b   cfox       1   8   2gorilla   1   2   5lion      2   6   9>>>df.groupby(""a"").groups{1: ['fox', 'gorilla'], 2: ['lion']}>>>df.groupby(""a"").cumsum()b   cfox       8   2gorilla  10   7lion      6   9"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.describe,"pandas.core.groupby.DataFrameGroupBy.describe#DataFrameGroupBy.describe(percentiles=None,include=None,exclude=None)[source]#Generate descriptive statistics.Descriptive statistics include those that summarize the central
tendency, dispersion and shape of a
dataset’s distribution, excludingNaNvalues.Analyzes both numeric and object series, as well
asDataFramecolumn sets of mixed data types. The output
will vary depending on what is provided. Refer to the notes
below for more detail.Parameters:percentileslist-like of numbers, optionalThe percentiles to include in the output. All should
fall between 0 and 1. The default is[.25,.5,.75], which returns the 25th, 50th, and
75th percentiles.include‘all’, list-like of dtypes or None (default), optionalA white list of data types to include in the result. Ignored
forSeries. Here are the options:‘all’ : All columns of the input will be included in the output.A list-like of dtypes : Limits the results to the
provided data types.
To limit the result to numeric types submitnumpy.number. To limit it instead to object columns submit
thenumpy.objectdata type. Strings
can also be used in the style ofselect_dtypes(e.g.df.describe(include=['O'])). To
select pandas categorical columns, use'category'None (default) : The result will include all numeric columns.excludelist-like of dtypes or None (default), optional,A black list of data types to omit from the result. Ignored
forSeries. Here are the options:A list-like of dtypes : Excludes the provided data types
from the result. To exclude numeric types submitnumpy.number. To exclude object columns submit the data
typenumpy.object. Strings can also be used in the style ofselect_dtypes(e.g.df.describe(exclude=['O'])). To
exclude pandas categorical columns, use'category'None (default) : The result will exclude nothing.Returns:Series or DataFrameSummary statistics of the Series or Dataframe provided.See alsoDataFrame.countCount number of non-NA/null observations.DataFrame.maxMaximum of the values in the object.DataFrame.minMinimum of the values in the object.DataFrame.meanMean of the values.DataFrame.stdStandard deviation of the observations.DataFrame.select_dtypesSubset of a DataFrame including/excluding columns based on their dtype.NotesFor numeric data, the result’s index will includecount,mean,std,min,maxas well as lower,50and
upper percentiles. By default the lower percentile is25and the
upper percentile is75. The50percentile is the
same as the median.For object data (e.g. strings or timestamps), the result’s index
will includecount,unique,top, andfreq. Thetopis the most common value. Thefreqis the most common value’s
frequency. Timestamps also include thefirstandlastitems.If multiple object values have the highest count, then thecountandtopresults will be arbitrarily chosen from
among those with the highest count.For mixed data types provided via aDataFrame, the default is to
return only an analysis of numeric columns. If the dataframe consists
only of object and categorical data without any numeric columns, the
default is to return an analysis of both the object and categorical
columns. Ifinclude='all'is provided as an option, the result
will include a union of attributes of each type.Theincludeandexcludeparameters can be used to limit
which columns in aDataFrameare analyzed for the output.
The parameters are ignored when analyzing aSeries.ExamplesDescribing a numericSeries.>>>s=pd.Series([1,2,3])>>>s.describe()count    3.0mean     2.0std      1.0min      1.025%      1.550%      2.075%      2.5max      3.0dtype: float64Describing a categoricalSeries.>>>s=pd.Series(['a','a','b','c'])>>>s.describe()count     4unique    3top       afreq      2dtype: objectDescribing a timestampSeries.>>>s=pd.Series([...np.datetime64(""2000-01-01""),...np.datetime64(""2010-01-01""),...np.datetime64(""2010-01-01"")...])>>>s.describe()count                      3mean     2006-09-01 08:00:00min      2000-01-01 00:00:0025%      2004-12-31 12:00:0050%      2010-01-01 00:00:0075%      2010-01-01 00:00:00max      2010-01-01 00:00:00dtype: objectDescribing aDataFrame. By default only numeric fields
are returned.>>>df=pd.DataFrame({'categorical':pd.Categorical(['d','e','f']),...'numeric':[1,2,3],...'object':['a','b','c']...})>>>df.describe()numericcount      3.0mean       2.0std        1.0min        1.025%        1.550%        2.075%        2.5max        3.0Describing all columns of aDataFrameregardless of data type.>>>df.describe(include='all')categorical  numeric objectcount            3      3.0      3unique           3      NaN      3top              f      NaN      afreq             1      NaN      1mean           NaN      2.0    NaNstd            NaN      1.0    NaNmin            NaN      1.0    NaN25%            NaN      1.5    NaN50%            NaN      2.0    NaN75%            NaN      2.5    NaNmax            NaN      3.0    NaNDescribing a column from aDataFrameby accessing it as
an attribute.>>>df.numeric.describe()count    3.0mean     2.0std      1.0min      1.025%      1.550%      2.075%      2.5max      3.0Name: numeric, dtype: float64Including only numeric columns in aDataFramedescription.>>>df.describe(include=[np.number])numericcount      3.0mean       2.0std        1.0min        1.025%        1.550%        2.075%        2.5max        3.0Including only string columns in aDataFramedescription.>>>df.describe(include=[object])objectcount       3unique      3top         afreq        1Including only categorical columns from aDataFramedescription.>>>df.describe(include=['category'])categoricalcount            3unique           3top              dfreq             1Excluding numeric columns from aDataFramedescription.>>>df.describe(exclude=[np.number])categorical objectcount            3      3unique           3      3top              f      afreq             1      1Excluding object columns from aDataFramedescription.>>>df.describe(exclude=[object])categorical  numericcount            3      3.0unique           3      NaNtop              f      NaNfreq             1      NaNmean           NaN      2.0std            NaN      1.0min            NaN      1.025%            NaN      1.550%            NaN      2.075%            NaN      2.5max            NaN      3.0"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.diff,"pandas.core.groupby.DataFrameGroupBy.diff#DataFrameGroupBy.diff(periods=1,axis=_NoDefault.no_default)[source]#First discrete difference of element.Calculates the difference of each element compared with another
element in the group (default is element in previous row).Parameters:periodsint, default 1Periods to shift for calculating difference, accepts negative values.axisaxis to shift, default 0Take difference over rows (0) or columns (1).Deprecated since version 2.1.0:For axis=1, operate on the underlying object instead. Otherwise
the axis keyword is not necessary.Returns:Series or DataFrameFirst differences.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','a','b','b','b']>>>ser=pd.Series([7,2,8,4,3,3],index=lst)>>>sera     7a     2a     8b     4b     3b     3dtype: int64>>>ser.groupby(level=0).diff()a    NaNa   -5.0a    6.0b    NaNb   -1.0b    0.0dtype: float64For DataFrameGroupBy:>>>data={'a':[1,3,5,7,7,8,3],'b':[1,4,8,4,4,2,1]}>>>df=pd.DataFrame(data,index=['dog','dog','dog',...'mouse','mouse','mouse','mouse'])>>>dfa  bdog    1  1dog    3  4dog    5  8mouse    7  4mouse    7  4mouse    8  2mouse    3  1>>>df.groupby(level=0).diff()a    bdog  NaN  NaNdog  2.0  3.0dog  2.0  4.0mouse  NaN  NaNmouse  0.0  0.0mouse  1.0 -2.0mouse -5.0 -1.0"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.ffill,"pandas.core.groupby.DataFrameGroupBy.ffill#DataFrameGroupBy.ffill(limit=None)[source]#Forward fill the values.Parameters:limitint, optionalLimit of how many values to fill.Returns:Series or DataFrameObject with missing values filled.See alsoSeries.ffillReturns Series with minimum number of char in object.DataFrame.ffillObject with missing values filled or None if inplace=True.Series.fillnaFill NaN values of a Series.DataFrame.fillnaFill NaN values of a DataFrame.ExamplesFor SeriesGroupBy:>>>key=[0,0,1,1]>>>ser=pd.Series([np.nan,2,3,np.nan],index=key)>>>ser0    NaN0    2.01    3.01    NaNdtype: float64>>>ser.groupby(level=0).ffill()0    NaN0    2.01    3.01    3.0dtype: float64For DataFrameGroupBy:>>>df=pd.DataFrame(...{...""key"":[0,0,1,1,1],...""A"":[np.nan,2,np.nan,3,np.nan],...""B"":[2,3,np.nan,np.nan,np.nan],...""C"":[np.nan,np.nan,2,np.nan,np.nan],...}...)>>>dfkey    A    B   C0    0  NaN  2.0 NaN1    0  2.0  3.0 NaN2    1  NaN  NaN 2.03    1  3.0  NaN NaN4    1  NaN  NaN NaNPropagate non-null values forward or backward within each group along columns.>>>df.groupby(""key"").ffill()A    B   C0  NaN  2.0 NaN1  2.0  3.0 NaN2  NaN  NaN 2.03  3.0  NaN 2.04  3.0  NaN 2.0Propagate non-null values forward or backward within each group along rows.>>>df.T.groupby(np.array([0,0,1,1])).ffill().Tkey    A    B    C0  0.0  0.0  2.0  2.01  0.0  2.0  3.0  3.02  1.0  1.0  NaN  2.03  1.0  3.0  NaN  NaN4  1.0  1.0  NaN  NaNOnly replace the first NaN element within a group along rows.>>>df.groupby(""key"").ffill(limit=1)A    B    C0  NaN  2.0  NaN1  2.0  3.0  NaN2  NaN  NaN  2.03  3.0  NaN  2.04  3.0  NaN  NaN"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.fillna,"pandas.core.groupby.DataFrameGroupBy.fillna#DataFrameGroupBy.fillna(value=None,method=None,axis=_NoDefault.no_default,inplace=False,limit=None,downcast=_NoDefault.no_default)[source]#Fill NA/NaN values using the specified method within groups.Parameters:valuescalar, dict, Series, or DataFrameValue to use to fill holes (e.g. 0), alternately a
dict/Series/DataFrame of values specifying which value to use for
each index (for a Series) or column (for a DataFrame). Values not
in the dict/Series/DataFrame will not be filled. This value cannot
be a list. Users wanting to use thevalueargument and notmethodshould preferDataFrame.fillna()as this
will produce the same result and be more performant.method{{‘bfill’, ‘ffill’, None}}, default NoneMethod to use for filling holes.'ffill'will propagate
the last valid observation forward within a group.'bfill'will use next valid observation to fill the gap.axis{0 or ‘index’, 1 or ‘columns’}Axis along which to fill missing values. When theDataFrameGroupByaxisargument is0, usingaxis=1here will produce
the same results asDataFrame.fillna(). When theDataFrameGroupByaxisargument is1, usingaxis=0oraxis=1here will produce the same results.Deprecated since version 2.1.0:For axis=1, operate on the underlying object instead. Otherwise
the axis keyword is not necessary.inplacebool, default FalseBroken. Do not set to True.limitint, default NoneIf method is specified, this is the maximum number of consecutive
NaN values to forward/backward fill within a group. In other words,
if there is a gap with more than this number of consecutive NaNs,
it will only be partially filled. If method is not specified, this is the
maximum number of entries along the entire axis where NaNs will be
filled. Must be greater than 0 if not None.downcastdict, default is NoneA dict of item->dtype of what to downcast if possible,
or the string ‘infer’ which will try to downcast to an appropriate
equal type (e.g. float64 to int64 if possible).Deprecated since version 2.1.0.Returns:DataFrameObject with missing values filled.See alsoffillForward fill values within a group.bfillBackward fill values within a group.Examples>>>df=pd.DataFrame(...{...""key"":[0,0,1,1,1],...""A"":[np.nan,2,np.nan,3,np.nan],...""B"":[2,3,np.nan,np.nan,np.nan],...""C"":[np.nan,np.nan,2,np.nan,np.nan],...}...)>>>dfkey    A    B   C0    0  NaN  2.0 NaN1    0  2.0  3.0 NaN2    1  NaN  NaN 2.03    1  3.0  NaN NaN4    1  NaN  NaN NaNPropagate non-null values forward or backward within each group along columns.>>>df.groupby(""key"").fillna(method=""ffill"")A    B   C0  NaN  2.0 NaN1  2.0  3.0 NaN2  NaN  NaN 2.03  3.0  NaN 2.04  3.0  NaN 2.0>>>df.groupby(""key"").fillna(method=""bfill"")A    B   C0  2.0  2.0 NaN1  2.0  3.0 NaN2  3.0  NaN 2.03  3.0  NaN NaN4  NaN  NaN NaNPropagate non-null values forward or backward within each group along rows.>>>df.T.groupby(np.array([0,0,1,1])).fillna(method=""ffill"").Tkey    A    B    C0  0.0  0.0  2.0  2.01  0.0  2.0  3.0  3.02  1.0  1.0  NaN  2.03  1.0  3.0  NaN  NaN4  1.0  1.0  NaN  NaN>>>df.T.groupby(np.array([0,0,1,1])).fillna(method=""bfill"").Tkey    A    B    C0  0.0  NaN  2.0  NaN1  0.0  2.0  3.0  NaN2  1.0  NaN  2.0  2.03  1.0  3.0  NaN  NaN4  1.0  NaN  NaN  NaNOnly replace the first NaN element within a group along rows.>>>df.groupby(""key"").fillna(method=""ffill"",limit=1)A    B    C0  NaN  2.0  NaN1  2.0  3.0  NaN2  NaN  NaN  2.03  3.0  NaN  2.04  3.0  NaN  NaN"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.first,"pandas.core.groupby.DataFrameGroupBy.first#DataFrameGroupBy.first(numeric_only=False,min_count=-1)[source]#Compute the first non-null entry of each column.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.min_countint, default -1The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.Returns:Series or DataFrameFirst non-null of values within each group.See alsoDataFrame.groupbyApply a function groupby to each row or column of a DataFrame.pandas.core.groupby.DataFrameGroupBy.lastCompute the last non-null entry of each column.pandas.core.groupby.DataFrameGroupBy.nthTake the nth row from each group.Examples>>>df=pd.DataFrame(dict(A=[1,1,3],B=[None,5,6],C=[1,2,3],...D=['3/11/2000','3/12/2000','3/13/2000']))>>>df['D']=pd.to_datetime(df['D'])>>>df.groupby(""A"").first()B  C          DA1  5.0  1 2000-03-113  6.0  3 2000-03-13>>>df.groupby(""A"").first(min_count=2)B    C          DA1 NaN  1.0 2000-03-113 NaN  NaN        NaT>>>df.groupby(""A"").first(numeric_only=True)B  CA1  5.0  13  6.0  3"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.head,"pandas.core.groupby.DataFrameGroupBy.head#DataFrameGroupBy.head(n=5)[source]#Return first n rows of each group.Similar to.apply(lambdax:x.head(n)), but it returns a subset of rows
from the original DataFrame with original index and order preserved
(as_indexflag is ignored).Parameters:nintIf positive: number of entries to include from start of each group.
If negative: number of entries to exclude from end of each group.Returns:Series or DataFrameSubset of original Series or DataFrame as determined by n.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.Examples>>>df=pd.DataFrame([[1,2],[1,4],[5,6]],...columns=['A','B'])>>>df.groupby('A').head(1)A  B0  1  22  5  6>>>df.groupby('A').head(-1)A  B0  1  2"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.idxmax,"pandas.core.groupby.DataFrameGroupBy.idxmax#DataFrameGroupBy.idxmax(axis=_NoDefault.no_default,skipna=True,numeric_only=False)[source]#Return index of first occurrence of maximum over requested axis.NA/null values are excluded.Parameters:axis{{0 or ‘index’, 1 or ‘columns’}}, default NoneThe axis to use. 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise.
If axis is not provided, grouper’s axis is used.Changed in version 2.0.0.Deprecated since version 2.1.0:For axis=1, operate on the underlying object instead. Otherwise
the axis keyword is not necessary.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result
will be NA.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Returns:SeriesIndexes of maxima along the specified axis.Raises:ValueErrorIf the row/column is emptySee alsoSeries.idxmaxReturn index of the maximum element.NotesThis method is the DataFrame version ofndarray.argmax.ExamplesConsider a dataset containing food consumption in Argentina.>>>df=pd.DataFrame({'consumption':[10.51,103.11,55.48],...'co2_emissions':[37.2,19.66,1712]},...index=['Pork','Wheat Products','Beef'])>>>dfconsumption  co2_emissionsPork                  10.51         37.20Wheat Products       103.11         19.66Beef                  55.48       1712.00By default, it returns the index for the maximum value in each column.>>>df.idxmax()consumption     Wheat Productsco2_emissions             Beefdtype: objectTo return the index for the maximum value in each row, useaxis=""columns"".>>>df.idxmax(axis=""columns"")Pork              co2_emissionsWheat Products     consumptionBeef              co2_emissionsdtype: object"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.idxmin,"pandas.core.groupby.DataFrameGroupBy.idxmin#DataFrameGroupBy.idxmin(axis=_NoDefault.no_default,skipna=True,numeric_only=False)[source]#Return index of first occurrence of minimum over requested axis.NA/null values are excluded.Parameters:axis{{0 or ‘index’, 1 or ‘columns’}}, default NoneThe axis to use. 0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise.
If axis is not provided, grouper’s axis is used.Changed in version 2.0.0.Deprecated since version 2.1.0:For axis=1, operate on the underlying object instead. Otherwise
the axis keyword is not necessary.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result
will be NA.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Returns:SeriesIndexes of minima along the specified axis.Raises:ValueErrorIf the row/column is emptySee alsoSeries.idxminReturn index of the minimum element.NotesThis method is the DataFrame version ofndarray.argmin.ExamplesConsider a dataset containing food consumption in Argentina.>>>df=pd.DataFrame({'consumption':[10.51,103.11,55.48],...'co2_emissions':[37.2,19.66,1712]},...index=['Pork','Wheat Products','Beef'])>>>dfconsumption  co2_emissionsPork                  10.51         37.20Wheat Products       103.11         19.66Beef                  55.48       1712.00By default, it returns the index for the minimum value in each column.>>>df.idxmin()consumption                Porkco2_emissions    Wheat Productsdtype: objectTo return the index for the minimum value in each row, useaxis=""columns"".>>>df.idxmin(axis=""columns"")Pork                consumptionWheat Products    co2_emissionsBeef                consumptiondtype: object"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.last,"pandas.core.groupby.DataFrameGroupBy.last#DataFrameGroupBy.last(numeric_only=False,min_count=-1)[source]#Compute the last non-null entry of each column.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns. If None, will attempt to use
everything, then use only numeric data.min_countint, default -1The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.Returns:Series or DataFrameLast non-null of values within each group.See alsoDataFrame.groupbyApply a function groupby to each row or column of a DataFrame.pandas.core.groupby.DataFrameGroupBy.firstCompute the first non-null entry of each column.pandas.core.groupby.DataFrameGroupBy.nthTake the nth row from each group.Examples>>>df=pd.DataFrame(dict(A=[1,1,3],B=[5,None,6],C=[1,2,3]))>>>df.groupby(""A"").last()B  CA1  5.0  23  6.0  3"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.max,"pandas.core.groupby.DataFrameGroupBy.max#DataFrameGroupBy.max(numeric_only=False,min_count=-1,engine=None,engine_kwargs=None)[source]#Compute max of group values.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.Changed in version 2.0.0:numeric_only no longer acceptsNone.min_countint, default -1The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.enginestr, default None None'cython': Runs rolling apply through C-extensions from cython.'numba'Runs rolling apply through JIT compiled code from numba.Only available whenrawis set toTrue.None: Defaults to'cython'or globally settingcompute.use_numbaengine_kwargsdict, default None NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{'nopython':True,'nogil':False,'parallel':False}and will be
applied to both thefuncand theapplygroupby aggregation.Returns:Series or DataFrameComputed max of values within each group.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b','b']>>>ser=pd.Series([1,2,3,4],index=lst)>>>sera    1a    2b    3b    4dtype: int64>>>ser.groupby(level=0).max()a    2b    4dtype: int64For DataFrameGroupBy:>>>data=[[1,8,2],[1,2,5],[2,5,8],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""tiger"",""leopard"",""cheetah"",""lion""])>>>dfa  b  ctiger   1  8  2leopard   1  2  5cheetah   2  5  8lion   2  6  9>>>df.groupby(""a"").max()b  ca1   8  52   6  9"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.mean,"pandas.core.groupby.DataFrameGroupBy.mean#DataFrameGroupBy.mean(numeric_only=False,engine=None,engine_kwargs=None)[source]#Compute mean of groups, excluding missing values.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.Changed in version 2.0.0:numeric_only no longer acceptsNoneand defaults toFalse.enginestr, default None'cython': Runs the operation through C-extensions from cython.'numba': Runs the operation through JIT compiled code from numba.None: Defaults to'cython'or globally settingcompute.use_numbaNew in version 1.4.0.engine_kwargsdict, default NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{{'nopython':True,'nogil':False,'parallel':False}}New in version 1.4.0.Returns:pandas.Series or pandas.DataFrameSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.Examples>>>df=pd.DataFrame({'A':[1,1,2,1,2],...'B':[np.nan,2,3,4,5],...'C':[1,2,1,1,2]},columns=['A','B','C'])Groupby one column and return the mean of the remaining columns in
each group.>>>df.groupby('A').mean()B         CA1  3.0  1.3333332  4.0  1.500000Groupby two columns and return the mean of the remaining column.>>>df.groupby(['A','B']).mean()CA B1 2.0  2.04.0  1.02 3.0  1.05.0  2.0Groupby one column and return the mean of only particular column in
the group.>>>df.groupby('A')['B'].mean()A1    3.02    4.0Name: B, dtype: float64"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.median,"pandas.core.groupby.DataFrameGroupBy.median#DataFrameGroupBy.median(numeric_only=False)[source]#Compute median of groups, excluding missing values.For multiple groupings, the result index will be a MultiIndexParameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.Changed in version 2.0.0:numeric_only no longer acceptsNoneand defaults to False.Returns:Series or DataFrameMedian of values within each group.ExamplesFor SeriesGroupBy:>>>lst=['a','a','a','b','b','b']>>>ser=pd.Series([7,2,8,4,3,3],index=lst)>>>sera     7a     2a     8b     4b     3b     3dtype: int64>>>ser.groupby(level=0).median()a    7.0b    3.0dtype: float64For DataFrameGroupBy:>>>data={'a':[1,3,5,7,7,8,3],'b':[1,4,8,4,4,2,1]}>>>df=pd.DataFrame(data,index=['dog','dog','dog',...'mouse','mouse','mouse','mouse'])>>>dfa  bdog    1  1dog    3  4dog    5  8mouse    7  4mouse    7  4mouse    8  2mouse    3  1>>>df.groupby(level=0).median()a    bdog    3.0  4.0mouse  7.0  3.0For Resampler:>>>ser=pd.Series([1,2,3,3,4,5],...index=pd.DatetimeIndex(['2023-01-01',...'2023-01-10',...'2023-01-15',...'2023-02-01',...'2023-02-10',...'2023-02-15']))>>>ser.resample('MS').median()2023-01-01    2.02023-02-01    4.0Freq: MS, dtype: float64"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.min,"pandas.core.groupby.DataFrameGroupBy.min#DataFrameGroupBy.min(numeric_only=False,min_count=-1,engine=None,engine_kwargs=None)[source]#Compute min of group values.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.Changed in version 2.0.0:numeric_only no longer acceptsNone.min_countint, default -1The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.enginestr, default None None'cython': Runs rolling apply through C-extensions from cython.'numba'Runs rolling apply through JIT compiled code from numba.Only available whenrawis set toTrue.None: Defaults to'cython'or globally settingcompute.use_numbaengine_kwargsdict, default None NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{'nopython':True,'nogil':False,'parallel':False}and will be
applied to both thefuncand theapplygroupby aggregation.Returns:Series or DataFrameComputed min of values within each group.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b','b']>>>ser=pd.Series([1,2,3,4],index=lst)>>>sera    1a    2b    3b    4dtype: int64>>>ser.groupby(level=0).min()a    1b    3dtype: int64For DataFrameGroupBy:>>>data=[[1,8,2],[1,2,5],[2,5,8],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""tiger"",""leopard"",""cheetah"",""lion""])>>>dfa  b  ctiger   1  8  2leopard   1  2  5cheetah   2  5  8lion   2  6  9>>>df.groupby(""a"").min()b  ca1   2  22   5  8"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.ngroup,"pandas.core.groupby.DataFrameGroupBy.ngroup#DataFrameGroupBy.ngroup(ascending=True)[source]#Number each group from 0 to the number of groups - 1.This is the enumerative complement of cumcount. Note that the
numbers given to the groups match the order in which the groups
would be seen when iterating over the groupby object, not the
order they are first observed.Groups with missing keys (wherepd.isna()is True) will be labeled withNaNand will be skipped from the count.Parameters:ascendingbool, default TrueIf False, number in reverse, from number of group - 1 to 0.Returns:SeriesUnique numbers for each group.See alsocumcountNumber the rows in each group.Examples>>>df=pd.DataFrame({""color"":[""red"",None,""red"",""blue"",""blue"",""red""]})>>>dfcolor0    red1   None2    red3   blue4   blue5    red>>>df.groupby(""color"").ngroup()0    1.01    NaN2    1.03    0.04    0.05    1.0dtype: float64>>>df.groupby(""color"",dropna=False).ngroup()0    11    22    13    04    05    1dtype: int64>>>df.groupby(""color"",dropna=False).ngroup(ascending=False)0    11    02    13    24    25    1dtype: int64"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.nth,"pandas.core.groupby.DataFrameGroupBy.nth#propertyDataFrameGroupBy.nth[source]#Take the nth row from each group if n is an int, otherwise a subset of rows.Can be either a call or an index. dropna is not available with index notation.
Index notation accepts a comma separated list of integers and slices.If dropna, will take the nth non-null row, dropna is either
‘all’ or ‘any’; this is equivalent to calling dropna(how=dropna)
before the groupby.Parameters:nint, slice or list of ints and slicesA single nth value for the row or a list of nth values or slices.Changed in version 1.4.0:Added slice and lists containing slices.
Added index notation.dropna{‘any’, ‘all’, None}, default NoneApply the specified dropna operation before counting which row is
the nth row. Only supported if n is an int.Returns:Series or DataFrameN-th value within each group.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.Examples>>>df=pd.DataFrame({'A':[1,1,2,1,2],...'B':[np.nan,2,3,4,5]},columns=['A','B'])>>>g=df.groupby('A')>>>g.nth(0)A   B0  1 NaN2  2 3.0>>>g.nth(1)A   B1  1 2.04  2 5.0>>>g.nth(-1)A   B3  1 4.04  2 5.0>>>g.nth([0,1])A   B0  1 NaN1  1 2.02  2 3.04  2 5.0>>>g.nth(slice(None,-1))A   B0  1 NaN1  1 2.02  2 3.0Index notation may also be used>>>g.nth[0,1]A   B0  1 NaN1  1 2.02  2 3.04  2 5.0>>>g.nth[:-1]A   B0  1 NaN1  1 2.02  2 3.0Specifyingdropnaallows ignoringNaNvalues>>>g.nth(0,dropna='any')A   B1  1 2.02  2 3.0When the specifiednis larger than any of the groups, an
empty DataFrame is returned>>>g.nth(3,dropna='any')Empty DataFrameColumns: [A, B]Index: []"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.nunique,"pandas.core.groupby.DataFrameGroupBy.nunique#DataFrameGroupBy.nunique(dropna=True)[source]#Return DataFrame with counts of unique elements in each position.Parameters:dropnabool, default TrueDon’t include NaN in the counts.Returns:nunique: DataFrameExamples>>>df=pd.DataFrame({'id':['spam','egg','egg','spam',...'ham','ham'],...'value1':[1,5,5,2,5,5],...'value2':list('abbaxy')})>>>dfid  value1 value20  spam       1      a1   egg       5      b2   egg       5      b3  spam       2      a4   ham       5      x5   ham       5      y>>>df.groupby('id').nunique()value1  value2idegg        1       1ham        1       2spam       2       1Check for rows with the same id but conflicting values:>>>df.groupby('id').filter(lambdag:(g.nunique()>1).any())id  value1 value20  spam       1      a3  spam       2      a4   ham       5      x5   ham       5      y"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.ohlc,"pandas.core.groupby.DataFrameGroupBy.ohlc#DataFrameGroupBy.ohlc()[source]#Compute open, high, low and close values of a group, excluding missing values.For multiple groupings, the result index will be a MultiIndexReturns:DataFrameOpen, high, low and close values within each group.ExamplesFor SeriesGroupBy:>>>lst=['SPX','CAC','SPX','CAC','SPX','CAC','SPX','CAC',]>>>ser=pd.Series([3.4,9.0,7.2,5.2,8.8,9.4,0.1,0.5],index=lst)>>>serSPX     3.4CAC     9.0SPX     7.2CAC     5.2SPX     8.8CAC     9.4SPX     0.1CAC     0.5dtype: float64>>>ser.groupby(level=0).ohlc()open  high  low  closeCAC   9.0   9.4  0.5    0.5SPX   3.4   8.8  0.1    0.1For DataFrameGroupBy:>>>data={2022:[1.2,2.3,8.9,4.5,4.4,3,2,1],...2023:[3.4,9.0,7.2,5.2,8.8,9.4,8.2,1.0]}>>>df=pd.DataFrame(data,index=['SPX','CAC','SPX','CAC',...'SPX','CAC','SPX','CAC'])>>>df2022  2023SPX   1.2   3.4CAC   2.3   9.0SPX   8.9   7.2CAC   4.5   5.2SPX   4.4   8.8CAC   3.0   9.4SPX   2.0   8.2CAC   1.0   1.0>>>df.groupby(level=0).ohlc()2022                 2023open high  low close open high  low closeCAC  2.3  4.5  1.0   1.0  9.0  9.4  1.0   1.0SPX  1.2  8.9  1.2   2.0  3.4  8.8  3.4   8.2For Resampler:>>>ser=pd.Series([1,3,2,4,3,5],...index=pd.DatetimeIndex(['2023-01-01',...'2023-01-10',...'2023-01-15',...'2023-02-01',...'2023-02-10',...'2023-02-15']))>>>ser.resample('MS').ohlc()open  high  low  close2023-01-01     1     3    1      22023-02-01     4     5    3      5"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.pct_change,"pandas.core.groupby.DataFrameGroupBy.pct_change#DataFrameGroupBy.pct_change(periods=1,fill_method=_NoDefault.no_default,limit=_NoDefault.no_default,freq=None,axis=_NoDefault.no_default)[source]#Calculate pct_change of each value to previous entry in group.Returns:Series or DataFramePercentage changes within each group.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b','b']>>>ser=pd.Series([1,2,3,4],index=lst)>>>sera    1a    2b    3b    4dtype: int64>>>ser.groupby(level=0).pct_change()a         NaNa    1.000000b         NaNb    0.333333dtype: float64For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[2,5,8],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""tuna"",""salmon"",""catfish"",""goldfish""])>>>dfa  b  ctuna   1  2  3salmon   1  5  6catfish   2  5  8goldfish   2  6  9>>>df.groupby(""a"").pct_change()b  ctuna    NaN    NaNsalmon    1.5  1.000catfish    NaN    NaNgoldfish    0.2  0.125"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.prod,"pandas.core.groupby.DataFrameGroupBy.prod#DataFrameGroupBy.prod(numeric_only=False,min_count=0)[source]#Compute prod of group values.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.Changed in version 2.0.0:numeric_only no longer acceptsNone.min_countint, default 0The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.Returns:Series or DataFrameComputed prod of values within each group.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b','b']>>>ser=pd.Series([1,2,3,4],index=lst)>>>sera    1a    2b    3b    4dtype: int64>>>ser.groupby(level=0).prod()a    2b   12dtype: int64For DataFrameGroupBy:>>>data=[[1,8,2],[1,2,5],[2,5,8],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""tiger"",""leopard"",""cheetah"",""lion""])>>>dfa  b  ctiger   1  8  2leopard   1  2  5cheetah   2  5  8lion   2  6  9>>>df.groupby(""a"").prod()b    ca1   16   102   30   72"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.quantile,"pandas.core.groupby.DataFrameGroupBy.quantile#DataFrameGroupBy.quantile(q=0.5,interpolation='linear',numeric_only=False)[source]#Return group values at the given quantile, a la numpy.percentile.Parameters:qfloat or array-like, default 0.5 (50% quantile)Value(s) between 0 and 1 providing the quantile(s) to compute.interpolation{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}Method to use when the desired quantile falls between two points.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:numeric_only now defaults toFalse.Returns:Series or DataFrameReturn type determined by caller of GroupBy object.See alsoSeries.quantileSimilar method for Series.DataFrame.quantileSimilar method for DataFrame.numpy.percentileNumPy method to compute qth percentile.Examples>>>df=pd.DataFrame([...['a',1],['a',2],['a',3],...['b',1],['b',3],['b',5]...],columns=['key','val'])>>>df.groupby('key').quantile()valkeya    2.0b    3.0"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.rank,"pandas.core.groupby.DataFrameGroupBy.rank#DataFrameGroupBy.rank(method='average',ascending=True,na_option='keep',pct=False,axis=_NoDefault.no_default)[source]#Provide the rank of values within each group.Parameters:method{‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’average: average rank of group.min: lowest rank in group.max: highest rank in group.first: ranks assigned in order they appear in the array.dense: like ‘min’, but rank always increases by 1 between groups.ascendingbool, default TrueFalse for ranks by high (1) to low (N).na_option{‘keep’, ‘top’, ‘bottom’}, default ‘keep’keep: leave NA values where they are.top: smallest rank if ascending.bottom: smallest rank if descending.pctbool, default FalseCompute percentage rank of data within each group.axisint, default 0The axis of the object over which to compute the rank.Deprecated since version 2.1.0:For axis=1, operate on the underlying object instead. Otherwise
the axis keyword is not necessary.Returns:DataFrame with ranking of values within each groupSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.Examples>>>df=pd.DataFrame(...{...""group"":[""a"",""a"",""a"",""a"",""a"",""b"",""b"",""b"",""b"",""b""],...""value"":[2,4,2,3,5,1,2,4,1,5],...}...)>>>dfgroup  value0     a      21     a      42     a      23     a      34     a      55     b      16     b      27     b      48     b      19     b      5>>>formethodin['average','min','max','dense','first']:...df[f'{method}_rank']=df.groupby('group')['value'].rank(method)>>>dfgroup  value  average_rank  min_rank  max_rank  dense_rank  first_rank0     a      2           1.5       1.0       2.0         1.0         1.01     a      4           4.0       4.0       4.0         3.0         4.02     a      2           1.5       1.0       2.0         1.0         2.03     a      3           3.0       3.0       3.0         2.0         3.04     a      5           5.0       5.0       5.0         4.0         5.05     b      1           1.5       1.0       2.0         1.0         1.06     b      2           3.0       3.0       3.0         2.0         3.07     b      4           4.0       4.0       4.0         3.0         4.08     b      1           1.5       1.0       2.0         1.0         2.09     b      5           5.0       5.0       5.0         4.0         5.0"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.resample,"pandas.core.groupby.DataFrameGroupBy.resample#DataFrameGroupBy.resample(rule,*args,**kwargs)[source]#Provide resampling when using a TimeGrouper.Given a grouper, the function resamples it according to a string
“string” -> “frequency”.See thefrequency aliasesdocumentation for more details.Parameters:rulestr or DateOffsetThe offset string or object representing target grouper conversion.*args, **kwargsPossible arguments arehow,fill_method,limit,kindandon, and other arguments ofTimeGrouper.Returns:pandas.api.typing.DatetimeIndexResamplerGroupby,pandas.api.typing.PeriodIndexResamplerGroupby, orpandas.api.typing.TimedeltaIndexResamplerGroupbyReturn a new groupby object, with type depending on the data
being resampled.See alsoGrouperSpecify a frequency to resample with when grouping by a key.DatetimeIndex.resampleFrequency conversion and resampling of time series.Examples>>>idx=pd.date_range('1/1/2000',periods=4,freq='T')>>>df=pd.DataFrame(data=4*[range(2)],...index=idx,...columns=['a','b'])>>>df.iloc[2,0]=5>>>dfa  b2000-01-01 00:00:00  0  12000-01-01 00:01:00  0  12000-01-01 00:02:00  5  12000-01-01 00:03:00  0  1Downsample the DataFrame into 3 minute bins and sum the values of
the timestamps falling into a bin.>>>df.groupby('a').resample('3T').sum()a  ba0   2000-01-01 00:00:00  0  22000-01-01 00:03:00  0  15   2000-01-01 00:00:00  5  1Upsample the series into 30 second bins.>>>df.groupby('a').resample('30S').sum()a  ba0   2000-01-01 00:00:00  0  12000-01-01 00:00:30  0  02000-01-01 00:01:00  0  12000-01-01 00:01:30  0  02000-01-01 00:02:00  0  02000-01-01 00:02:30  0  02000-01-01 00:03:00  0  15   2000-01-01 00:02:00  5  1Resample by month. Values are assigned to the month of the period.>>>df.groupby('a').resample('M').sum()a  ba0   2000-01-31  0  35   2000-01-31  5  1Downsample the series into 3 minute bins as above, but close the right
side of the bin interval.>>>df.groupby('a').resample('3T',closed='right').sum()a  ba0   1999-12-31 23:57:00  0  12000-01-01 00:00:00  0  25   2000-01-01 00:00:00  5  1Downsample the series into 3 minute bins and close the right side of
the bin interval, but label each bin using the right edge instead of
the left.>>>df.groupby('a').resample('3T',closed='right',label='right').sum()a  ba0   2000-01-01 00:00:00  0  12000-01-01 00:03:00  0  25   2000-01-01 00:03:00  5  1"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.rolling,"pandas.core.groupby.DataFrameGroupBy.rolling#DataFrameGroupBy.rolling(*args,**kwargs)[source]#Return a rolling grouper, providing rolling functionality per group.Parameters:windowint, timedelta, str, offset, or BaseIndexer subclassSize of the moving window.If an integer, the fixed number of observations used for
each window.If a timedelta, str, or offset, the time period of each window. Each
window will be a variable sized based on the observations included in
the time-period. This is only valid for datetimelike indexes.
To learn more about the offsets & frequency strings, please seethis link.If a BaseIndexer subclass, the window boundaries
based on the definedget_window_boundsmethod. Additional rolling
keyword arguments, namelymin_periods,center,closedandstepwill be passed toget_window_bounds.min_periodsint, default NoneMinimum number of observations in window required to have a value;
otherwise, result isnp.nan.For a window that is specified by an offset,min_periodswill default to 1.For a window that is specified by an integer,min_periodswill default
to the size of the window.centerbool, default FalseIf False, set the window labels as the right edge of the window index.If True, set the window labels as the center of the window index.win_typestr, default NoneIfNone, all points are evenly weighted.If a string, it must be a validscipy.signal window function.Certain Scipy window types require additional parameters to be passed
in the aggregation function. The additional parameters must match
the keywords specified in the Scipy window type method signature.onstr, optionalFor a DataFrame, a column label or Index level on which
to calculate the rolling window, rather than the DataFrame’s index.Provided integer column is ignored and excluded from result since
an integer index is not used to calculate the rolling window.axisint or str, default 0If0or'index', roll across the rows.If1or'columns', roll across the columns.ForSeriesthis parameter is unused and defaults to 0.closedstr, default NoneIf'right', the first point in the window is excluded from calculations.If'left', the last point in the window is excluded from calculations.If'both', no points in the window are excluded from calculations.If'neither', the first and last points in the window are excluded
from calculations.DefaultNone('right').methodstr {‘single’, ‘table’}, default ‘single’Execute the rolling operation per single column or row ('single')
or over the entire object ('table').This argument is only implemented when specifyingengine='numba'in the method call.Returns:pandas.api.typing.RollingGroupbyReturn a new grouper with our rolling appended.See alsoSeries.rollingCalling object with Series data.DataFrame.rollingCalling object with DataFrames.Series.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby.Examples>>>df=pd.DataFrame({'A':[1,1,2,2],...'B':[1,2,3,4],...'C':[0.362,0.227,1.267,-0.562]})>>>dfA  B      C0     1  1  0.3621     1  2  0.2272     2  3  1.2673     2  4 -0.562>>>df.groupby('A').rolling(2).sum()B      CA1 0  NaN    NaN1  3.0  0.5892 2  NaN    NaN3  7.0  0.705>>>df.groupby('A').rolling(2,min_periods=1).sum()B      CA1 0  1.0  0.3621  3.0  0.5892 2  3.0  1.2673  7.0  0.705>>>df.groupby('A').rolling(2,on='B').sum()B      CA1 0  1    NaN1  2  0.5892 2  3    NaN3  4  0.705"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.sample,"pandas.core.groupby.DataFrameGroupBy.sample#DataFrameGroupBy.sample(n=None,frac=None,replace=False,weights=None,random_state=None)[source]#Return a random sample of items from each group.You can userandom_statefor reproducibility.Parameters:nint, optionalNumber of items to return for each group. Cannot be used withfracand must be no larger than the smallest group unlessreplaceis True. Default is one iffracis None.fracfloat, optionalFraction of items to return. Cannot be used withn.replacebool, default FalseAllow or disallow sampling of the same row more than once.weightslist-like, optionalDefault None results in equal probability weighting.
If passed a list-like then values must have the same length as
the underlying DataFrame or Series object and will be used as
sampling probabilities after normalization within each group.
Values must be non-negative with at least one positive element
within each group.random_stateint, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optionalIf int, array-like, or BitGenerator, seed for random number generator.
If np.random.RandomState or np.random.Generator, use as given.Changed in version 1.4.0:np.random.Generator objects now acceptedReturns:Series or DataFrameA new object of same type as caller containing items randomly
sampled within each group from the caller object.See alsoDataFrame.sampleGenerate random samples from a DataFrame object.numpy.random.choiceGenerate a random sample from a given 1-D numpy array.Examples>>>df=pd.DataFrame(...{""a"":[""red""]*2+[""blue""]*2+[""black""]*2,""b"":range(6)}...)>>>dfa  b0    red  01    red  12   blue  23   blue  34  black  45  black  5Select one row at random for each distinct value in column a. Therandom_stateargument can be used to guarantee reproducibility:>>>df.groupby(""a"").sample(n=1,random_state=1)a  b4  black  42   blue  21    red  1Setfracto sample fixed proportions rather than counts:>>>df.groupby(""a"")[""b""].sample(frac=0.5,random_state=2)5    52    20    0Name: b, dtype: int64Control sample probabilities within groups by setting weights:>>>df.groupby(""a"").sample(...n=1,...weights=[1,1,1,0,0,1],...random_state=1,...)a  b5  black  52   blue  20    red  0"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.sem,"pandas.core.groupby.DataFrameGroupBy.sem#DataFrameGroupBy.sem(ddof=1,numeric_only=False)[source]#Compute standard error of the mean of groups, excluding missing values.For multiple groupings, the result index will be a MultiIndex.Parameters:ddofint, default 1Degrees of freedom.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:numeric_only now defaults toFalse.Returns:Series or DataFrameStandard error of the mean of values within each group.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b','b']>>>ser=pd.Series([5,10,8,14],index=lst)>>>sera     5a    10b     8b    14dtype: int64>>>ser.groupby(level=0).sem()a    2.5b    3.0dtype: float64For DataFrameGroupBy:>>>data=[[1,12,11],[1,15,2],[2,5,8],[2,6,12]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""tuna"",""salmon"",""catfish"",""goldfish""])>>>dfa   b   ctuna   1  12  11salmon   1  15   2catfish   2   5   8goldfish   2   6  12>>>df.groupby(""a"").sem()b  ca1    1.5  4.52    0.5  2.0For Resampler:>>>ser=pd.Series([1,3,2,4,3,8],...index=pd.DatetimeIndex(['2023-01-01',...'2023-01-10',...'2023-01-15',...'2023-02-01',...'2023-02-10',...'2023-02-15']))>>>ser.resample('MS').sem()2023-01-01    0.5773502023-02-01    1.527525Freq: MS, dtype: float64"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.shift,"pandas.core.groupby.DataFrameGroupBy.shift#DataFrameGroupBy.shift(periods=1,freq=None,axis=_NoDefault.no_default,fill_value=_NoDefault.no_default,suffix=None)[source]#Shift each group by periods observations.If freq is passed, the index will be increased using the periods and the freq.Parameters:periodsint | Sequence[int], default 1Number of periods to shift. If a list of values, shift each group by
each period.freqstr, optionalFrequency string.axisaxis to shift, default 0Shift direction.Deprecated since version 2.1.0:For axis=1, operate on the underlying object instead. Otherwise
the axis keyword is not necessary.fill_valueoptionalThe scalar value to use for newly introduced missing values.Changed in version 2.1.0:Will raise aValueErroriffreqis provided too.suffixstr, optionalA string to add to each shifted column if there are multiple periods.
Ignored otherwise.Returns:Series or DataFrameObject shifted within each group.See alsoIndex.shiftShift values of Index.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b','b']>>>ser=pd.Series([1,2,3,4],index=lst)>>>sera    1a    2b    3b    4dtype: int64>>>ser.groupby(level=0).shift(1)a    NaNa    1.0b    NaNb    3.0dtype: float64For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[2,5,8],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""tuna"",""salmon"",""catfish"",""goldfish""])>>>dfa  b  ctuna   1  2  3salmon   1  5  6catfish   2  5  8goldfish   2  6  9>>>df.groupby(""a"").shift(1)b    ctuna    NaN  NaNsalmon    2.0  3.0catfish    NaN  NaNgoldfish    5.0  8.0"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.size,"pandas.core.groupby.DataFrameGroupBy.size#DataFrameGroupBy.size()[source]#Compute group sizes.Returns:DataFrame or SeriesNumber of rows in each group as a Series if as_index is True
or a DataFrame if as_index is False.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,3],index=lst)>>>sera     1a     2b     3dtype: int64>>>ser.groupby(level=0).size()a    2b    1dtype: int64>>>data=[[1,2,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""owl"",""toucan"",""eagle""])>>>dfa  b  cowl     1  2  3toucan  1  5  6eagle   7  8  9>>>df.groupby(""a"").size()a1    27    1dtype: int64For Resampler:>>>ser=pd.Series([1,2,3],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01']))>>>ser2023-01-01    12023-01-15    22023-02-01    3dtype: int64>>>ser.resample('MS').size()2023-01-01    22023-02-01    1Freq: MS, dtype: int64"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.skew,"pandas.core.groupby.DataFrameGroupBy.skew#DataFrameGroupBy.skew(axis=_NoDefault.no_default,skipna=True,numeric_only=False,**kwargs)[source]#Return unbiased skew within groups.Normalized by N-1.Parameters:axis{0 or ‘index’, 1 or ‘columns’, None}, default 0Axis for the function to be applied on.Specifyingaxis=Nonewill apply the aggregation across both axes.New in version 2.0.0.Deprecated since version 2.1.0:For axis=1, operate on the underlying object instead. Otherwise
the axis keyword is not necessary.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns.**kwargsAdditional keyword arguments to be passed to the function.Returns:DataFrameSee alsoDataFrame.skewReturn unbiased skew over requested axis.Examples>>>arrays=[['falcon','parrot','cockatoo','kiwi',...'lion','monkey','rabbit'],...['bird','bird','bird','bird',...'mammal','mammal','mammal']]>>>index=pd.MultiIndex.from_arrays(arrays,names=('name','class'))>>>df=pd.DataFrame({'max_speed':[389.0,24.0,70.0,np.nan,...80.5,21.5,15.0]},...index=index)>>>dfmax_speedname     classfalcon   bird        389.0parrot   bird         24.0cockatoo bird         70.0kiwi     bird          NaNlion     mammal       80.5monkey   mammal       21.5rabbit   mammal       15.0>>>gb=df.groupby([""class""])>>>gb.skew()max_speedclassbird     1.628296mammal   1.669046>>>gb.skew(skipna=False)max_speedclassbird          NaNmammal   1.669046"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.std,"pandas.core.groupby.DataFrameGroupBy.std#DataFrameGroupBy.std(ddof=1,engine=None,engine_kwargs=None,numeric_only=False)[source]#Compute standard deviation of groups, excluding missing values.For multiple groupings, the result index will be a MultiIndex.Parameters:ddofint, default 1Degrees of freedom.enginestr, default None'cython': Runs the operation through C-extensions from cython.'numba': Runs the operation through JIT compiled code from numba.None: Defaults to'cython'or globally settingcompute.use_numbaNew in version 1.4.0.engine_kwargsdict, default NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{{'nopython':True,'nogil':False,'parallel':False}}New in version 1.4.0.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:numeric_only now defaults toFalse.Returns:Series or DataFrameStandard deviation of values within each group.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','a','b','b','b']>>>ser=pd.Series([7,2,8,4,3,3],index=lst)>>>sera     7a     2a     8b     4b     3b     3dtype: int64>>>ser.groupby(level=0).std()a    3.21455b    0.57735dtype: float64For DataFrameGroupBy:>>>data={'a':[1,3,5,7,7,8,3],'b':[1,4,8,4,4,2,1]}>>>df=pd.DataFrame(data,index=['dog','dog','dog',...'mouse','mouse','mouse','mouse'])>>>dfa  bdog    1  1dog    3  4dog    5  8mouse    7  4mouse    7  4mouse    8  2mouse    3  1>>>df.groupby(level=0).std()a         bdog    2.000000  3.511885mouse  2.217356  1.500000"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.sum,"pandas.core.groupby.DataFrameGroupBy.sum#DataFrameGroupBy.sum(numeric_only=False,min_count=0,engine=None,engine_kwargs=None)[source]#Compute sum of group values.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.Changed in version 2.0.0:numeric_only no longer acceptsNone.min_countint, default 0The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.enginestr, default None None'cython': Runs rolling apply through C-extensions from cython.'numba'Runs rolling apply through JIT compiled code from numba.Only available whenrawis set toTrue.None: Defaults to'cython'or globally settingcompute.use_numbaengine_kwargsdict, default None NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{'nopython':True,'nogil':False,'parallel':False}and will be
applied to both thefuncand theapplygroupby aggregation.Returns:Series or DataFrameComputed sum of values within each group.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b','b']>>>ser=pd.Series([1,2,3,4],index=lst)>>>sera    1a    2b    3b    4dtype: int64>>>ser.groupby(level=0).sum()a    3b    7dtype: int64For DataFrameGroupBy:>>>data=[[1,8,2],[1,2,5],[2,5,8],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""tiger"",""leopard"",""cheetah"",""lion""])>>>dfa  b  ctiger   1  8  2leopard   1  2  5cheetah   2  5  8lion   2  6  9>>>df.groupby(""a"").sum()b   ca1   10   72   11  17"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.var,"pandas.core.groupby.DataFrameGroupBy.var#DataFrameGroupBy.var(ddof=1,engine=None,engine_kwargs=None,numeric_only=False)[source]#Compute variance of groups, excluding missing values.For multiple groupings, the result index will be a MultiIndex.Parameters:ddofint, default 1Degrees of freedom.enginestr, default None'cython': Runs the operation through C-extensions from cython.'numba': Runs the operation through JIT compiled code from numba.None: Defaults to'cython'or globally settingcompute.use_numbaNew in version 1.4.0.engine_kwargsdict, default NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{{'nopython':True,'nogil':False,'parallel':False}}New in version 1.4.0.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:numeric_only now defaults toFalse.Returns:Series or DataFrameVariance of values within each group.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','a','b','b','b']>>>ser=pd.Series([7,2,8,4,3,3],index=lst)>>>sera     7a     2a     8b     4b     3b     3dtype: int64>>>ser.groupby(level=0).var()a    10.333333b     0.333333dtype: float64For DataFrameGroupBy:>>>data={'a':[1,3,5,7,7,8,3],'b':[1,4,8,4,4,2,1]}>>>df=pd.DataFrame(data,index=['dog','dog','dog',...'mouse','mouse','mouse','mouse'])>>>dfa  bdog    1  1dog    3  4dog    5  8mouse    7  4mouse    7  4mouse    8  2mouse    3  1>>>df.groupby(level=0).var()a          bdog    4.000000  12.333333mouse  4.916667   2.250000"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.tail,"pandas.core.groupby.DataFrameGroupBy.tail#DataFrameGroupBy.tail(n=5)[source]#Return last n rows of each group.Similar to.apply(lambdax:x.tail(n)), but it returns a subset of rows
from the original DataFrame with original index and order preserved
(as_indexflag is ignored).Parameters:nintIf positive: number of entries to include from end of each group.
If negative: number of entries to exclude from start of each group.Returns:Series or DataFrameSubset of original Series or DataFrame as determined by n.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.Examples>>>df=pd.DataFrame([['a',1],['a',2],['b',1],['b',2]],...columns=['A','B'])>>>df.groupby('A').tail(1)A  B1  a  23  b  2>>>df.groupby('A').tail(-1)A  B1  a  23  b  2"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.take,"pandas.core.groupby.DataFrameGroupBy.take#DataFrameGroupBy.take(indices,axis=_NoDefault.no_default,**kwargs)[source]#Return the elements in the givenpositionalindices in each group.This means that we are not indexing according to actual values in
the index attribute of the object. We are indexing according to the
actual position of the element in the object.If a requested index does not exist for some group, this method will raise.
To get similar behavior that ignores indices that don’t exist, seeDataFrameGroupBy.nth().Parameters:indicesarray-likeAn array of ints indicating which positions to take.axis{0 or ‘index’, 1 or ‘columns’, None}, default 0The axis on which to select elements.0means that we are
selecting rows,1means that we are selecting columns.Deprecated since version 2.1.0:For axis=1, operate on the underlying object instead. Otherwise
the axis keyword is not necessary.**kwargsFor compatibility withnumpy.take(). Has no effect on the
output.Returns:DataFrameAn DataFrame containing the elements taken from each group.See alsoDataFrame.takeTake elements from a Series along an axis.DataFrame.locSelect a subset of a DataFrame by labels.DataFrame.ilocSelect a subset of a DataFrame by positions.numpy.takeTake elements from an array along an axis.Examples>>>df=pd.DataFrame([('falcon','bird',389.0),...('parrot','bird',24.0),...('lion','mammal',80.5),...('monkey','mammal',np.nan),...('rabbit','mammal',15.0)],...columns=['name','class','max_speed'],...index=[4,3,2,1,0])>>>dfname   class  max_speed4  falcon    bird      389.03  parrot    bird       24.02    lion  mammal       80.51  monkey  mammal        NaN0  rabbit  mammal       15.0>>>gb=df.groupby([1,1,2,2,2])Take elements at positions 0 and 1 along the axis 0 (default).Note how the indices selected in the result do not correspond to
our input indices 0 and 1. That’s because we are selecting the 0th
and 1st rows, not rows whose indices equal 0 and 1.>>>gb.take([0,1])name   class  max_speed1 4  falcon    bird      389.03  parrot    bird       24.02 2    lion  mammal       80.51  monkey  mammal        NaNThe order of the specified indices influences the order in the result.
Here, the order is swapped from the previous example.>>>gb.take([1,0])name   class  max_speed1 3  parrot    bird       24.04  falcon    bird      389.02 1  monkey  mammal        NaN2    lion  mammal       80.5Take elements at indices 1 and 2 along the axis 1 (column selection).We may take elements using negative integers for positive indices,
starting from the end of the object, just like with Python lists.>>>gb.take([-1,-2])name   class  max_speed1 3  parrot    bird       24.04  falcon    bird      389.02 0  rabbit  mammal       15.01  monkey  mammal        NaN"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.value_counts,"pandas.core.groupby.DataFrameGroupBy.value_counts#DataFrameGroupBy.value_counts(subset=None,normalize=False,sort=True,ascending=False,dropna=True)[source]#Return a Series or DataFrame containing counts of unique rows.New in version 1.4.0.Parameters:subsetlist-like, optionalColumns to use when counting unique combinations.normalizebool, default FalseReturn proportions rather than frequencies.sortbool, default TrueSort by frequencies.ascendingbool, default FalseSort in ascending order.dropnabool, default TrueDon’t include counts of rows that contain NA values.Returns:Series or DataFrameSeries if the groupby as_index is True, otherwise DataFrame.See alsoSeries.value_countsEquivalent method on Series.DataFrame.value_countsEquivalent method on DataFrame.SeriesGroupBy.value_countsEquivalent method on SeriesGroupBy.NotesIf the groupby as_index is True then the returned Series will have a
MultiIndex with one level per input column.If the groupby as_index is False then the returned DataFrame will have an
additional column with the value_counts. The column is labelled ‘count’ or
‘proportion’, depending on thenormalizeparameter.By default, rows that contain any NA values are omitted from
the result.By default, the result will be in descending order so that the
first element of each group is the most frequently-occurring row.Examples>>>df=pd.DataFrame({...'gender':['male','male','female','male','female','male'],...'education':['low','medium','high','low','high','low'],...'country':['US','FR','US','FR','FR','FR']...})>>>dfgender  education   country0       male    low         US1       male    medium      FR2       female  high        US3       male    low         FR4       female  high        FR5       male    low         FR>>>df.groupby('gender').value_counts()gender  education  countryfemale  high       FR         1US         1male    low        FR         2US         1medium     FR         1Name: count, dtype: int64>>>df.groupby('gender').value_counts(ascending=True)gender  education  countryfemale  high       FR         1US         1male    low        US         1medium     FR         1low        FR         2Name: count, dtype: int64>>>df.groupby('gender').value_counts(normalize=True)gender  education  countryfemale  high       FR         0.50US         0.50male    low        FR         0.50US         0.25medium     FR         0.25Name: proportion, dtype: float64>>>df.groupby('gender',as_index=False).value_counts()gender education country  count0  female      high      FR      11  female      high      US      12    male       low      FR      23    male       low      US      14    male    medium      FR      1>>>df.groupby('gender',as_index=False).value_counts(normalize=True)gender education country  proportion0  female      high      FR        0.501  female      high      US        0.502    male       low      FR        0.503    male       low      US        0.254    male    medium      FR        0.25"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.all,"pandas.core.groupby.SeriesGroupBy.all#SeriesGroupBy.all(skipna=True)[source]#Return True if all values in the group are truthful, else False.Parameters:skipnabool, default TrueFlag to ignore nan values during truth testing.Returns:Series or DataFrameDataFrame or Series of boolean values, where a value is True if all elements
are True within its respective group, False otherwise.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,0],index=lst)>>>sera    1a    2b    0dtype: int64>>>ser.groupby(level=0).all()a     Trueb    Falsedtype: boolFor DataFrameGroupBy:>>>data=[[1,0,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""ostrich"",""penguin"",""parrot""])>>>dfa  b  costrich  1  0  3penguin  1  5  6parrot   7  8  9>>>df.groupby(by=[""a""]).all()b      ca1  False   True7   True   True"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.any,"pandas.core.groupby.SeriesGroupBy.any#SeriesGroupBy.any(skipna=True)[source]#Return True if any value in the group is truthful, else False.Parameters:skipnabool, default TrueFlag to ignore nan values during truth testing.Returns:Series or DataFrameDataFrame or Series of boolean values, where a value is True if any element
is True within its respective group, False otherwise.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,0],index=lst)>>>sera    1a    2b    0dtype: int64>>>ser.groupby(level=0).any()a     Trueb    Falsedtype: boolFor DataFrameGroupBy:>>>data=[[1,0,3],[1,0,6],[7,1,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""ostrich"",""penguin"",""parrot""])>>>dfa  b  costrich  1  0  3penguin  1  0  6parrot   7  1  9>>>df.groupby(by=[""a""]).any()b      ca1  False   True7   True   True"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.bfill,"pandas.core.groupby.SeriesGroupBy.bfill#SeriesGroupBy.bfill(limit=None)[source]#Backward fill the values.Parameters:limitint, optionalLimit of how many values to fill.Returns:Series or DataFrameObject with missing values filled.See alsoSeries.bfillBackward fill the missing values in the dataset.DataFrame.bfillBackward fill the missing values in the dataset.Series.fillnaFill NaN values of a Series.DataFrame.fillnaFill NaN values of a DataFrame.ExamplesWith Series:>>>index=['Falcon','Falcon','Parrot','Parrot','Parrot']>>>s=pd.Series([None,1,None,None,3],index=index)>>>sFalcon    NaNFalcon    1.0Parrot    NaNParrot    NaNParrot    3.0dtype: float64>>>s.groupby(level=0).bfill()Falcon    1.0Falcon    1.0Parrot    3.0Parrot    3.0Parrot    3.0dtype: float64>>>s.groupby(level=0).bfill(limit=1)Falcon    1.0Falcon    1.0Parrot    NaNParrot    3.0Parrot    3.0dtype: float64With DataFrame:>>>df=pd.DataFrame({'A':[1,None,None,None,4],...'B':[None,None,5,None,7]},index=index)>>>dfA         BFalcon  1.0       NaNFalcon  NaN       NaNParrot  NaN       5.0Parrot  NaN       NaNParrot  4.0       7.0>>>df.groupby(level=0).bfill()A         BFalcon  1.0       NaNFalcon  NaN       NaNParrot  4.0       5.0Parrot  4.0       7.0Parrot  4.0       7.0>>>df.groupby(level=0).bfill(limit=1)A         BFalcon  1.0       NaNFalcon  NaN       NaNParrot  NaN       5.0Parrot  4.0       7.0Parrot  4.0       7.0"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.corr,"pandas.core.groupby.SeriesGroupBy.corr#SeriesGroupBy.corr(other,method='pearson',min_periods=None)[source]#Compute correlation withotherSeries, excluding missing values.The twoSeriesobjects are not required to be the same length and will be
aligned internally before the correlation function is applied.Parameters:otherSeriesSeries with which to compute the correlation.method{‘pearson’, ‘kendall’, ‘spearman’} or callableMethod used to compute correlation:pearson : Standard correlation coefficientkendall : Kendall Tau correlation coefficientspearman : Spearman rank correlationcallable: Callable with input two 1d ndarrays and returning a float.WarningNote that the returned matrix from corr will have 1 along the
diagonals and will be symmetric regardless of the callable’s
behavior.min_periodsint, optionalMinimum number of observations needed to have a valid result.Returns:floatCorrelation with other.See alsoDataFrame.corrCompute pairwise correlation between columns.DataFrame.corrwithCompute pairwise correlation with another DataFrame or Series.NotesPearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.Pearson correlation coefficientKendall rank correlation coefficientSpearman’s rank correlation coefficientAutomatic data alignment: as with all pandas operations, automatic data alignment is performed for this method.corr()automatically considers values with matching indices.Examples>>>defhistogram_intersection(a,b):...v=np.minimum(a,b).sum().round(decimals=1)...returnv>>>s1=pd.Series([.2,.0,.6,.2])>>>s2=pd.Series([.3,.6,.0,.1])>>>s1.corr(s2,method=histogram_intersection)0.3Pandas auto-aligns the values with matching indices>>>s1=pd.Series([1,2,3],index=[0,1,2])>>>s2=pd.Series([1,2,3],index=[2,1,0])>>>s1.corr(s2)-1.0"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.count,"pandas.core.groupby.SeriesGroupBy.count#SeriesGroupBy.count()[source]#Compute count of group, excluding missing values.Returns:Series or DataFrameCount of values within each group.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,np.nan],index=lst)>>>sera    1.0a    2.0b    NaNdtype: float64>>>ser.groupby(level=0).count()a    2b    0dtype: int64For DataFrameGroupBy:>>>data=[[1,np.nan,3],[1,np.nan,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""cow"",""horse"",""bull""])>>>dfa         b     ccow     1       NaN     3horse   1       NaN     6bull    7       8.0     9>>>df.groupby(""a"").count()b   ca1   0   27   1   1For Resampler:>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').count()2023-01-01    22023-02-01    2Freq: MS, dtype: int64"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.cov,"pandas.core.groupby.SeriesGroupBy.cov#SeriesGroupBy.cov(other,min_periods=None,ddof=1)[source]#Compute covariance with Series, excluding missing values.The twoSeriesobjects are not required to be the same length and
will be aligned internally before the covariance is calculated.Parameters:otherSeriesSeries with which to compute the covariance.min_periodsint, optionalMinimum number of observations needed to have a valid result.ddofint, default 1Delta degrees of freedom. The divisor used in calculations
isN-ddof, whereNrepresents the number of elements.Returns:floatCovariance between Series and other normalized by N-1
(unbiased estimator).See alsoDataFrame.covCompute pairwise covariance of columns.Examples>>>s1=pd.Series([0.90010907,0.13484424,0.62036035])>>>s2=pd.Series([0.12528585,0.26962463,0.51111198])>>>s1.cov(s2)-0.01685762652715874"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.cumcount,"pandas.core.groupby.SeriesGroupBy.cumcount#SeriesGroupBy.cumcount(ascending=True)[source]#Number each item in each group from 0 to the length of that group - 1.Essentially this is equivalent toself.apply(lambdax:pd.Series(np.arange(len(x)),x.index))Parameters:ascendingbool, default TrueIf False, number in reverse, from length of group - 1 to 0.Returns:SeriesSequence number of each element within each group.See alsongroupNumber the groups themselves.Examples>>>df=pd.DataFrame([['a'],['a'],['a'],['b'],['b'],['a']],...columns=['A'])>>>dfA0  a1  a2  a3  b4  b5  a>>>df.groupby('A').cumcount()0    01    12    23    04    15    3dtype: int64>>>df.groupby('A').cumcount(ascending=False)0    31    22    13    14    05    0dtype: int64"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.cummax,"pandas.core.groupby.SeriesGroupBy.cummax#SeriesGroupBy.cummax(axis=_NoDefault.no_default,numeric_only=False,**kwargs)[source]#Cumulative max for each group.Returns:Series or DataFrameSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','a','b','b','b']>>>ser=pd.Series([1,6,2,3,1,4],index=lst)>>>sera    1a    6a    2b    3b    1b    4dtype: int64>>>ser.groupby(level=0).cummax()a    1a    6a    6b    3b    3b    4dtype: int64For DataFrameGroupBy:>>>data=[[1,8,2],[1,1,0],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""cow"",""horse"",""bull""])>>>dfa   b   ccow     1   8   2horse   1   1   0bull    2   6   9>>>df.groupby(""a"").groups{1: ['cow', 'horse'], 2: ['bull']}>>>df.groupby(""a"").cummax()b   ccow     8   2horse   8   2bull    6   9"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.cummin,"pandas.core.groupby.SeriesGroupBy.cummin#SeriesGroupBy.cummin(axis=_NoDefault.no_default,numeric_only=False,**kwargs)[source]#Cumulative min for each group.Returns:Series or DataFrameSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','a','b','b','b']>>>ser=pd.Series([1,6,2,3,0,4],index=lst)>>>sera    1a    6a    2b    3b    0b    4dtype: int64>>>ser.groupby(level=0).cummin()a    1a    1a    1b    3b    0b    0dtype: int64For DataFrameGroupBy:>>>data=[[1,0,2],[1,1,5],[6,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""snake"",""rabbit"",""turtle""])>>>dfa   b   csnake   1   0   2rabbit  1   1   5turtle  6   6   9>>>df.groupby(""a"").groups{1: ['snake', 'rabbit'], 6: ['turtle']}>>>df.groupby(""a"").cummin()b   csnake   0   2rabbit  0   2turtle  6   9"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.cumprod,"pandas.core.groupby.SeriesGroupBy.cumprod#SeriesGroupBy.cumprod(axis=_NoDefault.no_default,*args,**kwargs)[source]#Cumulative product for each group.Returns:Series or DataFrameSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([6,2,0],index=lst)>>>sera    6a    2b    0dtype: int64>>>ser.groupby(level=0).cumprod()a    6a   12b    0dtype: int64For DataFrameGroupBy:>>>data=[[1,8,2],[1,2,5],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""cow"",""horse"",""bull""])>>>dfa   b   ccow     1   8   2horse   1   2   5bull    2   6   9>>>df.groupby(""a"").groups{1: ['cow', 'horse'], 2: ['bull']}>>>df.groupby(""a"").cumprod()b   ccow     8   2horse  16  10bull    6   9"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.cumsum,"pandas.core.groupby.SeriesGroupBy.cumsum#SeriesGroupBy.cumsum(axis=_NoDefault.no_default,*args,**kwargs)[source]#Cumulative sum for each group.Returns:Series or DataFrameSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([6,2,0],index=lst)>>>sera    6a    2b    0dtype: int64>>>ser.groupby(level=0).cumsum()a    6a    8b    0dtype: int64For DataFrameGroupBy:>>>data=[[1,8,2],[1,2,5],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""fox"",""gorilla"",""lion""])>>>dfa   b   cfox       1   8   2gorilla   1   2   5lion      2   6   9>>>df.groupby(""a"").groups{1: ['fox', 'gorilla'], 2: ['lion']}>>>df.groupby(""a"").cumsum()b   cfox       8   2gorilla  10   7lion      6   9"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.describe,"pandas.core.groupby.SeriesGroupBy.describe#SeriesGroupBy.describe(**kwargs)[source]#Generate descriptive statistics.Descriptive statistics include those that summarize the central
tendency, dispersion and shape of a
dataset’s distribution, excludingNaNvalues.Analyzes both numeric and object series, as well
asDataFramecolumn sets of mixed data types. The output
will vary depending on what is provided. Refer to the notes
below for more detail.Parameters:percentileslist-like of numbers, optionalThe percentiles to include in the output. All should
fall between 0 and 1. The default is[.25,.5,.75], which returns the 25th, 50th, and
75th percentiles.include‘all’, list-like of dtypes or None (default), optionalA white list of data types to include in the result. Ignored
forSeries. Here are the options:‘all’ : All columns of the input will be included in the output.A list-like of dtypes : Limits the results to the
provided data types.
To limit the result to numeric types submitnumpy.number. To limit it instead to object columns submit
thenumpy.objectdata type. Strings
can also be used in the style ofselect_dtypes(e.g.df.describe(include=['O'])). To
select pandas categorical columns, use'category'None (default) : The result will include all numeric columns.excludelist-like of dtypes or None (default), optional,A black list of data types to omit from the result. Ignored
forSeries. Here are the options:A list-like of dtypes : Excludes the provided data types
from the result. To exclude numeric types submitnumpy.number. To exclude object columns submit the data
typenumpy.object. Strings can also be used in the style ofselect_dtypes(e.g.df.describe(exclude=['O'])). To
exclude pandas categorical columns, use'category'None (default) : The result will exclude nothing.Returns:Series or DataFrameSummary statistics of the Series or Dataframe provided.See alsoDataFrame.countCount number of non-NA/null observations.DataFrame.maxMaximum of the values in the object.DataFrame.minMinimum of the values in the object.DataFrame.meanMean of the values.DataFrame.stdStandard deviation of the observations.DataFrame.select_dtypesSubset of a DataFrame including/excluding columns based on their dtype.NotesFor numeric data, the result’s index will includecount,mean,std,min,maxas well as lower,50and
upper percentiles. By default the lower percentile is25and the
upper percentile is75. The50percentile is the
same as the median.For object data (e.g. strings or timestamps), the result’s index
will includecount,unique,top, andfreq. Thetopis the most common value. Thefreqis the most common value’s
frequency. Timestamps also include thefirstandlastitems.If multiple object values have the highest count, then thecountandtopresults will be arbitrarily chosen from
among those with the highest count.For mixed data types provided via aDataFrame, the default is to
return only an analysis of numeric columns. If the dataframe consists
only of object and categorical data without any numeric columns, the
default is to return an analysis of both the object and categorical
columns. Ifinclude='all'is provided as an option, the result
will include a union of attributes of each type.Theincludeandexcludeparameters can be used to limit
which columns in aDataFrameare analyzed for the output.
The parameters are ignored when analyzing aSeries.ExamplesDescribing a numericSeries.>>>s=pd.Series([1,2,3])>>>s.describe()count    3.0mean     2.0std      1.0min      1.025%      1.550%      2.075%      2.5max      3.0dtype: float64Describing a categoricalSeries.>>>s=pd.Series(['a','a','b','c'])>>>s.describe()count     4unique    3top       afreq      2dtype: objectDescribing a timestampSeries.>>>s=pd.Series([...np.datetime64(""2000-01-01""),...np.datetime64(""2010-01-01""),...np.datetime64(""2010-01-01"")...])>>>s.describe()count                      3mean     2006-09-01 08:00:00min      2000-01-01 00:00:0025%      2004-12-31 12:00:0050%      2010-01-01 00:00:0075%      2010-01-01 00:00:00max      2010-01-01 00:00:00dtype: objectDescribing aDataFrame. By default only numeric fields
are returned.>>>df=pd.DataFrame({'categorical':pd.Categorical(['d','e','f']),...'numeric':[1,2,3],...'object':['a','b','c']...})>>>df.describe()numericcount      3.0mean       2.0std        1.0min        1.025%        1.550%        2.075%        2.5max        3.0Describing all columns of aDataFrameregardless of data type.>>>df.describe(include='all')categorical  numeric objectcount            3      3.0      3unique           3      NaN      3top              f      NaN      afreq             1      NaN      1mean           NaN      2.0    NaNstd            NaN      1.0    NaNmin            NaN      1.0    NaN25%            NaN      1.5    NaN50%            NaN      2.0    NaN75%            NaN      2.5    NaNmax            NaN      3.0    NaNDescribing a column from aDataFrameby accessing it as
an attribute.>>>df.numeric.describe()count    3.0mean     2.0std      1.0min      1.025%      1.550%      2.075%      2.5max      3.0Name: numeric, dtype: float64Including only numeric columns in aDataFramedescription.>>>df.describe(include=[np.number])numericcount      3.0mean       2.0std        1.0min        1.025%        1.550%        2.075%        2.5max        3.0Including only string columns in aDataFramedescription.>>>df.describe(include=[object])objectcount       3unique      3top         afreq        1Including only categorical columns from aDataFramedescription.>>>df.describe(include=['category'])categoricalcount            3unique           3top              dfreq             1Excluding numeric columns from aDataFramedescription.>>>df.describe(exclude=[np.number])categorical objectcount            3      3unique           3      3top              f      afreq             1      1Excluding object columns from aDataFramedescription.>>>df.describe(exclude=[object])categorical  numericcount            3      3.0unique           3      NaNtop              f      NaNfreq             1      NaNmean           NaN      2.0std            NaN      1.0min            NaN      1.025%            NaN      1.550%            NaN      2.075%            NaN      2.5max            NaN      3.0"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.diff,"pandas.core.groupby.SeriesGroupBy.diff#SeriesGroupBy.diff(periods=1,axis=_NoDefault.no_default)[source]#First discrete difference of element.Calculates the difference of each element compared with another
element in the group (default is element in previous row).Parameters:periodsint, default 1Periods to shift for calculating difference, accepts negative values.axisaxis to shift, default 0Take difference over rows (0) or columns (1).Deprecated since version 2.1.0:For axis=1, operate on the underlying object instead. Otherwise
the axis keyword is not necessary.Returns:Series or DataFrameFirst differences.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','a','b','b','b']>>>ser=pd.Series([7,2,8,4,3,3],index=lst)>>>sera     7a     2a     8b     4b     3b     3dtype: int64>>>ser.groupby(level=0).diff()a    NaNa   -5.0a    6.0b    NaNb   -1.0b    0.0dtype: float64For DataFrameGroupBy:>>>data={'a':[1,3,5,7,7,8,3],'b':[1,4,8,4,4,2,1]}>>>df=pd.DataFrame(data,index=['dog','dog','dog',...'mouse','mouse','mouse','mouse'])>>>dfa  bdog    1  1dog    3  4dog    5  8mouse    7  4mouse    7  4mouse    8  2mouse    3  1>>>df.groupby(level=0).diff()a    bdog  NaN  NaNdog  2.0  3.0dog  2.0  4.0mouse  NaN  NaNmouse  0.0  0.0mouse  1.0 -2.0mouse -5.0 -1.0"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.ffill,"pandas.core.groupby.SeriesGroupBy.ffill#SeriesGroupBy.ffill(limit=None)[source]#Forward fill the values.Parameters:limitint, optionalLimit of how many values to fill.Returns:Series or DataFrameObject with missing values filled.See alsoSeries.ffillReturns Series with minimum number of char in object.DataFrame.ffillObject with missing values filled or None if inplace=True.Series.fillnaFill NaN values of a Series.DataFrame.fillnaFill NaN values of a DataFrame.ExamplesFor SeriesGroupBy:>>>key=[0,0,1,1]>>>ser=pd.Series([np.nan,2,3,np.nan],index=key)>>>ser0    NaN0    2.01    3.01    NaNdtype: float64>>>ser.groupby(level=0).ffill()0    NaN0    2.01    3.01    3.0dtype: float64For DataFrameGroupBy:>>>df=pd.DataFrame(...{...""key"":[0,0,1,1,1],...""A"":[np.nan,2,np.nan,3,np.nan],...""B"":[2,3,np.nan,np.nan,np.nan],...""C"":[np.nan,np.nan,2,np.nan,np.nan],...}...)>>>dfkey    A    B   C0    0  NaN  2.0 NaN1    0  2.0  3.0 NaN2    1  NaN  NaN 2.03    1  3.0  NaN NaN4    1  NaN  NaN NaNPropagate non-null values forward or backward within each group along columns.>>>df.groupby(""key"").ffill()A    B   C0  NaN  2.0 NaN1  2.0  3.0 NaN2  NaN  NaN 2.03  3.0  NaN 2.04  3.0  NaN 2.0Propagate non-null values forward or backward within each group along rows.>>>df.T.groupby(np.array([0,0,1,1])).ffill().Tkey    A    B    C0  0.0  0.0  2.0  2.01  0.0  2.0  3.0  3.02  1.0  1.0  NaN  2.03  1.0  3.0  NaN  NaN4  1.0  1.0  NaN  NaNOnly replace the first NaN element within a group along rows.>>>df.groupby(""key"").ffill(limit=1)A    B    C0  NaN  2.0  NaN1  2.0  3.0  NaN2  NaN  NaN  2.03  3.0  NaN  2.04  3.0  NaN  NaN"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.fillna,"pandas.core.groupby.SeriesGroupBy.fillna#SeriesGroupBy.fillna(value=None,method=None,axis=_NoDefault.no_default,inplace=False,limit=None,downcast=_NoDefault.no_default)[source]#Fill NA/NaN values using the specified method within groups.Parameters:valuescalar, dict, Series, or DataFrameValue to use to fill holes (e.g. 0), alternately a
dict/Series/DataFrame of values specifying which value to use for
each index (for a Series) or column (for a DataFrame). Values not
in the dict/Series/DataFrame will not be filled. This value cannot
be a list. Users wanting to use thevalueargument and notmethodshould preferSeries.fillna()as this
will produce the same result and be more performant.method{{‘bfill’, ‘ffill’, None}}, default NoneMethod to use for filling holes.'ffill'will propagate
the last valid observation forward within a group.'bfill'will use next valid observation to fill the gap.Deprecated since version 2.1.0:Use obj.ffill or obj.bfill instead.axis{0 or ‘index’, 1 or ‘columns’}Unused, only for compatibility withDataFrameGroupBy.fillna().Deprecated since version 2.1.0:For axis=1, operate on the underlying object instead. Otherwise
the axis keyword is not necessary.inplacebool, default FalseBroken. Do not set to True.limitint, default NoneIf method is specified, this is the maximum number of consecutive
NaN values to forward/backward fill within a group. In other words,
if there is a gap with more than this number of consecutive NaNs,
it will only be partially filled. If method is not specified, this is the
maximum number of entries along the entire axis where NaNs will be
filled. Must be greater than 0 if not None.downcastdict, default is NoneA dict of item->dtype of what to downcast if possible,
or the string ‘infer’ which will try to downcast to an appropriate
equal type (e.g. float64 to int64 if possible).Deprecated since version 2.1.0.Returns:SeriesObject with missing values filled within groups.See alsoffillForward fill values within a group.bfillBackward fill values within a group.ExamplesFor SeriesGroupBy:>>>lst=['cat','cat','cat','mouse','mouse']>>>ser=pd.Series([1,None,None,2,None],index=lst)>>>sercat    1.0cat    NaNcat    NaNmouse  2.0mouse  NaNdtype: float64>>>ser.groupby(level=0).fillna(0,limit=1)cat    1.0cat    0.0cat    NaNmouse  2.0mouse  0.0dtype: float64"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.first,"pandas.core.groupby.SeriesGroupBy.first#SeriesGroupBy.first(numeric_only=False,min_count=-1)[source]#Compute the first non-null entry of each column.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.min_countint, default -1The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.Returns:Series or DataFrameFirst non-null of values within each group.See alsoDataFrame.groupbyApply a function groupby to each row or column of a DataFrame.pandas.core.groupby.DataFrameGroupBy.lastCompute the last non-null entry of each column.pandas.core.groupby.DataFrameGroupBy.nthTake the nth row from each group.Examples>>>df=pd.DataFrame(dict(A=[1,1,3],B=[None,5,6],C=[1,2,3],...D=['3/11/2000','3/12/2000','3/13/2000']))>>>df['D']=pd.to_datetime(df['D'])>>>df.groupby(""A"").first()B  C          DA1  5.0  1 2000-03-113  6.0  3 2000-03-13>>>df.groupby(""A"").first(min_count=2)B    C          DA1 NaN  1.0 2000-03-113 NaN  NaN        NaT>>>df.groupby(""A"").first(numeric_only=True)B  CA1  5.0  13  6.0  3"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.head,"pandas.core.groupby.SeriesGroupBy.head#SeriesGroupBy.head(n=5)[source]#Return first n rows of each group.Similar to.apply(lambdax:x.head(n)), but it returns a subset of rows
from the original DataFrame with original index and order preserved
(as_indexflag is ignored).Parameters:nintIf positive: number of entries to include from start of each group.
If negative: number of entries to exclude from end of each group.Returns:Series or DataFrameSubset of original Series or DataFrame as determined by n.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.Examples>>>df=pd.DataFrame([[1,2],[1,4],[5,6]],...columns=['A','B'])>>>df.groupby('A').head(1)A  B0  1  22  5  6>>>df.groupby('A').head(-1)A  B0  1  2"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.last,"pandas.core.groupby.SeriesGroupBy.last#SeriesGroupBy.last(numeric_only=False,min_count=-1)[source]#Compute the last non-null entry of each column.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns. If None, will attempt to use
everything, then use only numeric data.min_countint, default -1The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.Returns:Series or DataFrameLast non-null of values within each group.See alsoDataFrame.groupbyApply a function groupby to each row or column of a DataFrame.pandas.core.groupby.DataFrameGroupBy.firstCompute the first non-null entry of each column.pandas.core.groupby.DataFrameGroupBy.nthTake the nth row from each group.Examples>>>df=pd.DataFrame(dict(A=[1,1,3],B=[5,None,6],C=[1,2,3]))>>>df.groupby(""A"").last()B  CA1  5.0  23  6.0  3"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.idxmax,"pandas.core.groupby.SeriesGroupBy.idxmax#SeriesGroupBy.idxmax(axis=_NoDefault.no_default,skipna=True)[source]#Return the row label of the maximum value.If multiple values equal the maximum, the first row label with that
value is returned.Parameters:axis{0 or ‘index’}Unused. Parameter needed for compatibility with DataFrame.skipnabool, default TrueExclude NA/null values. If the entire Series is NA, the result
will be NA.*args, **kwargsAdditional arguments and keywords have no effect but might be
accepted for compatibility with NumPy.Returns:IndexLabel of the maximum value.Raises:ValueErrorIf the Series is empty.See alsonumpy.argmaxReturn indices of the maximum values along the given axis.DataFrame.idxmaxReturn index of first occurrence of maximum over requested axis.Series.idxminReturn indexlabelof the first occurrence of minimum of values.NotesThis method is the Series version ofndarray.argmax. This method
returns the label of the maximum, whilendarray.argmaxreturns
the position. To get the position, useseries.values.argmax().Examples>>>s=pd.Series(data=[1,None,4,3,4],...index=['A','B','C','D','E'])>>>sA    1.0B    NaNC    4.0D    3.0E    4.0dtype: float64>>>s.idxmax()'C'Ifskipnais False and there is an NA value in the data,
the function returnsnan.>>>s.idxmax(skipna=False)nan"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.idxmin,"pandas.core.groupby.SeriesGroupBy.idxmin#SeriesGroupBy.idxmin(axis=_NoDefault.no_default,skipna=True)[source]#Return the row label of the minimum value.If multiple values equal the minimum, the first row label with that
value is returned.Parameters:axis{0 or ‘index’}Unused. Parameter needed for compatibility with DataFrame.skipnabool, default TrueExclude NA/null values. If the entire Series is NA, the result
will be NA.*args, **kwargsAdditional arguments and keywords have no effect but might be
accepted for compatibility with NumPy.Returns:IndexLabel of the minimum value.Raises:ValueErrorIf the Series is empty.See alsonumpy.argminReturn indices of the minimum values along the given axis.DataFrame.idxminReturn index of first occurrence of minimum over requested axis.Series.idxmaxReturn indexlabelof the first occurrence of maximum of values.NotesThis method is the Series version ofndarray.argmin. This method
returns the label of the minimum, whilendarray.argminreturns
the position. To get the position, useseries.values.argmin().Examples>>>s=pd.Series(data=[1,None,4,1],...index=['A','B','C','D'])>>>sA    1.0B    NaNC    4.0D    1.0dtype: float64>>>s.idxmin()'A'Ifskipnais False and there is an NA value in the data,
the function returnsnan.>>>s.idxmin(skipna=False)nan"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.is_monotonic_increasing,"pandas.core.groupby.SeriesGroupBy.is_monotonic_increasing#propertySeriesGroupBy.is_monotonic_increasing[source]#Return whether each group’s values are monotonically increasing.Returns:SeriesExamples>>>s=pd.Series([2,1,3,4],index=['Falcon','Falcon','Parrot','Parrot'])>>>s.groupby(level=0).is_monotonic_increasingFalcon    FalseParrot     Truedtype: bool"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.is_monotonic_decreasing,"pandas.core.groupby.SeriesGroupBy.is_monotonic_decreasing#propertySeriesGroupBy.is_monotonic_decreasing[source]#Return whether each group’s values are monotonically decreasing.Returns:SeriesExamples>>>s=pd.Series([2,1,3,4],index=['Falcon','Falcon','Parrot','Parrot'])>>>s.groupby(level=0).is_monotonic_decreasingFalcon     TrueParrot    Falsedtype: bool"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.max,"pandas.core.groupby.SeriesGroupBy.max#SeriesGroupBy.max(numeric_only=False,min_count=-1,engine=None,engine_kwargs=None)[source]#Compute max of group values.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.Changed in version 2.0.0:numeric_only no longer acceptsNone.min_countint, default -1The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.enginestr, default None None'cython': Runs rolling apply through C-extensions from cython.'numba'Runs rolling apply through JIT compiled code from numba.Only available whenrawis set toTrue.None: Defaults to'cython'or globally settingcompute.use_numbaengine_kwargsdict, default None NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{'nopython':True,'nogil':False,'parallel':False}and will be
applied to both thefuncand theapplygroupby aggregation.Returns:Series or DataFrameComputed max of values within each group.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b','b']>>>ser=pd.Series([1,2,3,4],index=lst)>>>sera    1a    2b    3b    4dtype: int64>>>ser.groupby(level=0).max()a    2b    4dtype: int64For DataFrameGroupBy:>>>data=[[1,8,2],[1,2,5],[2,5,8],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""tiger"",""leopard"",""cheetah"",""lion""])>>>dfa  b  ctiger   1  8  2leopard   1  2  5cheetah   2  5  8lion   2  6  9>>>df.groupby(""a"").max()b  ca1   8  52   6  9"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.mean,"pandas.core.groupby.SeriesGroupBy.mean#SeriesGroupBy.mean(numeric_only=False,engine=None,engine_kwargs=None)[source]#Compute mean of groups, excluding missing values.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.Changed in version 2.0.0:numeric_only no longer acceptsNoneand defaults toFalse.enginestr, default None'cython': Runs the operation through C-extensions from cython.'numba': Runs the operation through JIT compiled code from numba.None: Defaults to'cython'or globally settingcompute.use_numbaNew in version 1.4.0.engine_kwargsdict, default NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{{'nopython':True,'nogil':False,'parallel':False}}New in version 1.4.0.Returns:pandas.Series or pandas.DataFrameSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.Examples>>>df=pd.DataFrame({'A':[1,1,2,1,2],...'B':[np.nan,2,3,4,5],...'C':[1,2,1,1,2]},columns=['A','B','C'])Groupby one column and return the mean of the remaining columns in
each group.>>>df.groupby('A').mean()B         CA1  3.0  1.3333332  4.0  1.500000Groupby two columns and return the mean of the remaining column.>>>df.groupby(['A','B']).mean()CA B1 2.0  2.04.0  1.02 3.0  1.05.0  2.0Groupby one column and return the mean of only particular column in
the group.>>>df.groupby('A')['B'].mean()A1    3.02    4.0Name: B, dtype: float64"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.median,"pandas.core.groupby.SeriesGroupBy.median#SeriesGroupBy.median(numeric_only=False)[source]#Compute median of groups, excluding missing values.For multiple groupings, the result index will be a MultiIndexParameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.Changed in version 2.0.0:numeric_only no longer acceptsNoneand defaults to False.Returns:Series or DataFrameMedian of values within each group.ExamplesFor SeriesGroupBy:>>>lst=['a','a','a','b','b','b']>>>ser=pd.Series([7,2,8,4,3,3],index=lst)>>>sera     7a     2a     8b     4b     3b     3dtype: int64>>>ser.groupby(level=0).median()a    7.0b    3.0dtype: float64For DataFrameGroupBy:>>>data={'a':[1,3,5,7,7,8,3],'b':[1,4,8,4,4,2,1]}>>>df=pd.DataFrame(data,index=['dog','dog','dog',...'mouse','mouse','mouse','mouse'])>>>dfa  bdog    1  1dog    3  4dog    5  8mouse    7  4mouse    7  4mouse    8  2mouse    3  1>>>df.groupby(level=0).median()a    bdog    3.0  4.0mouse  7.0  3.0For Resampler:>>>ser=pd.Series([1,2,3,3,4,5],...index=pd.DatetimeIndex(['2023-01-01',...'2023-01-10',...'2023-01-15',...'2023-02-01',...'2023-02-10',...'2023-02-15']))>>>ser.resample('MS').median()2023-01-01    2.02023-02-01    4.0Freq: MS, dtype: float64"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.min,"pandas.core.groupby.SeriesGroupBy.min#SeriesGroupBy.min(numeric_only=False,min_count=-1,engine=None,engine_kwargs=None)[source]#Compute min of group values.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.Changed in version 2.0.0:numeric_only no longer acceptsNone.min_countint, default -1The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.enginestr, default None None'cython': Runs rolling apply through C-extensions from cython.'numba'Runs rolling apply through JIT compiled code from numba.Only available whenrawis set toTrue.None: Defaults to'cython'or globally settingcompute.use_numbaengine_kwargsdict, default None NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{'nopython':True,'nogil':False,'parallel':False}and will be
applied to both thefuncand theapplygroupby aggregation.Returns:Series or DataFrameComputed min of values within each group.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b','b']>>>ser=pd.Series([1,2,3,4],index=lst)>>>sera    1a    2b    3b    4dtype: int64>>>ser.groupby(level=0).min()a    1b    3dtype: int64For DataFrameGroupBy:>>>data=[[1,8,2],[1,2,5],[2,5,8],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""tiger"",""leopard"",""cheetah"",""lion""])>>>dfa  b  ctiger   1  8  2leopard   1  2  5cheetah   2  5  8lion   2  6  9>>>df.groupby(""a"").min()b  ca1   2  22   5  8"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.ngroup,"pandas.core.groupby.SeriesGroupBy.ngroup#SeriesGroupBy.ngroup(ascending=True)[source]#Number each group from 0 to the number of groups - 1.This is the enumerative complement of cumcount. Note that the
numbers given to the groups match the order in which the groups
would be seen when iterating over the groupby object, not the
order they are first observed.Groups with missing keys (wherepd.isna()is True) will be labeled withNaNand will be skipped from the count.Parameters:ascendingbool, default TrueIf False, number in reverse, from number of group - 1 to 0.Returns:SeriesUnique numbers for each group.See alsocumcountNumber the rows in each group.Examples>>>df=pd.DataFrame({""color"":[""red"",None,""red"",""blue"",""blue"",""red""]})>>>dfcolor0    red1   None2    red3   blue4   blue5    red>>>df.groupby(""color"").ngroup()0    1.01    NaN2    1.03    0.04    0.05    1.0dtype: float64>>>df.groupby(""color"",dropna=False).ngroup()0    11    22    13    04    05    1dtype: int64>>>df.groupby(""color"",dropna=False).ngroup(ascending=False)0    11    02    13    24    25    1dtype: int64"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.nlargest,"pandas.core.groupby.SeriesGroupBy.nlargest#SeriesGroupBy.nlargest(n=5,keep='first')[source]#Return the largestnelements.Parameters:nint, default 5Return this many descending sorted values.keep{‘first’, ‘last’, ‘all’}, default ‘first’When there are duplicate values that cannot all fit in a
Series ofnelements:first: return the firstnoccurrences in order
of appearance.last: return the lastnoccurrences in reverse
order of appearance.all: keep all occurrences. This can result in a Series of
size larger thann.Returns:SeriesThenlargest values in the Series, sorted in decreasing order.See alsoSeries.nsmallestGet thensmallest elements.Series.sort_valuesSort Series by values.Series.headReturn the firstnrows.NotesFaster than.sort_values(ascending=False).head(n)for smallnrelative to the size of theSeriesobject.Examples>>>countries_population={""Italy"":59000000,""France"":65000000,...""Malta"":434000,""Maldives"":434000,...""Brunei"":434000,""Iceland"":337000,...""Nauru"":11300,""Tuvalu"":11300,...""Anguilla"":11300,""Montserrat"":5200}>>>s=pd.Series(countries_population)>>>sItaly       59000000France      65000000Malta         434000Maldives      434000Brunei        434000Iceland       337000Nauru          11300Tuvalu         11300Anguilla       11300Montserrat      5200dtype: int64Thenlargest elements wheren=5by default.>>>s.nlargest()France      65000000Italy       59000000Malta         434000Maldives      434000Brunei        434000dtype: int64Thenlargest elements wheren=3. Defaultkeepvalue is ‘first’
so Malta will be kept.>>>s.nlargest(3)France    65000000Italy     59000000Malta       434000dtype: int64Thenlargest elements wheren=3and keeping the last duplicates.
Brunei will be kept since it is the last with value 434000 based on
the index order.>>>s.nlargest(3,keep='last')France      65000000Italy       59000000Brunei        434000dtype: int64Thenlargest elements wheren=3with all duplicates kept. Note
that the returned Series has five elements due to the three duplicates.>>>s.nlargest(3,keep='all')France      65000000Italy       59000000Malta         434000Maldives      434000Brunei        434000dtype: int64"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.nsmallest,"pandas.core.groupby.SeriesGroupBy.nsmallest#SeriesGroupBy.nsmallest(n=5,keep='first')[source]#Return the smallestnelements.Parameters:nint, default 5Return this many ascending sorted values.keep{‘first’, ‘last’, ‘all’}, default ‘first’When there are duplicate values that cannot all fit in a
Series ofnelements:first: return the firstnoccurrences in order
of appearance.last: return the lastnoccurrences in reverse
order of appearance.all: keep all occurrences. This can result in a Series of
size larger thann.Returns:SeriesThensmallest values in the Series, sorted in increasing order.See alsoSeries.nlargestGet thenlargest elements.Series.sort_valuesSort Series by values.Series.headReturn the firstnrows.NotesFaster than.sort_values().head(n)for smallnrelative to
the size of theSeriesobject.Examples>>>countries_population={""Italy"":59000000,""France"":65000000,...""Brunei"":434000,""Malta"":434000,...""Maldives"":434000,""Iceland"":337000,...""Nauru"":11300,""Tuvalu"":11300,...""Anguilla"":11300,""Montserrat"":5200}>>>s=pd.Series(countries_population)>>>sItaly       59000000France      65000000Brunei        434000Malta         434000Maldives      434000Iceland       337000Nauru          11300Tuvalu         11300Anguilla       11300Montserrat      5200dtype: int64Thensmallest elements wheren=5by default.>>>s.nsmallest()Montserrat    5200Nauru        11300Tuvalu       11300Anguilla     11300Iceland     337000dtype: int64Thensmallest elements wheren=3. Defaultkeepvalue is
‘first’ so Nauru and Tuvalu will be kept.>>>s.nsmallest(3)Montserrat   5200Nauru       11300Tuvalu      11300dtype: int64Thensmallest elements wheren=3and keeping the last
duplicates. Anguilla and Tuvalu will be kept since they are the last
with value 11300 based on the index order.>>>s.nsmallest(3,keep='last')Montserrat   5200Anguilla    11300Tuvalu      11300dtype: int64Thensmallest elements wheren=3with all duplicates kept. Note
that the returned Series has four elements due to the three duplicates.>>>s.nsmallest(3,keep='all')Montserrat   5200Nauru       11300Tuvalu      11300Anguilla    11300dtype: int64"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.nth,"pandas.core.groupby.SeriesGroupBy.nth#propertySeriesGroupBy.nth[source]#Take the nth row from each group if n is an int, otherwise a subset of rows.Can be either a call or an index. dropna is not available with index notation.
Index notation accepts a comma separated list of integers and slices.If dropna, will take the nth non-null row, dropna is either
‘all’ or ‘any’; this is equivalent to calling dropna(how=dropna)
before the groupby.Parameters:nint, slice or list of ints and slicesA single nth value for the row or a list of nth values or slices.Changed in version 1.4.0:Added slice and lists containing slices.
Added index notation.dropna{‘any’, ‘all’, None}, default NoneApply the specified dropna operation before counting which row is
the nth row. Only supported if n is an int.Returns:Series or DataFrameN-th value within each group.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.Examples>>>df=pd.DataFrame({'A':[1,1,2,1,2],...'B':[np.nan,2,3,4,5]},columns=['A','B'])>>>g=df.groupby('A')>>>g.nth(0)A   B0  1 NaN2  2 3.0>>>g.nth(1)A   B1  1 2.04  2 5.0>>>g.nth(-1)A   B3  1 4.04  2 5.0>>>g.nth([0,1])A   B0  1 NaN1  1 2.02  2 3.04  2 5.0>>>g.nth(slice(None,-1))A   B0  1 NaN1  1 2.02  2 3.0Index notation may also be used>>>g.nth[0,1]A   B0  1 NaN1  1 2.02  2 3.04  2 5.0>>>g.nth[:-1]A   B0  1 NaN1  1 2.02  2 3.0Specifyingdropnaallows ignoringNaNvalues>>>g.nth(0,dropna='any')A   B1  1 2.02  2 3.0When the specifiednis larger than any of the groups, an
empty DataFrame is returned>>>g.nth(3,dropna='any')Empty DataFrameColumns: [A, B]Index: []"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.nunique,"pandas.core.groupby.SeriesGroupBy.nunique#SeriesGroupBy.nunique(dropna=True)[source]#Return number of unique elements in the group.Returns:SeriesNumber of unique values within each group.ExamplesFor SeriesGroupby:>>>lst=['a','a','b','b']>>>ser=pd.Series([1,2,3,3],index=lst)>>>sera    1a    2b    3b    3dtype: int64>>>ser.groupby(level=0).nunique()a    2b    1dtype: int64For Resampler:>>>ser=pd.Series([1,2,3,3],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    3dtype: int64>>>ser.resample('MS').nunique()2023-01-01    22023-02-01    1Freq: MS, dtype: int64"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.unique,"pandas.core.groupby.SeriesGroupBy.unique#SeriesGroupBy.unique()[source]#Return unique values for each group.It returns unique values for each of the grouped values. Returned in
order of appearance. Hash table-based unique, therefore does NOT sort.Returns:SeriesUnique values for each of the grouped values.See alsoSeries.uniqueReturn unique values of Series object.Examples>>>df=pd.DataFrame([('Chihuahua','dog',6.1),...('Beagle','dog',15.2),...('Chihuahua','dog',6.9),...('Persian','cat',9.2),...('Chihuahua','dog',7),...('Persian','cat',8.8)],...columns=['breed','animal','height_in'])>>>dfbreed     animal   height_in0  Chihuahua        dog         6.11     Beagle        dog        15.22  Chihuahua        dog         6.93    Persian        cat         9.24  Chihuahua        dog         7.05    Persian        cat         8.8>>>ser=df.groupby('animal')['breed'].unique()>>>seranimalcat              [Persian]dog    [Chihuahua, Beagle]Name: breed, dtype: object"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.ohlc,"pandas.core.groupby.SeriesGroupBy.ohlc#SeriesGroupBy.ohlc()[source]#Compute open, high, low and close values of a group, excluding missing values.For multiple groupings, the result index will be a MultiIndexReturns:DataFrameOpen, high, low and close values within each group.ExamplesFor SeriesGroupBy:>>>lst=['SPX','CAC','SPX','CAC','SPX','CAC','SPX','CAC',]>>>ser=pd.Series([3.4,9.0,7.2,5.2,8.8,9.4,0.1,0.5],index=lst)>>>serSPX     3.4CAC     9.0SPX     7.2CAC     5.2SPX     8.8CAC     9.4SPX     0.1CAC     0.5dtype: float64>>>ser.groupby(level=0).ohlc()open  high  low  closeCAC   9.0   9.4  0.5    0.5SPX   3.4   8.8  0.1    0.1For DataFrameGroupBy:>>>data={2022:[1.2,2.3,8.9,4.5,4.4,3,2,1],...2023:[3.4,9.0,7.2,5.2,8.8,9.4,8.2,1.0]}>>>df=pd.DataFrame(data,index=['SPX','CAC','SPX','CAC',...'SPX','CAC','SPX','CAC'])>>>df2022  2023SPX   1.2   3.4CAC   2.3   9.0SPX   8.9   7.2CAC   4.5   5.2SPX   4.4   8.8CAC   3.0   9.4SPX   2.0   8.2CAC   1.0   1.0>>>df.groupby(level=0).ohlc()2022                 2023open high  low close open high  low closeCAC  2.3  4.5  1.0   1.0  9.0  9.4  1.0   1.0SPX  1.2  8.9  1.2   2.0  3.4  8.8  3.4   8.2For Resampler:>>>ser=pd.Series([1,3,2,4,3,5],...index=pd.DatetimeIndex(['2023-01-01',...'2023-01-10',...'2023-01-15',...'2023-02-01',...'2023-02-10',...'2023-02-15']))>>>ser.resample('MS').ohlc()open  high  low  close2023-01-01     1     3    1      22023-02-01     4     5    3      5"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.pct_change,"pandas.core.groupby.SeriesGroupBy.pct_change#SeriesGroupBy.pct_change(periods=1,fill_method=_NoDefault.no_default,limit=_NoDefault.no_default,freq=None,axis=_NoDefault.no_default)[source]#Calculate pct_change of each value to previous entry in group.Returns:Series or DataFramePercentage changes within each group.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b','b']>>>ser=pd.Series([1,2,3,4],index=lst)>>>sera    1a    2b    3b    4dtype: int64>>>ser.groupby(level=0).pct_change()a         NaNa    1.000000b         NaNb    0.333333dtype: float64For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[2,5,8],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""tuna"",""salmon"",""catfish"",""goldfish""])>>>dfa  b  ctuna   1  2  3salmon   1  5  6catfish   2  5  8goldfish   2  6  9>>>df.groupby(""a"").pct_change()b  ctuna    NaN    NaNsalmon    1.5  1.000catfish    NaN    NaNgoldfish    0.2  0.125"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.prod,"pandas.core.groupby.SeriesGroupBy.prod#SeriesGroupBy.prod(numeric_only=False,min_count=0)[source]#Compute prod of group values.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.Changed in version 2.0.0:numeric_only no longer acceptsNone.min_countint, default 0The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.Returns:Series or DataFrameComputed prod of values within each group.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b','b']>>>ser=pd.Series([1,2,3,4],index=lst)>>>sera    1a    2b    3b    4dtype: int64>>>ser.groupby(level=0).prod()a    2b   12dtype: int64For DataFrameGroupBy:>>>data=[[1,8,2],[1,2,5],[2,5,8],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""tiger"",""leopard"",""cheetah"",""lion""])>>>dfa  b  ctiger   1  8  2leopard   1  2  5cheetah   2  5  8lion   2  6  9>>>df.groupby(""a"").prod()b    ca1   16   102   30   72"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.quantile,"pandas.core.groupby.SeriesGroupBy.quantile#SeriesGroupBy.quantile(q=0.5,interpolation='linear',numeric_only=False)[source]#Return group values at the given quantile, a la numpy.percentile.Parameters:qfloat or array-like, default 0.5 (50% quantile)Value(s) between 0 and 1 providing the quantile(s) to compute.interpolation{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}Method to use when the desired quantile falls between two points.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:numeric_only now defaults toFalse.Returns:Series or DataFrameReturn type determined by caller of GroupBy object.See alsoSeries.quantileSimilar method for Series.DataFrame.quantileSimilar method for DataFrame.numpy.percentileNumPy method to compute qth percentile.Examples>>>df=pd.DataFrame([...['a',1],['a',2],['a',3],...['b',1],['b',3],['b',5]...],columns=['key','val'])>>>df.groupby('key').quantile()valkeya    2.0b    3.0"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.rank,"pandas.core.groupby.SeriesGroupBy.rank#SeriesGroupBy.rank(method='average',ascending=True,na_option='keep',pct=False,axis=_NoDefault.no_default)[source]#Provide the rank of values within each group.Parameters:method{‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’average: average rank of group.min: lowest rank in group.max: highest rank in group.first: ranks assigned in order they appear in the array.dense: like ‘min’, but rank always increases by 1 between groups.ascendingbool, default TrueFalse for ranks by high (1) to low (N).na_option{‘keep’, ‘top’, ‘bottom’}, default ‘keep’keep: leave NA values where they are.top: smallest rank if ascending.bottom: smallest rank if descending.pctbool, default FalseCompute percentage rank of data within each group.axisint, default 0The axis of the object over which to compute the rank.Deprecated since version 2.1.0:For axis=1, operate on the underlying object instead. Otherwise
the axis keyword is not necessary.Returns:DataFrame with ranking of values within each groupSee alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.Examples>>>df=pd.DataFrame(...{...""group"":[""a"",""a"",""a"",""a"",""a"",""b"",""b"",""b"",""b"",""b""],...""value"":[2,4,2,3,5,1,2,4,1,5],...}...)>>>dfgroup  value0     a      21     a      42     a      23     a      34     a      55     b      16     b      27     b      48     b      19     b      5>>>formethodin['average','min','max','dense','first']:...df[f'{method}_rank']=df.groupby('group')['value'].rank(method)>>>dfgroup  value  average_rank  min_rank  max_rank  dense_rank  first_rank0     a      2           1.5       1.0       2.0         1.0         1.01     a      4           4.0       4.0       4.0         3.0         4.02     a      2           1.5       1.0       2.0         1.0         2.03     a      3           3.0       3.0       3.0         2.0         3.04     a      5           5.0       5.0       5.0         4.0         5.05     b      1           1.5       1.0       2.0         1.0         1.06     b      2           3.0       3.0       3.0         2.0         3.07     b      4           4.0       4.0       4.0         3.0         4.08     b      1           1.5       1.0       2.0         1.0         2.09     b      5           5.0       5.0       5.0         4.0         5.0"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.resample,"pandas.core.groupby.SeriesGroupBy.resample#SeriesGroupBy.resample(rule,*args,**kwargs)[source]#Provide resampling when using a TimeGrouper.Given a grouper, the function resamples it according to a string
“string” -> “frequency”.See thefrequency aliasesdocumentation for more details.Parameters:rulestr or DateOffsetThe offset string or object representing target grouper conversion.*args, **kwargsPossible arguments arehow,fill_method,limit,kindandon, and other arguments ofTimeGrouper.Returns:pandas.api.typing.DatetimeIndexResamplerGroupby,pandas.api.typing.PeriodIndexResamplerGroupby, orpandas.api.typing.TimedeltaIndexResamplerGroupbyReturn a new groupby object, with type depending on the data
being resampled.See alsoGrouperSpecify a frequency to resample with when grouping by a key.DatetimeIndex.resampleFrequency conversion and resampling of time series.Examples>>>idx=pd.date_range('1/1/2000',periods=4,freq='T')>>>df=pd.DataFrame(data=4*[range(2)],...index=idx,...columns=['a','b'])>>>df.iloc[2,0]=5>>>dfa  b2000-01-01 00:00:00  0  12000-01-01 00:01:00  0  12000-01-01 00:02:00  5  12000-01-01 00:03:00  0  1Downsample the DataFrame into 3 minute bins and sum the values of
the timestamps falling into a bin.>>>df.groupby('a').resample('3T').sum()a  ba0   2000-01-01 00:00:00  0  22000-01-01 00:03:00  0  15   2000-01-01 00:00:00  5  1Upsample the series into 30 second bins.>>>df.groupby('a').resample('30S').sum()a  ba0   2000-01-01 00:00:00  0  12000-01-01 00:00:30  0  02000-01-01 00:01:00  0  12000-01-01 00:01:30  0  02000-01-01 00:02:00  0  02000-01-01 00:02:30  0  02000-01-01 00:03:00  0  15   2000-01-01 00:02:00  5  1Resample by month. Values are assigned to the month of the period.>>>df.groupby('a').resample('M').sum()a  ba0   2000-01-31  0  35   2000-01-31  5  1Downsample the series into 3 minute bins as above, but close the right
side of the bin interval.>>>df.groupby('a').resample('3T',closed='right').sum()a  ba0   1999-12-31 23:57:00  0  12000-01-01 00:00:00  0  25   2000-01-01 00:00:00  5  1Downsample the series into 3 minute bins and close the right side of
the bin interval, but label each bin using the right edge instead of
the left.>>>df.groupby('a').resample('3T',closed='right',label='right').sum()a  ba0   2000-01-01 00:00:00  0  12000-01-01 00:03:00  0  25   2000-01-01 00:03:00  5  1"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.rolling,"pandas.core.groupby.SeriesGroupBy.rolling#SeriesGroupBy.rolling(*args,**kwargs)[source]#Return a rolling grouper, providing rolling functionality per group.Parameters:windowint, timedelta, str, offset, or BaseIndexer subclassSize of the moving window.If an integer, the fixed number of observations used for
each window.If a timedelta, str, or offset, the time period of each window. Each
window will be a variable sized based on the observations included in
the time-period. This is only valid for datetimelike indexes.
To learn more about the offsets & frequency strings, please seethis link.If a BaseIndexer subclass, the window boundaries
based on the definedget_window_boundsmethod. Additional rolling
keyword arguments, namelymin_periods,center,closedandstepwill be passed toget_window_bounds.min_periodsint, default NoneMinimum number of observations in window required to have a value;
otherwise, result isnp.nan.For a window that is specified by an offset,min_periodswill default to 1.For a window that is specified by an integer,min_periodswill default
to the size of the window.centerbool, default FalseIf False, set the window labels as the right edge of the window index.If True, set the window labels as the center of the window index.win_typestr, default NoneIfNone, all points are evenly weighted.If a string, it must be a validscipy.signal window function.Certain Scipy window types require additional parameters to be passed
in the aggregation function. The additional parameters must match
the keywords specified in the Scipy window type method signature.onstr, optionalFor a DataFrame, a column label or Index level on which
to calculate the rolling window, rather than the DataFrame’s index.Provided integer column is ignored and excluded from result since
an integer index is not used to calculate the rolling window.axisint or str, default 0If0or'index', roll across the rows.If1or'columns', roll across the columns.ForSeriesthis parameter is unused and defaults to 0.closedstr, default NoneIf'right', the first point in the window is excluded from calculations.If'left', the last point in the window is excluded from calculations.If'both', no points in the window are excluded from calculations.If'neither', the first and last points in the window are excluded
from calculations.DefaultNone('right').methodstr {‘single’, ‘table’}, default ‘single’Execute the rolling operation per single column or row ('single')
or over the entire object ('table').This argument is only implemented when specifyingengine='numba'in the method call.Returns:pandas.api.typing.RollingGroupbyReturn a new grouper with our rolling appended.See alsoSeries.rollingCalling object with Series data.DataFrame.rollingCalling object with DataFrames.Series.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby.Examples>>>df=pd.DataFrame({'A':[1,1,2,2],...'B':[1,2,3,4],...'C':[0.362,0.227,1.267,-0.562]})>>>dfA  B      C0     1  1  0.3621     1  2  0.2272     2  3  1.2673     2  4 -0.562>>>df.groupby('A').rolling(2).sum()B      CA1 0  NaN    NaN1  3.0  0.5892 2  NaN    NaN3  7.0  0.705>>>df.groupby('A').rolling(2,min_periods=1).sum()B      CA1 0  1.0  0.3621  3.0  0.5892 2  3.0  1.2673  7.0  0.705>>>df.groupby('A').rolling(2,on='B').sum()B      CA1 0  1    NaN1  2  0.5892 2  3    NaN3  4  0.705"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.sample,"pandas.core.groupby.SeriesGroupBy.sample#SeriesGroupBy.sample(n=None,frac=None,replace=False,weights=None,random_state=None)[source]#Return a random sample of items from each group.You can userandom_statefor reproducibility.Parameters:nint, optionalNumber of items to return for each group. Cannot be used withfracand must be no larger than the smallest group unlessreplaceis True. Default is one iffracis None.fracfloat, optionalFraction of items to return. Cannot be used withn.replacebool, default FalseAllow or disallow sampling of the same row more than once.weightslist-like, optionalDefault None results in equal probability weighting.
If passed a list-like then values must have the same length as
the underlying DataFrame or Series object and will be used as
sampling probabilities after normalization within each group.
Values must be non-negative with at least one positive element
within each group.random_stateint, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optionalIf int, array-like, or BitGenerator, seed for random number generator.
If np.random.RandomState or np.random.Generator, use as given.Changed in version 1.4.0:np.random.Generator objects now acceptedReturns:Series or DataFrameA new object of same type as caller containing items randomly
sampled within each group from the caller object.See alsoDataFrame.sampleGenerate random samples from a DataFrame object.numpy.random.choiceGenerate a random sample from a given 1-D numpy array.Examples>>>df=pd.DataFrame(...{""a"":[""red""]*2+[""blue""]*2+[""black""]*2,""b"":range(6)}...)>>>dfa  b0    red  01    red  12   blue  23   blue  34  black  45  black  5Select one row at random for each distinct value in column a. Therandom_stateargument can be used to guarantee reproducibility:>>>df.groupby(""a"").sample(n=1,random_state=1)a  b4  black  42   blue  21    red  1Setfracto sample fixed proportions rather than counts:>>>df.groupby(""a"")[""b""].sample(frac=0.5,random_state=2)5    52    20    0Name: b, dtype: int64Control sample probabilities within groups by setting weights:>>>df.groupby(""a"").sample(...n=1,...weights=[1,1,1,0,0,1],...random_state=1,...)a  b5  black  52   blue  20    red  0"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.sem,"pandas.core.groupby.SeriesGroupBy.sem#SeriesGroupBy.sem(ddof=1,numeric_only=False)[source]#Compute standard error of the mean of groups, excluding missing values.For multiple groupings, the result index will be a MultiIndex.Parameters:ddofint, default 1Degrees of freedom.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:numeric_only now defaults toFalse.Returns:Series or DataFrameStandard error of the mean of values within each group.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b','b']>>>ser=pd.Series([5,10,8,14],index=lst)>>>sera     5a    10b     8b    14dtype: int64>>>ser.groupby(level=0).sem()a    2.5b    3.0dtype: float64For DataFrameGroupBy:>>>data=[[1,12,11],[1,15,2],[2,5,8],[2,6,12]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""tuna"",""salmon"",""catfish"",""goldfish""])>>>dfa   b   ctuna   1  12  11salmon   1  15   2catfish   2   5   8goldfish   2   6  12>>>df.groupby(""a"").sem()b  ca1    1.5  4.52    0.5  2.0For Resampler:>>>ser=pd.Series([1,3,2,4,3,8],...index=pd.DatetimeIndex(['2023-01-01',...'2023-01-10',...'2023-01-15',...'2023-02-01',...'2023-02-10',...'2023-02-15']))>>>ser.resample('MS').sem()2023-01-01    0.5773502023-02-01    1.527525Freq: MS, dtype: float64"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.shift,"pandas.core.groupby.SeriesGroupBy.shift#SeriesGroupBy.shift(periods=1,freq=None,axis=_NoDefault.no_default,fill_value=_NoDefault.no_default,suffix=None)[source]#Shift each group by periods observations.If freq is passed, the index will be increased using the periods and the freq.Parameters:periodsint | Sequence[int], default 1Number of periods to shift. If a list of values, shift each group by
each period.freqstr, optionalFrequency string.axisaxis to shift, default 0Shift direction.Deprecated since version 2.1.0:For axis=1, operate on the underlying object instead. Otherwise
the axis keyword is not necessary.fill_valueoptionalThe scalar value to use for newly introduced missing values.Changed in version 2.1.0:Will raise aValueErroriffreqis provided too.suffixstr, optionalA string to add to each shifted column if there are multiple periods.
Ignored otherwise.Returns:Series or DataFrameObject shifted within each group.See alsoIndex.shiftShift values of Index.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b','b']>>>ser=pd.Series([1,2,3,4],index=lst)>>>sera    1a    2b    3b    4dtype: int64>>>ser.groupby(level=0).shift(1)a    NaNa    1.0b    NaNb    3.0dtype: float64For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[2,5,8],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""tuna"",""salmon"",""catfish"",""goldfish""])>>>dfa  b  ctuna   1  2  3salmon   1  5  6catfish   2  5  8goldfish   2  6  9>>>df.groupby(""a"").shift(1)b    ctuna    NaN  NaNsalmon    2.0  3.0catfish    NaN  NaNgoldfish    5.0  8.0"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.size,"pandas.core.groupby.SeriesGroupBy.size#SeriesGroupBy.size()[source]#Compute group sizes.Returns:DataFrame or SeriesNumber of rows in each group as a Series if as_index is True
or a DataFrame if as_index is False.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,3],index=lst)>>>sera     1a     2b     3dtype: int64>>>ser.groupby(level=0).size()a    2b    1dtype: int64>>>data=[[1,2,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""owl"",""toucan"",""eagle""])>>>dfa  b  cowl     1  2  3toucan  1  5  6eagle   7  8  9>>>df.groupby(""a"").size()a1    27    1dtype: int64For Resampler:>>>ser=pd.Series([1,2,3],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01']))>>>ser2023-01-01    12023-01-15    22023-02-01    3dtype: int64>>>ser.resample('MS').size()2023-01-01    22023-02-01    1Freq: MS, dtype: int64"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.skew,"pandas.core.groupby.SeriesGroupBy.skew#SeriesGroupBy.skew(axis=_NoDefault.no_default,skipna=True,numeric_only=False,**kwargs)[source]#Return unbiased skew within groups.Normalized by N-1.Parameters:axis{0 or ‘index’, 1 or ‘columns’, None}, default 0Axis for the function to be applied on.
This parameter is only for compatibility with DataFrame and is unused.Deprecated since version 2.1.0:For axis=1, operate on the underlying object instead. Otherwise
the axis keyword is not necessary.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.**kwargsAdditional keyword arguments to be passed to the function.Returns:SeriesSee alsoSeries.skewReturn unbiased skew over requested axis.Examples>>>ser=pd.Series([390.,350.,357.,np.nan,22.,20.,30.],...index=['Falcon','Falcon','Falcon','Falcon',...'Parrot','Parrot','Parrot'],...name=""Max Speed"")>>>serFalcon    390.0Falcon    350.0Falcon    357.0Falcon      NaNParrot     22.0Parrot     20.0Parrot     30.0Name: Max Speed, dtype: float64>>>ser.groupby(level=0).skew()Falcon    1.525174Parrot    1.457863Name: Max Speed, dtype: float64>>>ser.groupby(level=0).skew(skipna=False)Falcon         NaNParrot    1.457863Name: Max Speed, dtype: float64"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.std,"pandas.core.groupby.SeriesGroupBy.std#SeriesGroupBy.std(ddof=1,engine=None,engine_kwargs=None,numeric_only=False)[source]#Compute standard deviation of groups, excluding missing values.For multiple groupings, the result index will be a MultiIndex.Parameters:ddofint, default 1Degrees of freedom.enginestr, default None'cython': Runs the operation through C-extensions from cython.'numba': Runs the operation through JIT compiled code from numba.None: Defaults to'cython'or globally settingcompute.use_numbaNew in version 1.4.0.engine_kwargsdict, default NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{{'nopython':True,'nogil':False,'parallel':False}}New in version 1.4.0.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:numeric_only now defaults toFalse.Returns:Series or DataFrameStandard deviation of values within each group.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','a','b','b','b']>>>ser=pd.Series([7,2,8,4,3,3],index=lst)>>>sera     7a     2a     8b     4b     3b     3dtype: int64>>>ser.groupby(level=0).std()a    3.21455b    0.57735dtype: float64For DataFrameGroupBy:>>>data={'a':[1,3,5,7,7,8,3],'b':[1,4,8,4,4,2,1]}>>>df=pd.DataFrame(data,index=['dog','dog','dog',...'mouse','mouse','mouse','mouse'])>>>dfa  bdog    1  1dog    3  4dog    5  8mouse    7  4mouse    7  4mouse    8  2mouse    3  1>>>df.groupby(level=0).std()a         bdog    2.000000  3.511885mouse  2.217356  1.500000"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.sum,"pandas.core.groupby.SeriesGroupBy.sum#SeriesGroupBy.sum(numeric_only=False,min_count=0,engine=None,engine_kwargs=None)[source]#Compute sum of group values.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.Changed in version 2.0.0:numeric_only no longer acceptsNone.min_countint, default 0The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.enginestr, default None None'cython': Runs rolling apply through C-extensions from cython.'numba'Runs rolling apply through JIT compiled code from numba.Only available whenrawis set toTrue.None: Defaults to'cython'or globally settingcompute.use_numbaengine_kwargsdict, default None NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{'nopython':True,'nogil':False,'parallel':False}and will be
applied to both thefuncand theapplygroupby aggregation.Returns:Series or DataFrameComputed sum of values within each group.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b','b']>>>ser=pd.Series([1,2,3,4],index=lst)>>>sera    1a    2b    3b    4dtype: int64>>>ser.groupby(level=0).sum()a    3b    7dtype: int64For DataFrameGroupBy:>>>data=[[1,8,2],[1,2,5],[2,5,8],[2,6,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""tiger"",""leopard"",""cheetah"",""lion""])>>>dfa  b  ctiger   1  8  2leopard   1  2  5cheetah   2  5  8lion   2  6  9>>>df.groupby(""a"").sum()b   ca1   10   72   11  17"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.var,"pandas.core.groupby.SeriesGroupBy.var#SeriesGroupBy.var(ddof=1,engine=None,engine_kwargs=None,numeric_only=False)[source]#Compute variance of groups, excluding missing values.For multiple groupings, the result index will be a MultiIndex.Parameters:ddofint, default 1Degrees of freedom.enginestr, default None'cython': Runs the operation through C-extensions from cython.'numba': Runs the operation through JIT compiled code from numba.None: Defaults to'cython'or globally settingcompute.use_numbaNew in version 1.4.0.engine_kwargsdict, default NoneFor'cython'engine, there are no acceptedengine_kwargsFor'numba'engine, the engine can acceptnopython,nogilandparalleldictionary keys. The values must either beTrueorFalse. The defaultengine_kwargsfor the'numba'engine is{{'nopython':True,'nogil':False,'parallel':False}}New in version 1.4.0.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:numeric_only now defaults toFalse.Returns:Series or DataFrameVariance of values within each group.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','a','b','b','b']>>>ser=pd.Series([7,2,8,4,3,3],index=lst)>>>sera     7a     2a     8b     4b     3b     3dtype: int64>>>ser.groupby(level=0).var()a    10.333333b     0.333333dtype: float64For DataFrameGroupBy:>>>data={'a':[1,3,5,7,7,8,3],'b':[1,4,8,4,4,2,1]}>>>df=pd.DataFrame(data,index=['dog','dog','dog',...'mouse','mouse','mouse','mouse'])>>>dfa  bdog    1  1dog    3  4dog    5  8mouse    7  4mouse    7  4mouse    8  2mouse    3  1>>>df.groupby(level=0).var()a          bdog    4.000000  12.333333mouse  4.916667   2.250000"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.tail,"pandas.core.groupby.SeriesGroupBy.tail#SeriesGroupBy.tail(n=5)[source]#Return last n rows of each group.Similar to.apply(lambdax:x.tail(n)), but it returns a subset of rows
from the original DataFrame with original index and order preserved
(as_indexflag is ignored).Parameters:nintIf positive: number of entries to include from end of each group.
If negative: number of entries to exclude from start of each group.Returns:Series or DataFrameSubset of original Series or DataFrame as determined by n.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.Examples>>>df=pd.DataFrame([['a',1],['a',2],['b',1],['b',2]],...columns=['A','B'])>>>df.groupby('A').tail(1)A  B1  a  23  b  2>>>df.groupby('A').tail(-1)A  B1  a  23  b  2"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.take,"pandas.core.groupby.SeriesGroupBy.take#SeriesGroupBy.take(indices,axis=_NoDefault.no_default,**kwargs)[source]#Return the elements in the givenpositionalindices in each group.This means that we are not indexing according to actual values in
the index attribute of the object. We are indexing according to the
actual position of the element in the object.If a requested index does not exist for some group, this method will raise.
To get similar behavior that ignores indices that don’t exist, seeSeriesGroupBy.nth().Parameters:indicesarray-likeAn array of ints indicating which positions to take in each group.axis{0 or ‘index’, 1 or ‘columns’, None}, default 0The axis on which to select elements.0means that we are
selecting rows,1means that we are selecting columns.
ForSeriesGroupBythis parameter is unused and defaults to 0.Deprecated since version 2.1.0:For axis=1, operate on the underlying object instead. Otherwise
the axis keyword is not necessary.**kwargsFor compatibility withnumpy.take(). Has no effect on the
output.Returns:SeriesA Series containing the elements taken from each group.See alsoSeries.takeTake elements from a Series along an axis.Series.locSelect a subset of a DataFrame by labels.Series.ilocSelect a subset of a DataFrame by positions.numpy.takeTake elements from an array along an axis.SeriesGroupBy.nthSimilar to take, won’t raise if indices don’t exist.Examples>>>df=pd.DataFrame([('falcon','bird',389.0),...('parrot','bird',24.0),...('lion','mammal',80.5),...('monkey','mammal',np.nan),...('rabbit','mammal',15.0)],...columns=['name','class','max_speed'],...index=[4,3,2,1,0])>>>dfname   class  max_speed4  falcon    bird      389.03  parrot    bird       24.02    lion  mammal       80.51  monkey  mammal        NaN0  rabbit  mammal       15.0>>>gb=df[""name""].groupby([1,1,2,2,2])Take elements at positions 0 and 1 along the axis 0 in each group (default).>>>gb.take([0,1])1  4    falcon3    parrot2  2      lion1    monkeyName: name, dtype: objectWe may take elements using negative integers for positive indices,
starting from the end of the object, just like with Python lists.>>>gb.take([-1,-2])1  3    parrot4    falcon2  0    rabbit1    monkeyName: name, dtype: object"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.value_counts,"pandas.core.groupby.SeriesGroupBy.value_counts#SeriesGroupBy.value_counts(normalize=False,sort=True,ascending=False,bins=None,dropna=True)[source]#"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.boxplot,"pandas.core.groupby.DataFrameGroupBy.boxplot#DataFrameGroupBy.boxplot(subplots=True,column=None,fontsize=None,rot=0,grid=True,ax=None,figsize=None,layout=None,sharex=False,sharey=True,backend=None,**kwargs)[source]#Make box plots from DataFrameGroupBy data.Parameters:groupedGrouped DataFramesubplotsboolFalse- no subplots will be usedTrue- create a subplot for each group.columncolumn name or list of names, or vectorCan be any valid input to groupby.fontsizefloat or strrotlabel rotation anglegridSetting this to True will show the gridaxMatplotlib axis object, default NonefigsizeA tuple (width, height) in incheslayouttuple (optional)The layout of the plot: (rows, columns).sharexbool, default FalseWhether x-axes will be shared among subplots.shareybool, default TrueWhether y-axes will be shared among subplots.backendstr, default NoneBackend to use instead of the backend specified in the optionplotting.backend. For instance, ‘matplotlib’. Alternatively, to
specify theplotting.backendfor the whole session, setpd.options.plotting.backend.**kwargsAll other plotting keyword arguments to be passed to
matplotlib’s boxplot function.Returns:dict of key/value = group key/DataFrame.boxplot return valueor DataFrame.boxplot return value in case subplots=figures=FalseExamplesYou can create boxplots for grouped data and show them as separate subplots:>>>importitertools>>>tuples=[tfortinitertools.product(range(1000),range(4))]>>>index=pd.MultiIndex.from_tuples(tuples,names=['lvl0','lvl1'])>>>data=np.random.randn(len(index),4)>>>df=pd.DataFrame(data,columns=list('ABCD'),index=index)>>>grouped=df.groupby(level='lvl1')>>>grouped.boxplot(rot=45,fontsize=12,figsize=(8,10))Thesubplots=Falseoption shows the boxplots in a single figure.>>>grouped.boxplot(subplots=False,rot=45,fontsize=12)"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.hist,"pandas.core.groupby.DataFrameGroupBy.hist#DataFrameGroupBy.hist(column=None,by=None,grid=True,xlabelsize=None,xrot=None,ylabelsize=None,yrot=None,ax=None,sharex=False,sharey=False,figsize=None,layout=None,bins=10,backend=None,legend=False,**kwargs)[source]#Make a histogram of the DataFrame’s columns.Ahistogramis a representation of the distribution of data.
This function callsmatplotlib.pyplot.hist(), on each series in
the DataFrame, resulting in one histogram per column.Parameters:dataDataFrameThe pandas object holding the data.columnstr or sequence, optionalIf passed, will be used to limit data to a subset of columns.byobject, optionalIf passed, then used to form histograms for separate groups.gridbool, default TrueWhether to show axis grid lines.xlabelsizeint, default NoneIf specified changes the x-axis label size.xrotfloat, default NoneRotation of x axis labels. For example, a value of 90 displays the
x labels rotated 90 degrees clockwise.ylabelsizeint, default NoneIf specified changes the y-axis label size.yrotfloat, default NoneRotation of y axis labels. For example, a value of 90 displays the
y labels rotated 90 degrees clockwise.axMatplotlib axes object, default NoneThe axes to plot the histogram on.sharexbool, default True if ax is None else FalseIn case subplots=True, share x axis and set some x axis labels to
invisible; defaults to True if ax is None otherwise False if an ax
is passed in.
Note that passing in both an ax and sharex=True will alter all x axis
labels for all subplots in a figure.shareybool, default FalseIn case subplots=True, share y axis and set some y axis labels to
invisible.figsizetuple, optionalThe size in inches of the figure to create. Uses the value inmatplotlib.rcParamsby default.layouttuple, optionalTuple of (rows, columns) for the layout of the histograms.binsint or sequence, default 10Number of histogram bins to be used. If an integer is given, bins + 1
bin edges are calculated and returned. If bins is a sequence, gives
bin edges, including left edge of first bin and right edge of last
bin. In this case, bins is returned unmodified.backendstr, default NoneBackend to use instead of the backend specified in the optionplotting.backend. For instance, ‘matplotlib’. Alternatively, to
specify theplotting.backendfor the whole session, setpd.options.plotting.backend.legendbool, default FalseWhether to show the legend.**kwargsAll other plotting keyword arguments to be passed tomatplotlib.pyplot.hist().Returns:matplotlib.AxesSubplot or numpy.ndarray of themSee alsomatplotlib.pyplot.histPlot a histogram using matplotlib.ExamplesThis example draws a histogram based on the length and width of
some animals, displayed in three bins>>>df=pd.DataFrame({...'length':[1.5,0.5,1.2,0.9,3],...'width':[0.7,0.2,0.15,0.2,1.1]...},index=['pig','rabbit','duck','chicken','horse'])>>>hist=df.hist(bins=3)"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.hist,"pandas.core.groupby.SeriesGroupBy.hist#SeriesGroupBy.hist(by=None,ax=None,grid=True,xlabelsize=None,xrot=None,ylabelsize=None,yrot=None,figsize=None,bins=10,backend=None,legend=False,**kwargs)[source]#Draw histogram of the input series using matplotlib.Parameters:byobject, optionalIf passed, then used to form histograms for separate groups.axmatplotlib axis objectIf not passed, uses gca().gridbool, default TrueWhether to show axis grid lines.xlabelsizeint, default NoneIf specified changes the x-axis label size.xrotfloat, default NoneRotation of x axis labels.ylabelsizeint, default NoneIf specified changes the y-axis label size.yrotfloat, default NoneRotation of y axis labels.figsizetuple, default NoneFigure size in inches by default.binsint or sequence, default 10Number of histogram bins to be used. If an integer is given, bins + 1
bin edges are calculated and returned. If bins is a sequence, gives
bin edges, including left edge of first bin and right edge of last
bin. In this case, bins is returned unmodified.backendstr, default NoneBackend to use instead of the backend specified in the optionplotting.backend. For instance, ‘matplotlib’. Alternatively, to
specify theplotting.backendfor the whole session, setpd.options.plotting.backend.legendbool, default FalseWhether to show the legend.**kwargsTo be passed to the actual plotting function.Returns:matplotlib.AxesSubplotA histogram plot.See alsomatplotlib.axes.Axes.histPlot a histogram using matplotlib.ExamplesFor Series:>>>lst=['a','a','a','b','b','b']>>>ser=pd.Series([1,2,2,4,6,6],index=lst)>>>hist=ser.hist()For Groupby:>>>lst=['a','a','a','b','b','b']>>>ser=pd.Series([1,2,2,4,6,6],index=lst)>>>hist=ser.groupby(level=0).hist()"
Pandas,GroupBy,pandas.core.groupby.DataFrameGroupBy.plot,"pandas.core.groupby.DataFrameGroupBy.plot#propertyDataFrameGroupBy.plot[source]#Make plots of Series or DataFrame.Uses the backend specified by the
optionplotting.backend. By default, matplotlib is used.Parameters:dataSeries or DataFrameThe object for which the method is called.xlabel or position, default NoneOnly used if data is a DataFrame.ylabel, position or list of label, positions, default NoneAllows plotting of one column versus another. Only used if data is a
DataFrame.kindstrThe kind of plot to produce:‘line’ : line plot (default)‘bar’ : vertical bar plot‘barh’ : horizontal bar plot‘hist’ : histogram‘box’ : boxplot‘kde’ : Kernel Density Estimation plot‘density’ : same as ‘kde’‘area’ : area plot‘pie’ : pie plot‘scatter’ : scatter plot (DataFrame only)‘hexbin’ : hexbin plot (DataFrame only)axmatplotlib axes object, default NoneAn axes of the current figure.subplotsbool or sequence of iterables, default FalseWhether to group columns into subplots:False: No subplots will be usedTrue: Make separate subplots for each column.sequence of iterables of column labels: Create a subplot for each
group of columns. For example[(‘a’, ‘c’), (‘b’, ‘d’)]will
create 2 subplots: one with columns ‘a’ and ‘c’, and one
with columns ‘b’ and ‘d’. Remaining columns that aren’t specified
will be plotted in additional subplots (one per column).New in version 1.5.0.sharexbool, default True if ax is None else FalseIn casesubplots=True, share x axis and set some x axis labels
to invisible; defaults to True if ax is None otherwise False if
an ax is passed in; Be aware, that passing in both an ax andsharex=Truewill alter all x axis labels for all axis in a figure.shareybool, default FalseIn casesubplots=True, share y axis and set some y axis labels to invisible.layouttuple, optional(rows, columns) for the layout of subplots.figsizea tuple (width, height) in inchesSize of a figure object.use_indexbool, default TrueUse index as ticks for x axis.titlestr or listTitle to use for the plot. If a string is passed, print the string
at the top of the figure. If a list is passed andsubplotsis
True, print each item in the list above the corresponding subplot.gridbool, default None (matlab style default)Axis grid lines.legendbool or {‘reverse’}Place legend on axis subplots.stylelist or dictThe matplotlib line style per column.logxbool or ‘sym’, default FalseUse log scaling or symlog scaling on x axis.logybool or ‘sym’ default FalseUse log scaling or symlog scaling on y axis.loglogbool or ‘sym’, default FalseUse log scaling or symlog scaling on both x and y axes.xtickssequenceValues to use for the xticks.ytickssequenceValues to use for the yticks.xlim2-tuple/listSet the x limits of the current axes.ylim2-tuple/listSet the y limits of the current axes.xlabellabel, optionalName to use for the xlabel on x-axis. Default uses index name as xlabel, or the
x-column name for planar plots.Changed in version 1.2.0:Now applicable to planar plots (scatter,hexbin).Changed in version 2.0.0:Now applicable to histograms.ylabellabel, optionalName to use for the ylabel on y-axis. Default will show no ylabel, or the
y-column name for planar plots.Changed in version 1.2.0:Now applicable to planar plots (scatter,hexbin).Changed in version 2.0.0:Now applicable to histograms.rotfloat, default NoneRotation for ticks (xticks for vertical, yticks for horizontal
plots).fontsizefloat, default NoneFont size for xticks and yticks.colormapstr or matplotlib colormap object, default NoneColormap to select colors from. If string, load colormap with that
name from matplotlib.colorbarbool, optionalIf True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’
plots).positionfloatSpecify relative alignments for bar plot layout.
From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5
(center).tablebool, Series or DataFrame, default FalseIf True, draw a table using the data in the DataFrame and the data
will be transposed to meet matplotlib’s default layout.
If a Series or DataFrame is passed, use passed data to draw a
table.yerrDataFrame, Series, array-like, dict and strSeePlotting with Error Barsfor
detail.xerrDataFrame, Series, array-like, dict and strEquivalent to yerr.stackedbool, default False in line and bar plots, and True in area plotIf True, create stacked plot.secondary_ybool or sequence, default FalseWhether to plot on the secondary y-axis if a list/tuple, which
columns to plot on secondary y-axis.mark_rightbool, default TrueWhen using a secondary_y axis, automatically mark the column
labels with “(right)” in the legend.include_boolbool, default is FalseIf True, boolean values can be plotted.backendstr, default NoneBackend to use instead of the backend specified in the optionplotting.backend. For instance, ‘matplotlib’. Alternatively, to
specify theplotting.backendfor the whole session, setpd.options.plotting.backend.**kwargsOptions to pass to matplotlib plotting method.Returns:matplotlib.axes.Axesor numpy.ndarray of themIf the backend is not the default matplotlib one, the return value
will be the object returned by the backend.NotesSee matplotlib documentation online for more on this subjectIfkind= ‘bar’ or ‘barh’, you can specify relative alignments
for bar plot layout bypositionkeyword.
From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5
(center)ExamplesFor Series:>>>ser=pd.Series([1,2,3,3])>>>plot=ser.plot(kind='hist',title=""My plot"")For DataFrame:>>>df=pd.DataFrame({'length':[1.5,0.5,1.2,0.9,3],...'width':[0.7,0.2,0.15,0.2,1.1]},...index=['pig','rabbit','duck','chicken','horse'])>>>plot=df.plot(title=""DataFrame Plot"")For SeriesGroupBy:>>>lst=[-1,-2,-3,1,2,3]>>>ser=pd.Series([1,2,2,4,6,6],index=lst)>>>plot=ser.groupby(lambdax:x>0).plot(title=""SeriesGroupBy Plot"")For DataFrameGroupBy:>>>df=pd.DataFrame({""col1"":[1,2,3,4],...""col2"":[""A"",""B"",""A"",""B""]})>>>plot=df.groupby(""col2"").plot(kind=""bar"",title=""DataFrameGroupBy Plot"")"
Pandas,GroupBy,pandas.core.groupby.SeriesGroupBy.plot,"pandas.core.groupby.SeriesGroupBy.plot#propertySeriesGroupBy.plot[source]#Make plots of Series or DataFrame.Uses the backend specified by the
optionplotting.backend. By default, matplotlib is used.Parameters:dataSeries or DataFrameThe object for which the method is called.xlabel or position, default NoneOnly used if data is a DataFrame.ylabel, position or list of label, positions, default NoneAllows plotting of one column versus another. Only used if data is a
DataFrame.kindstrThe kind of plot to produce:‘line’ : line plot (default)‘bar’ : vertical bar plot‘barh’ : horizontal bar plot‘hist’ : histogram‘box’ : boxplot‘kde’ : Kernel Density Estimation plot‘density’ : same as ‘kde’‘area’ : area plot‘pie’ : pie plot‘scatter’ : scatter plot (DataFrame only)‘hexbin’ : hexbin plot (DataFrame only)axmatplotlib axes object, default NoneAn axes of the current figure.subplotsbool or sequence of iterables, default FalseWhether to group columns into subplots:False: No subplots will be usedTrue: Make separate subplots for each column.sequence of iterables of column labels: Create a subplot for each
group of columns. For example[(‘a’, ‘c’), (‘b’, ‘d’)]will
create 2 subplots: one with columns ‘a’ and ‘c’, and one
with columns ‘b’ and ‘d’. Remaining columns that aren’t specified
will be plotted in additional subplots (one per column).New in version 1.5.0.sharexbool, default True if ax is None else FalseIn casesubplots=True, share x axis and set some x axis labels
to invisible; defaults to True if ax is None otherwise False if
an ax is passed in; Be aware, that passing in both an ax andsharex=Truewill alter all x axis labels for all axis in a figure.shareybool, default FalseIn casesubplots=True, share y axis and set some y axis labels to invisible.layouttuple, optional(rows, columns) for the layout of subplots.figsizea tuple (width, height) in inchesSize of a figure object.use_indexbool, default TrueUse index as ticks for x axis.titlestr or listTitle to use for the plot. If a string is passed, print the string
at the top of the figure. If a list is passed andsubplotsis
True, print each item in the list above the corresponding subplot.gridbool, default None (matlab style default)Axis grid lines.legendbool or {‘reverse’}Place legend on axis subplots.stylelist or dictThe matplotlib line style per column.logxbool or ‘sym’, default FalseUse log scaling or symlog scaling on x axis.logybool or ‘sym’ default FalseUse log scaling or symlog scaling on y axis.loglogbool or ‘sym’, default FalseUse log scaling or symlog scaling on both x and y axes.xtickssequenceValues to use for the xticks.ytickssequenceValues to use for the yticks.xlim2-tuple/listSet the x limits of the current axes.ylim2-tuple/listSet the y limits of the current axes.xlabellabel, optionalName to use for the xlabel on x-axis. Default uses index name as xlabel, or the
x-column name for planar plots.Changed in version 1.2.0:Now applicable to planar plots (scatter,hexbin).Changed in version 2.0.0:Now applicable to histograms.ylabellabel, optionalName to use for the ylabel on y-axis. Default will show no ylabel, or the
y-column name for planar plots.Changed in version 1.2.0:Now applicable to planar plots (scatter,hexbin).Changed in version 2.0.0:Now applicable to histograms.rotfloat, default NoneRotation for ticks (xticks for vertical, yticks for horizontal
plots).fontsizefloat, default NoneFont size for xticks and yticks.colormapstr or matplotlib colormap object, default NoneColormap to select colors from. If string, load colormap with that
name from matplotlib.colorbarbool, optionalIf True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’
plots).positionfloatSpecify relative alignments for bar plot layout.
From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5
(center).tablebool, Series or DataFrame, default FalseIf True, draw a table using the data in the DataFrame and the data
will be transposed to meet matplotlib’s default layout.
If a Series or DataFrame is passed, use passed data to draw a
table.yerrDataFrame, Series, array-like, dict and strSeePlotting with Error Barsfor
detail.xerrDataFrame, Series, array-like, dict and strEquivalent to yerr.stackedbool, default False in line and bar plots, and True in area plotIf True, create stacked plot.secondary_ybool or sequence, default FalseWhether to plot on the secondary y-axis if a list/tuple, which
columns to plot on secondary y-axis.mark_rightbool, default TrueWhen using a secondary_y axis, automatically mark the column
labels with “(right)” in the legend.include_boolbool, default is FalseIf True, boolean values can be plotted.backendstr, default NoneBackend to use instead of the backend specified in the optionplotting.backend. For instance, ‘matplotlib’. Alternatively, to
specify theplotting.backendfor the whole session, setpd.options.plotting.backend.**kwargsOptions to pass to matplotlib plotting method.Returns:matplotlib.axes.Axesor numpy.ndarray of themIf the backend is not the default matplotlib one, the return value
will be the object returned by the backend.NotesSee matplotlib documentation online for more on this subjectIfkind= ‘bar’ or ‘barh’, you can specify relative alignments
for bar plot layout bypositionkeyword.
From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5
(center)ExamplesFor Series:>>>ser=pd.Series([1,2,3,3])>>>plot=ser.plot(kind='hist',title=""My plot"")For DataFrame:>>>df=pd.DataFrame({'length':[1.5,0.5,1.2,0.9,3],...'width':[0.7,0.2,0.15,0.2,1.1]},...index=['pig','rabbit','duck','chicken','horse'])>>>plot=df.plot(title=""DataFrame Plot"")For SeriesGroupBy:>>>lst=[-1,-2,-3,1,2,3]>>>ser=pd.Series([1,2,2,4,6,6],index=lst)>>>plot=ser.groupby(lambdax:x>0).plot(title=""SeriesGroupBy Plot"")For DataFrameGroupBy:>>>df=pd.DataFrame({""col1"":[1,2,3,4],...""col2"":[""A"",""B"",""A"",""B""]})>>>plot=df.groupby(""col2"").plot(kind=""bar"",title=""DataFrameGroupBy Plot"")"
