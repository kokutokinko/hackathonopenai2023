ライブラリ名,章,節,内容
Pandas,Resampling,pandas.core.resample.Resampler.__iter__,"pandas.core.resample.Resampler.__iter__#Resampler.__iter__()[source]#Groupby iterator.Returns:Generator yielding sequence of (name, subsetted object)for each groupExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,3],index=lst)>>>sera    1a    2b    3dtype: int64>>>forx,yinser.groupby(level=0):...print(f'{x}\n{y}\n')aa    1a    2dtype: int64bb    3dtype: int64For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""])>>>dfa  b  c0  1  2  31  1  5  62  7  8  9>>>forx,yindf.groupby(by=[""a""]):...print(f'{x}\n{y}\n')(1,)a  b  c0  1  2  31  1  5  6(7,)a  b  c2  7  8  9For Resampler:>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>forx,yinser.resample('MS'):...print(f'{x}\n{y}\n')2023-01-01 00:00:002023-01-01    12023-01-15    2dtype: int642023-02-01 00:00:002023-02-01    32023-02-15    4dtype: int64"
Pandas,Resampling,pandas.core.resample.Resampler.groups,"pandas.core.resample.Resampler.groups#propertyResampler.groups[source]#Dict {group name -> group labels}.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,3],index=lst)>>>sera    1a    2b    3dtype: int64>>>ser.groupby(level=0).groups{'a': ['a', 'a'], 'b': ['b']}For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""])>>>dfa  b  c0  1  2  31  1  5  62  7  8  9>>>df.groupby(by=[""a""]).groups{1: [0, 1], 7: [2]}For Resampler:>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').groups{Timestamp('2023-01-01 00:00:00'): 2, Timestamp('2023-02-01 00:00:00'): 4}"
Pandas,Resampling,pandas.core.resample.Resampler.indices,"pandas.core.resample.Resampler.indices#propertyResampler.indices[source]#Dict {group name -> group indices}.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,3],index=lst)>>>sera    1a    2b    3dtype: int64>>>ser.groupby(level=0).indices{'a': array([0, 1]), 'b': array([2])}For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""owl"",""toucan"",""eagle""])>>>dfa  b  cowl     1  2  3toucan  1  5  6eagle   7  8  9>>>df.groupby(by=[""a""]).indices{1: array([0, 1]), 7: array([2])}For Resampler:>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').indicesdefaultdict(<class 'list'>, {Timestamp('2023-01-01 00:00:00'): [0, 1],Timestamp('2023-02-01 00:00:00'): [2, 3]})"
Pandas,Resampling,pandas.core.resample.Resampler.get_group,"pandas.core.resample.Resampler.get_group#Resampler.get_group(name,obj=None)[source]#Construct DataFrame from group with provided name.Parameters:nameobjectThe name of the group to get as a DataFrame.objDataFrame, default NoneThe DataFrame to take the DataFrame out of. If
it is None, the object groupby was called on will
be used.Deprecated since version 2.1.0:The obj is deprecated and will be removed in a future version.
Dodf.iloc[gb.indices.get(name)]instead ofgb.get_group(name,obj=df).Returns:same type as objExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,3],index=lst)>>>sera    1a    2b    3dtype: int64>>>ser.groupby(level=0).get_group(""a"")a    1a    2dtype: int64For DataFrameGroupBy:>>>data=[[1,2,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""owl"",""toucan"",""eagle""])>>>dfa  b  cowl     1  2  3toucan  1  5  6eagle   7  8  9>>>df.groupby(by=[""a""]).get_group(1)a  b  cowl     1  2  3toucan  1  5  6For Resampler:>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').get_group('2023-01-01')2023-01-01    12023-01-15    2dtype: int64"
Pandas,Resampling,pandas.core.resample.Resampler.apply,"pandas.core.resample.Resampler.apply#Resampler.apply(func=None,*args,**kwargs)[source]#Aggregate using one or more operations over the specified axis.Parameters:funcfunction, str, list or dictFunction to use for aggregating the data. If a function, must either
work when passed a DataFrame or when passed to DataFrame.apply.Accepted combinations are:functionstring function namelist of functions and/or function names, e.g.[np.sum,'mean']dict of axis labels -> functions, function names or list of such.*argsPositional arguments to pass tofunc.**kwargsKeyword arguments to pass tofunc.Returns:scalar, Series or DataFrameThe return can be:scalar : when Series.agg is called with single functionSeries : when DataFrame.agg is called with a single functionDataFrame : when DataFrame.agg is called with several functionsReturn scalar, Series or DataFrame.See alsoDataFrame.groupby.aggregateAggregate using callable, string, dict, or list of string/callables.DataFrame.resample.transformTransforms the Series on each group based on the given function.DataFrame.aggregateAggregate using one or more operations over the specified axis.NotesThe aggregation operations are always performed over an axis, either the
index (default) or the column axis. This behavior is different fromnumpyaggregation functions (mean,median,prod,sum,std,var), where the default is to compute the aggregation of the flattened
array, e.g.,numpy.mean(arr_2d)as opposed tonumpy.mean(arr_2d,axis=0).aggis an alias foraggregate. Use the alias.Functions that mutate the passed object can produce unexpected
behavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.A passed user-defined-function will be passed a Series for evaluation.Examples>>>s=pd.Series([1,2,3,4,5],...index=pd.date_range('20130101',periods=5,freq='s'))>>>s2013-01-01 00:00:00    12013-01-01 00:00:01    22013-01-01 00:00:02    32013-01-01 00:00:03    42013-01-01 00:00:04    5Freq: S, dtype: int64>>>r=s.resample('2s')>>>r.agg(""sum"")2013-01-01 00:00:00    32013-01-01 00:00:02    72013-01-01 00:00:04    5Freq: 2S, dtype: int64>>>r.agg(['sum','mean','max'])sum  mean  max2013-01-01 00:00:00    3   1.5    22013-01-01 00:00:02    7   3.5    42013-01-01 00:00:04    5   5.0    5>>>r.agg({'result':lambdax:x.mean()/x.std(),...'total':""sum""})result  total2013-01-01 00:00:00  2.121320      32013-01-01 00:00:02  4.949747      72013-01-01 00:00:04       NaN      5>>>r.agg(average=""mean"",total=""sum"")average  total2013-01-01 00:00:00      1.5      32013-01-01 00:00:02      3.5      72013-01-01 00:00:04      5.0      5"
Pandas,Resampling,pandas.core.resample.Resampler.aggregate,"pandas.core.resample.Resampler.aggregate#Resampler.aggregate(func=None,*args,**kwargs)[source]#Aggregate using one or more operations over the specified axis.Parameters:funcfunction, str, list or dictFunction to use for aggregating the data. If a function, must either
work when passed a DataFrame or when passed to DataFrame.apply.Accepted combinations are:functionstring function namelist of functions and/or function names, e.g.[np.sum,'mean']dict of axis labels -> functions, function names or list of such.*argsPositional arguments to pass tofunc.**kwargsKeyword arguments to pass tofunc.Returns:scalar, Series or DataFrameThe return can be:scalar : when Series.agg is called with single functionSeries : when DataFrame.agg is called with a single functionDataFrame : when DataFrame.agg is called with several functionsReturn scalar, Series or DataFrame.See alsoDataFrame.groupby.aggregateAggregate using callable, string, dict, or list of string/callables.DataFrame.resample.transformTransforms the Series on each group based on the given function.DataFrame.aggregateAggregate using one or more operations over the specified axis.NotesThe aggregation operations are always performed over an axis, either the
index (default) or the column axis. This behavior is different fromnumpyaggregation functions (mean,median,prod,sum,std,var), where the default is to compute the aggregation of the flattened
array, e.g.,numpy.mean(arr_2d)as opposed tonumpy.mean(arr_2d,axis=0).aggis an alias foraggregate. Use the alias.Functions that mutate the passed object can produce unexpected
behavior or errors and are not supported. SeeMutating with User Defined Function (UDF) methodsfor more details.A passed user-defined-function will be passed a Series for evaluation.Examples>>>s=pd.Series([1,2,3,4,5],...index=pd.date_range('20130101',periods=5,freq='s'))>>>s2013-01-01 00:00:00    12013-01-01 00:00:01    22013-01-01 00:00:02    32013-01-01 00:00:03    42013-01-01 00:00:04    5Freq: S, dtype: int64>>>r=s.resample('2s')>>>r.agg(""sum"")2013-01-01 00:00:00    32013-01-01 00:00:02    72013-01-01 00:00:04    5Freq: 2S, dtype: int64>>>r.agg(['sum','mean','max'])sum  mean  max2013-01-01 00:00:00    3   1.5    22013-01-01 00:00:02    7   3.5    42013-01-01 00:00:04    5   5.0    5>>>r.agg({'result':lambdax:x.mean()/x.std(),...'total':""sum""})result  total2013-01-01 00:00:00  2.121320      32013-01-01 00:00:02  4.949747      72013-01-01 00:00:04       NaN      5>>>r.agg(average=""mean"",total=""sum"")average  total2013-01-01 00:00:00      1.5      32013-01-01 00:00:02      3.5      72013-01-01 00:00:04      5.0      5"
Pandas,Resampling,pandas.core.resample.Resampler.transform,"pandas.core.resample.Resampler.transform#Resampler.transform(arg,*args,**kwargs)[source]#Call function producing a like-indexed Series on each group.Return a Series with the transformed values.Parameters:argfunctionTo apply to each group. Should return a Series with the same index.Returns:SeriesExamples>>>s=pd.Series([1,2],...index=pd.date_range('20180101',...periods=2,...freq='1h'))>>>s2018-01-01 00:00:00    12018-01-01 01:00:00    2Freq: H, dtype: int64>>>resampled=s.resample('15min')>>>resampled.transform(lambdax:(x-x.mean())/x.std())2018-01-01 00:00:00   NaN2018-01-01 01:00:00   NaNFreq: H, dtype: float64"
Pandas,Resampling,pandas.core.resample.Resampler.pipe,"pandas.core.resample.Resampler.pipe#Resampler.pipe(func,*args,**kwargs)[source]#Apply afuncwith arguments to this Resampler object and return its result.Use.pipewhen you want to improve readability by chaining together
functions that expect Series, DataFrames, GroupBy or Resampler objects.
Instead of writing>>>h(g(f(df.groupby('group')),arg1=a),arg2=b,arg3=c)You can write>>>(df.groupby('group')....pipe(f)....pipe(g,arg1=a)....pipe(h,arg2=b,arg3=c))which is much more readable.Parameters:funccallable or tuple of (callable, str)Function to apply to this Resampler object or, alternatively,
a(callable, data_keyword)tuple wheredata_keywordis a
string indicating the keyword ofcallablethat expects the
Resampler object.argsiterable, optionalPositional arguments passed intofunc.kwargsdict, optionalA dictionary of keyword arguments passed intofunc.Returns:the return type offunc.See alsoSeries.pipeApply a function with arguments to a series.DataFrame.pipeApply a function with arguments to a dataframe.applyApply function to each group instead of to the full Resampler object.NotesSee morehereExamples>>>df=pd.DataFrame({'A':[1,2,3,4]},...index=pd.date_range('2012-08-02',periods=4))>>>dfA2012-08-02  12012-08-03  22012-08-04  32012-08-05  4To get the difference between each 2-day period’s maximum and minimum
value in one pass, you can do>>>df.resample('2D').pipe(lambdax:x.max()-x.min())A2012-08-02  12012-08-04  1"
Pandas,Resampling,pandas.core.resample.Resampler.ffill,"pandas.core.resample.Resampler.ffill#Resampler.ffill(limit=None)[source]#Forward fill the values.Parameters:limitint, optionalLimit of how many values to fill.Returns:An upsampled Series.See alsoSeries.fillnaFill NA/NaN values using the specified method.DataFrame.fillnaFill NA/NaN values using the specified method.ExamplesHere we only create aSeries.>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64Example forffillwith downsampling (we have fewer dates after resampling):>>>ser.resample('MS').ffill()2023-01-01    12023-02-01    3Freq: MS, dtype: int64Example forffillwith upsampling (fill the new dates with
the previous value):>>>ser.resample('W').ffill()2023-01-01    12023-01-08    12023-01-15    22023-01-22    22023-01-29    22023-02-05    32023-02-12    32023-02-19    4Freq: W-SUN, dtype: int64With upsampling and limiting (only fill the first new date with the
previous value):>>>ser.resample('W').ffill(limit=1)2023-01-01    1.02023-01-08    1.02023-01-15    2.02023-01-22    2.02023-01-29    NaN2023-02-05    3.02023-02-12    NaN2023-02-19    4.0Freq: W-SUN, dtype: float64"
Pandas,Resampling,pandas.core.resample.Resampler.bfill,"pandas.core.resample.Resampler.bfill#Resampler.bfill(limit=None)[source]#Backward fill the new missing values in the resampled data.In statistics, imputation is the process of replacing missing data with
substituted values[1]. When resampling data, missing values may
appear (e.g., when the resampling frequency is higher than the original
frequency). The backward fill will replace NaN values that appeared in
the resampled data with the next value in the original sequence.
Missing values that existed in the original data will not be modified.Parameters:limitint, optionalLimit of how many values to fill.Returns:Series, DataFrameAn upsampled Series or DataFrame with backward filled NaN values.See alsobfillAlias of backfill.fillnaFill NaN values using the specified method, which can be ‘backfill’.nearestFill NaN values with nearest neighbor starting from center.ffillForward fill NaN values.Series.fillnaFill NaN values in the Series using the specified method, which can be ‘backfill’.DataFrame.fillnaFill NaN values in the DataFrame using the specified method, which can be ‘backfill’.References[1]https://en.wikipedia.org/wiki/Imputation_(statistics)ExamplesResampling a Series:>>>s=pd.Series([1,2,3],...index=pd.date_range('20180101',periods=3,freq='h'))>>>s2018-01-01 00:00:00    12018-01-01 01:00:00    22018-01-01 02:00:00    3Freq: H, dtype: int64>>>s.resample('30min').bfill()2018-01-01 00:00:00    12018-01-01 00:30:00    22018-01-01 01:00:00    22018-01-01 01:30:00    32018-01-01 02:00:00    3Freq: 30T, dtype: int64>>>s.resample('15min').bfill(limit=2)2018-01-01 00:00:00    1.02018-01-01 00:15:00    NaN2018-01-01 00:30:00    2.02018-01-01 00:45:00    2.02018-01-01 01:00:00    2.02018-01-01 01:15:00    NaN2018-01-01 01:30:00    3.02018-01-01 01:45:00    3.02018-01-01 02:00:00    3.0Freq: 15T, dtype: float64Resampling a DataFrame that has missing values:>>>df=pd.DataFrame({'a':[2,np.nan,6],'b':[1,3,5]},...index=pd.date_range('20180101',periods=3,...freq='h'))>>>dfa  b2018-01-01 00:00:00  2.0  12018-01-01 01:00:00  NaN  32018-01-01 02:00:00  6.0  5>>>df.resample('30min').bfill()a  b2018-01-01 00:00:00  2.0  12018-01-01 00:30:00  NaN  32018-01-01 01:00:00  NaN  32018-01-01 01:30:00  6.0  52018-01-01 02:00:00  6.0  5>>>df.resample('15min').bfill(limit=2)a    b2018-01-01 00:00:00  2.0  1.02018-01-01 00:15:00  NaN  NaN2018-01-01 00:30:00  NaN  3.02018-01-01 00:45:00  NaN  3.02018-01-01 01:00:00  NaN  3.02018-01-01 01:15:00  NaN  NaN2018-01-01 01:30:00  6.0  5.02018-01-01 01:45:00  6.0  5.02018-01-01 02:00:00  6.0  5.0"
Pandas,Resampling,pandas.core.resample.Resampler.nearest,"pandas.core.resample.Resampler.nearest#Resampler.nearest(limit=None)[source]#Resample by using the nearest value.When resampling data, missing values may appear (e.g., when the
resampling frequency is higher than the original frequency).
Thenearestmethod will replaceNaNvalues that appeared in
the resampled data with the value from the nearest member of the
sequence, based on the index value.
Missing values that existed in the original data will not be modified.
Iflimitis given, fill only this many values in each direction for
each of the original values.Parameters:limitint, optionalLimit of how many values to fill.Returns:Series or DataFrameAn upsampled Series or DataFrame withNaNvalues filled with
their nearest value.See alsobackfillBackward fill the new missing values in the resampled data.padForward fillNaNvalues.Examples>>>s=pd.Series([1,2],...index=pd.date_range('20180101',...periods=2,...freq='1h'))>>>s2018-01-01 00:00:00    12018-01-01 01:00:00    2Freq: H, dtype: int64>>>s.resample('15min').nearest()2018-01-01 00:00:00    12018-01-01 00:15:00    12018-01-01 00:30:00    22018-01-01 00:45:00    22018-01-01 01:00:00    2Freq: 15T, dtype: int64Limit the number of upsampled values imputed by the nearest:>>>s.resample('15min').nearest(limit=1)2018-01-01 00:00:00    1.02018-01-01 00:15:00    1.02018-01-01 00:30:00    NaN2018-01-01 00:45:00    2.02018-01-01 01:00:00    2.0Freq: 15T, dtype: float64"
Pandas,Resampling,pandas.core.resample.Resampler.fillna,"pandas.core.resample.Resampler.fillna#Resampler.fillna(method,limit=None)[source]#Fill missing values introduced by upsampling.In statistics, imputation is the process of replacing missing data with
substituted values[1]. When resampling data, missing values may
appear (e.g., when the resampling frequency is higher than the original
frequency).Missing values that existed in the original data will
not be modified.Parameters:method{‘pad’, ‘backfill’, ‘ffill’, ‘bfill’, ‘nearest’}Method to use for filling holes in resampled data‘pad’ or ‘ffill’: use previous valid observation to fill gap
(forward fill).‘backfill’ or ‘bfill’: use next valid observation to fill gap.‘nearest’: use nearest valid observation to fill gap.limitint, optionalLimit of how many consecutive missing values to fill.Returns:Series or DataFrameAn upsampled Series or DataFrame with missing values filled.See alsobfillBackward fill NaN values in the resampled data.ffillForward fill NaN values in the resampled data.nearestFill NaN values in the resampled data with nearest neighbor starting from center.interpolateFill NaN values using interpolation.Series.fillnaFill NaN values in the Series using the specified method, which can be ‘bfill’ and ‘ffill’.DataFrame.fillnaFill NaN values in the DataFrame using the specified method, which can be ‘bfill’ and ‘ffill’.References[1]https://en.wikipedia.org/wiki/Imputation_(statistics)ExamplesResampling a Series:>>>s=pd.Series([1,2,3],...index=pd.date_range('20180101',periods=3,freq='h'))>>>s2018-01-01 00:00:00    12018-01-01 01:00:00    22018-01-01 02:00:00    3Freq: H, dtype: int64Without filling the missing values you get:>>>s.resample(""30min"").asfreq()2018-01-01 00:00:00    1.02018-01-01 00:30:00    NaN2018-01-01 01:00:00    2.02018-01-01 01:30:00    NaN2018-01-01 02:00:00    3.0Freq: 30T, dtype: float64>>>s.resample('30min').fillna(""backfill"")2018-01-01 00:00:00    12018-01-01 00:30:00    22018-01-01 01:00:00    22018-01-01 01:30:00    32018-01-01 02:00:00    3Freq: 30T, dtype: int64>>>s.resample('15min').fillna(""backfill"",limit=2)2018-01-01 00:00:00    1.02018-01-01 00:15:00    NaN2018-01-01 00:30:00    2.02018-01-01 00:45:00    2.02018-01-01 01:00:00    2.02018-01-01 01:15:00    NaN2018-01-01 01:30:00    3.02018-01-01 01:45:00    3.02018-01-01 02:00:00    3.0Freq: 15T, dtype: float64>>>s.resample('30min').fillna(""pad"")2018-01-01 00:00:00    12018-01-01 00:30:00    12018-01-01 01:00:00    22018-01-01 01:30:00    22018-01-01 02:00:00    3Freq: 30T, dtype: int64>>>s.resample('30min').fillna(""nearest"")2018-01-01 00:00:00    12018-01-01 00:30:00    22018-01-01 01:00:00    22018-01-01 01:30:00    32018-01-01 02:00:00    3Freq: 30T, dtype: int64Missing values present before the upsampling are not affected.>>>sm=pd.Series([1,None,3],...index=pd.date_range('20180101',periods=3,freq='h'))>>>sm2018-01-01 00:00:00    1.02018-01-01 01:00:00    NaN2018-01-01 02:00:00    3.0Freq: H, dtype: float64>>>sm.resample('30min').fillna('backfill')2018-01-01 00:00:00    1.02018-01-01 00:30:00    NaN2018-01-01 01:00:00    NaN2018-01-01 01:30:00    3.02018-01-01 02:00:00    3.0Freq: 30T, dtype: float64>>>sm.resample('30min').fillna('pad')2018-01-01 00:00:00    1.02018-01-01 00:30:00    1.02018-01-01 01:00:00    NaN2018-01-01 01:30:00    NaN2018-01-01 02:00:00    3.0Freq: 30T, dtype: float64>>>sm.resample('30min').fillna('nearest')2018-01-01 00:00:00    1.02018-01-01 00:30:00    NaN2018-01-01 01:00:00    NaN2018-01-01 01:30:00    3.02018-01-01 02:00:00    3.0Freq: 30T, dtype: float64DataFrame resampling is done column-wise. All the same options are
available.>>>df=pd.DataFrame({'a':[2,np.nan,6],'b':[1,3,5]},...index=pd.date_range('20180101',periods=3,...freq='h'))>>>dfa  b2018-01-01 00:00:00  2.0  12018-01-01 01:00:00  NaN  32018-01-01 02:00:00  6.0  5>>>df.resample('30min').fillna(""bfill"")a  b2018-01-01 00:00:00  2.0  12018-01-01 00:30:00  NaN  32018-01-01 01:00:00  NaN  32018-01-01 01:30:00  6.0  52018-01-01 02:00:00  6.0  5"
Pandas,Resampling,pandas.core.resample.Resampler.asfreq,"pandas.core.resample.Resampler.asfreq#Resampler.asfreq(fill_value=None)[source]#Return the values at the new freq, essentially a reindex.Parameters:fill_valuescalar, optionalValue to use for missing values, applied during upsampling (note
this does not fill NaNs that already were present).Returns:DataFrame or SeriesValues at the specified freq.See alsoSeries.asfreqConvert TimeSeries to specified frequency.DataFrame.asfreqConvert TimeSeries to specified frequency.Examples>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-31','2023-02-01','2023-02-28']))>>>ser2023-01-01    12023-01-31    22023-02-01    32023-02-28    4dtype: int64>>>ser.resample('MS').asfreq()2023-01-01    12023-02-01    3Freq: MS, dtype: int64"
Pandas,Resampling,pandas.core.resample.Resampler.interpolate,"pandas.core.resample.Resampler.interpolate#Resampler.interpolate(method='linear',*,axis=0,limit=None,inplace=False,limit_direction='forward',limit_area=None,downcast=_NoDefault.no_default,**kwargs)[source]#Interpolate values between target timestamps according to different methods.The original index is first reindexed to target timestamps
(seecore.resample.Resampler.asfreq()),
then the interpolation ofNaNvalues via :meth`DataFrame.interpolate`
happens.Parameters:methodstr, default ‘linear’Interpolation technique to use. One of:‘linear’: Ignore the index and treat the values as equally
spaced. This is the only method supported on MultiIndexes.‘time’: Works on daily and higher resolution data to interpolate
given length of interval.‘index’, ‘values’: use the actual numerical values of the index.‘pad’: Fill in NaNs using existing values.‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,
‘barycentric’, ‘polynomial’: Passed toscipy.interpolate.interp1d, whereas ‘spline’ is passed toscipy.interpolate.UnivariateSpline. These methods use the numerical
values of the index. Both ‘polynomial’ and ‘spline’ require that
you also specify anorder(int), e.g.df.interpolate(method='polynomial',order=5). Note that,slinearmethod in Pandas refers to the Scipy first ordersplineinstead of Pandas first orderspline.‘krogh’, ‘piecewise_polynomial’, ‘spline’, ‘pchip’, ‘akima’,
‘cubicspline’: Wrappers around the SciPy interpolation methods of
similar names. SeeNotes.‘from_derivatives’: Refers toscipy.interpolate.BPoly.from_derivatives.axis{{0 or ‘index’, 1 or ‘columns’, None}}, default NoneAxis to interpolate along. ForSeriesthis parameter is unused
and defaults to 0.limitint, optionalMaximum number of consecutive NaNs to fill. Must be greater than
0.inplacebool, default FalseUpdate the data in place if possible.limit_direction{{‘forward’, ‘backward’, ‘both’}}, OptionalConsecutive NaNs will be filled in this direction.If limit is specified:If ‘method’ is ‘pad’ or ‘ffill’, ‘limit_direction’ must be ‘forward’.If ‘method’ is ‘backfill’ or ‘bfill’, ‘limit_direction’ must be
‘backwards’.If ‘limit’ is not specified:If ‘method’ is ‘backfill’ or ‘bfill’, the default is ‘backward’else the default is ‘forward’raises ValueError iflimit_directionis ‘forward’ or ‘both’ andmethod is ‘backfill’ or ‘bfill’.raises ValueError iflimit_directionis ‘backward’ or ‘both’ andmethod is ‘pad’ or ‘ffill’.limit_area{{None, ‘inside’, ‘outside’}}, default NoneIf limit is specified, consecutive NaNs will be filled with this
restriction.None: No fill restriction.‘inside’: Only fill NaNs surrounded by valid values
(interpolate).‘outside’: Only fill NaNs outside valid values (extrapolate).downcastoptional, ‘infer’ or None, defaults to NoneDowncast dtypes if possible.``**kwargs``optionalKeyword arguments to pass on to the interpolating function.Returns:DataFrame or SeriesInterpolated values at the specified freq.See alsocore.resample.Resampler.asfreqReturn the values at the new freq, essentially a reindex.DataFrame.interpolateFill NaN values using an interpolation method.NotesFor high-frequent or non-equidistant time-series with timestamps
the reindexing followed by interpolation may lead to information loss
as shown in the last example.Examples>>>importdatetimeasdt>>>timesteps=[...dt.datetime(2023,3,1,7,0,0),...dt.datetime(2023,3,1,7,0,1),...dt.datetime(2023,3,1,7,0,2),...dt.datetime(2023,3,1,7,0,3),...dt.datetime(2023,3,1,7,0,4)]>>>series=pd.Series(data=[1,-1,2,1,3],index=timesteps)>>>series2023-03-01 07:00:00    12023-03-01 07:00:01   -12023-03-01 07:00:02    22023-03-01 07:00:03    12023-03-01 07:00:04    3dtype: int64Upsample the dataframe to 0.5Hz by providing the period time of 2s.>>>series.resample(""2s"").interpolate(""linear"")2023-03-01 07:00:00    12023-03-01 07:00:02    22023-03-01 07:00:04    3Freq: 2S, dtype: int64Downsample the dataframe to 2Hz by providing the period time of 500ms.>>>series.resample(""500ms"").interpolate(""linear"")2023-03-01 07:00:00.000    1.02023-03-01 07:00:00.500    0.02023-03-01 07:00:01.000   -1.02023-03-01 07:00:01.500    0.52023-03-01 07:00:02.000    2.02023-03-01 07:00:02.500    1.52023-03-01 07:00:03.000    1.02023-03-01 07:00:03.500    2.02023-03-01 07:00:04.000    3.0Freq: 500L, dtype: float64Internal reindexing withas_freq()prior to interpolation leads to
an interpolated timeseries on the basis the reindexed timestamps (anchors).
Since not all datapoints from original series become anchors,
it can lead to misleading interpolation results as in the following example:>>>series.resample(""400ms"").interpolate(""linear"")2023-03-01 07:00:00.000    1.02023-03-01 07:00:00.400    1.22023-03-01 07:00:00.800    1.42023-03-01 07:00:01.200    1.62023-03-01 07:00:01.600    1.82023-03-01 07:00:02.000    2.02023-03-01 07:00:02.400    2.22023-03-01 07:00:02.800    2.42023-03-01 07:00:03.200    2.62023-03-01 07:00:03.600    2.82023-03-01 07:00:04.000    3.0Freq: 400L, dtype: float64Note that the series erroneously increases between two anchors07:00:00and07:00:02."
Pandas,Resampling,pandas.core.resample.Resampler.count,"pandas.core.resample.Resampler.count#Resampler.count()[source]#Compute count of group, excluding missing values.Returns:Series or DataFrameCount of values within each group.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,np.nan],index=lst)>>>sera    1.0a    2.0b    NaNdtype: float64>>>ser.groupby(level=0).count()a    2b    0dtype: int64For DataFrameGroupBy:>>>data=[[1,np.nan,3],[1,np.nan,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""cow"",""horse"",""bull""])>>>dfa         b     ccow     1       NaN     3horse   1       NaN     6bull    7       8.0     9>>>df.groupby(""a"").count()b   ca1   0   27   1   1For Resampler:>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').count()2023-01-01    22023-02-01    2Freq: MS, dtype: int64"
Pandas,Resampling,pandas.core.resample.Resampler.nunique,"pandas.core.resample.Resampler.nunique#Resampler.nunique(*args,**kwargs)[source]#Return number of unique elements in the group.Returns:SeriesNumber of unique values within each group.ExamplesFor SeriesGroupby:>>>lst=['a','a','b','b']>>>ser=pd.Series([1,2,3,3],index=lst)>>>sera    1a    2b    3b    3dtype: int64>>>ser.groupby(level=0).nunique()a    2b    1dtype: int64For Resampler:>>>ser=pd.Series([1,2,3,3],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    3dtype: int64>>>ser.resample('MS').nunique()2023-01-01    22023-02-01    1Freq: MS, dtype: int64"
Pandas,Resampling,pandas.core.resample.Resampler.first,"pandas.core.resample.Resampler.first#Resampler.first(numeric_only=False,min_count=0,*args,**kwargs)[source]#Compute the first non-null entry of each column.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.min_countint, default -1The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.Returns:Series or DataFrameFirst non-null of values within each group.See alsoDataFrame.groupbyApply a function groupby to each row or column of a DataFrame.pandas.core.groupby.DataFrameGroupBy.lastCompute the last non-null entry of each column.pandas.core.groupby.DataFrameGroupBy.nthTake the nth row from each group.Examples>>>df=pd.DataFrame(dict(A=[1,1,3],B=[None,5,6],C=[1,2,3],...D=['3/11/2000','3/12/2000','3/13/2000']))>>>df['D']=pd.to_datetime(df['D'])>>>df.groupby(""A"").first()B  C          DA1  5.0  1 2000-03-113  6.0  3 2000-03-13>>>df.groupby(""A"").first(min_count=2)B    C          DA1 NaN  1.0 2000-03-113 NaN  NaN        NaT>>>df.groupby(""A"").first(numeric_only=True)B  CA1  5.0  13  6.0  3"
Pandas,Resampling,pandas.core.resample.Resampler.last,"pandas.core.resample.Resampler.last#Resampler.last(numeric_only=False,min_count=0,*args,**kwargs)[source]#Compute the last non-null entry of each column.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns. If None, will attempt to use
everything, then use only numeric data.min_countint, default -1The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.Returns:Series or DataFrameLast non-null of values within each group.See alsoDataFrame.groupbyApply a function groupby to each row or column of a DataFrame.pandas.core.groupby.DataFrameGroupBy.firstCompute the first non-null entry of each column.pandas.core.groupby.DataFrameGroupBy.nthTake the nth row from each group.Examples>>>df=pd.DataFrame(dict(A=[1,1,3],B=[5,None,6],C=[1,2,3]))>>>df.groupby(""A"").last()B  CA1  5.0  23  6.0  3"
Pandas,Resampling,pandas.core.resample.Resampler.max,"pandas.core.resample.Resampler.max#Resampler.max(numeric_only=False,min_count=0,*args,**kwargs)[source]#Compute max value of group.Returns:Series or DataFrameExamples>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').max()2023-01-01    22023-02-01    4Freq: MS, dtype: int64"
Pandas,Resampling,pandas.core.resample.Resampler.mean,"pandas.core.resample.Resampler.mean#Resampler.mean(numeric_only=False,*args,**kwargs)[source]#Compute mean of groups, excluding missing values.Parameters:numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.Changed in version 2.0.0:numeric_only now defaults toFalse.Returns:DataFrame or SeriesMean of values within each group.Examples>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').mean()2023-01-01    1.52023-02-01    3.5Freq: MS, dtype: float64"
Pandas,Resampling,pandas.core.resample.Resampler.median,"pandas.core.resample.Resampler.median#Resampler.median(numeric_only=False,*args,**kwargs)[source]#Compute median of groups, excluding missing values.For multiple groupings, the result index will be a MultiIndexParameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.Changed in version 2.0.0:numeric_only no longer acceptsNoneand defaults to False.Returns:Series or DataFrameMedian of values within each group.ExamplesFor SeriesGroupBy:>>>lst=['a','a','a','b','b','b']>>>ser=pd.Series([7,2,8,4,3,3],index=lst)>>>sera     7a     2a     8b     4b     3b     3dtype: int64>>>ser.groupby(level=0).median()a    7.0b    3.0dtype: float64For DataFrameGroupBy:>>>data={'a':[1,3,5,7,7,8,3],'b':[1,4,8,4,4,2,1]}>>>df=pd.DataFrame(data,index=['dog','dog','dog',...'mouse','mouse','mouse','mouse'])>>>dfa  bdog    1  1dog    3  4dog    5  8mouse    7  4mouse    7  4mouse    8  2mouse    3  1>>>df.groupby(level=0).median()a    bdog    3.0  4.0mouse  7.0  3.0For Resampler:>>>ser=pd.Series([1,2,3,3,4,5],...index=pd.DatetimeIndex(['2023-01-01',...'2023-01-10',...'2023-01-15',...'2023-02-01',...'2023-02-10',...'2023-02-15']))>>>ser.resample('MS').median()2023-01-01    2.02023-02-01    4.0Freq: MS, dtype: float64"
Pandas,Resampling,pandas.core.resample.Resampler.min,"pandas.core.resample.Resampler.min#Resampler.min(numeric_only=False,min_count=0,*args,**kwargs)[source]#Compute min value of group.Returns:Series or DataFrameExamples>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').min()2023-01-01    12023-02-01    3Freq: MS, dtype: int64"
Pandas,Resampling,pandas.core.resample.Resampler.ohlc,"pandas.core.resample.Resampler.ohlc#Resampler.ohlc(*args,**kwargs)[source]#Compute open, high, low and close values of a group, excluding missing values.For multiple groupings, the result index will be a MultiIndexReturns:DataFrameOpen, high, low and close values within each group.ExamplesFor SeriesGroupBy:>>>lst=['SPX','CAC','SPX','CAC','SPX','CAC','SPX','CAC',]>>>ser=pd.Series([3.4,9.0,7.2,5.2,8.8,9.4,0.1,0.5],index=lst)>>>serSPX     3.4CAC     9.0SPX     7.2CAC     5.2SPX     8.8CAC     9.4SPX     0.1CAC     0.5dtype: float64>>>ser.groupby(level=0).ohlc()open  high  low  closeCAC   9.0   9.4  0.5    0.5SPX   3.4   8.8  0.1    0.1For DataFrameGroupBy:>>>data={2022:[1.2,2.3,8.9,4.5,4.4,3,2,1],...2023:[3.4,9.0,7.2,5.2,8.8,9.4,8.2,1.0]}>>>df=pd.DataFrame(data,index=['SPX','CAC','SPX','CAC',...'SPX','CAC','SPX','CAC'])>>>df2022  2023SPX   1.2   3.4CAC   2.3   9.0SPX   8.9   7.2CAC   4.5   5.2SPX   4.4   8.8CAC   3.0   9.4SPX   2.0   8.2CAC   1.0   1.0>>>df.groupby(level=0).ohlc()2022                 2023open high  low close open high  low closeCAC  2.3  4.5  1.0   1.0  9.0  9.4  1.0   1.0SPX  1.2  8.9  1.2   2.0  3.4  8.8  3.4   8.2For Resampler:>>>ser=pd.Series([1,3,2,4,3,5],...index=pd.DatetimeIndex(['2023-01-01',...'2023-01-10',...'2023-01-15',...'2023-02-01',...'2023-02-10',...'2023-02-15']))>>>ser.resample('MS').ohlc()open  high  low  close2023-01-01     1     3    1      22023-02-01     4     5    3      5"
Pandas,Resampling,pandas.core.resample.Resampler.prod,"pandas.core.resample.Resampler.prod#Resampler.prod(numeric_only=False,min_count=0,*args,**kwargs)[source]#Compute prod of group values.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.Changed in version 2.0.0:numeric_only no longer acceptsNone.min_countint, default 0The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.Returns:Series or DataFrameComputed prod of values within each group.Examples>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').prod()2023-01-01    22023-02-01   12Freq: MS, dtype: int64"
Pandas,Resampling,pandas.core.resample.Resampler.size,"pandas.core.resample.Resampler.size#Resampler.size()[source]#Compute group sizes.Returns:DataFrame or SeriesNumber of rows in each group as a Series if as_index is True
or a DataFrame if as_index is False.See alsoSeries.groupbyApply a function groupby to a Series.DataFrame.groupbyApply a function groupby to each row or column of a DataFrame.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b']>>>ser=pd.Series([1,2,3],index=lst)>>>sera     1a     2b     3dtype: int64>>>ser.groupby(level=0).size()a    2b    1dtype: int64>>>data=[[1,2,3],[1,5,6],[7,8,9]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""owl"",""toucan"",""eagle""])>>>dfa  b  cowl     1  2  3toucan  1  5  6eagle   7  8  9>>>df.groupby(""a"").size()a1    27    1dtype: int64For Resampler:>>>ser=pd.Series([1,2,3],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01']))>>>ser2023-01-01    12023-01-15    22023-02-01    3dtype: int64>>>ser.resample('MS').size()2023-01-01    22023-02-01    1Freq: MS, dtype: int64"
Pandas,Resampling,pandas.core.resample.Resampler.sem,"pandas.core.resample.Resampler.sem#Resampler.sem(ddof=1,numeric_only=False,*args,**kwargs)[source]#Compute standard error of the mean of groups, excluding missing values.For multiple groupings, the result index will be a MultiIndex.Parameters:ddofint, default 1Degrees of freedom.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:numeric_only now defaults toFalse.Returns:Series or DataFrameStandard error of the mean of values within each group.ExamplesFor SeriesGroupBy:>>>lst=['a','a','b','b']>>>ser=pd.Series([5,10,8,14],index=lst)>>>sera     5a    10b     8b    14dtype: int64>>>ser.groupby(level=0).sem()a    2.5b    3.0dtype: float64For DataFrameGroupBy:>>>data=[[1,12,11],[1,15,2],[2,5,8],[2,6,12]]>>>df=pd.DataFrame(data,columns=[""a"",""b"",""c""],...index=[""tuna"",""salmon"",""catfish"",""goldfish""])>>>dfa   b   ctuna   1  12  11salmon   1  15   2catfish   2   5   8goldfish   2   6  12>>>df.groupby(""a"").sem()b  ca1    1.5  4.52    0.5  2.0For Resampler:>>>ser=pd.Series([1,3,2,4,3,8],...index=pd.DatetimeIndex(['2023-01-01',...'2023-01-10',...'2023-01-15',...'2023-02-01',...'2023-02-10',...'2023-02-15']))>>>ser.resample('MS').sem()2023-01-01    0.5773502023-02-01    1.527525Freq: MS, dtype: float64"
Pandas,Resampling,pandas.core.resample.Resampler.std,"pandas.core.resample.Resampler.std#Resampler.std(ddof=1,numeric_only=False,*args,**kwargs)[source]#Compute standard deviation of groups, excluding missing values.Parameters:ddofint, default 1Degrees of freedom.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:numeric_only now defaults toFalse.Returns:DataFrame or SeriesStandard deviation of values within each group.Examples>>>ser=pd.Series([1,3,2,4,3,8],...index=pd.DatetimeIndex(['2023-01-01',...'2023-01-10',...'2023-01-15',...'2023-02-01',...'2023-02-10',...'2023-02-15']))>>>ser.resample('MS').std()2023-01-01    1.0000002023-02-01    2.645751Freq: MS, dtype: float64"
Pandas,Resampling,pandas.core.resample.Resampler.sum,"pandas.core.resample.Resampler.sum#Resampler.sum(numeric_only=False,min_count=0,*args,**kwargs)[source]#Compute sum of group values.Parameters:numeric_onlybool, default FalseInclude only float, int, boolean columns.Changed in version 2.0.0:numeric_only no longer acceptsNone.min_countint, default 0The required number of valid values to perform the operation. If fewer
thanmin_countnon-NA values are present the result will be NA.Returns:Series or DataFrameComputed sum of values within each group.Examples>>>ser=pd.Series([1,2,3,4],index=pd.DatetimeIndex(...['2023-01-01','2023-01-15','2023-02-01','2023-02-15']))>>>ser2023-01-01    12023-01-15    22023-02-01    32023-02-15    4dtype: int64>>>ser.resample('MS').sum()2023-01-01    32023-02-01    7Freq: MS, dtype: int64"
Pandas,Resampling,pandas.core.resample.Resampler.var,"pandas.core.resample.Resampler.var#Resampler.var(ddof=1,numeric_only=False,*args,**kwargs)[source]#Compute variance of groups, excluding missing values.Parameters:ddofint, default 1Degrees of freedom.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:numeric_only now defaults toFalse.Returns:DataFrame or SeriesVariance of values within each group.Examples>>>ser=pd.Series([1,3,2,4,3,8],...index=pd.DatetimeIndex(['2023-01-01',...'2023-01-10',...'2023-01-15',...'2023-02-01',...'2023-02-10',...'2023-02-15']))>>>ser.resample('MS').var()2023-01-01    1.02023-02-01    7.0Freq: MS, dtype: float64>>>ser.resample('MS').var(ddof=0)2023-01-01    0.6666672023-02-01    4.666667Freq: MS, dtype: float64"
Pandas,Resampling,pandas.core.resample.Resampler.quantile,"pandas.core.resample.Resampler.quantile#Resampler.quantile(q=0.5,**kwargs)[source]#Return value at the given quantile.Parameters:qfloat or array-like, default 0.5 (50% quantile)Returns:DataFrame or SeriesQuantile of values within each group.See alsoSeries.quantileReturn a series, where the index is q and the values are the quantiles.DataFrame.quantileReturn a DataFrame, where the columns are the columns of self, and the values are the quantiles.DataFrameGroupBy.quantileReturn a DataFrame, where the columns are groupby columns, and the values are its quantiles.Examples>>>ser=pd.Series([1,3,2,4,3,8],...index=pd.DatetimeIndex(['2023-01-01',...'2023-01-10',...'2023-01-15',...'2023-02-01',...'2023-02-10',...'2023-02-15']))>>>ser.resample('MS').quantile()2023-01-01    2.02023-02-01    4.0Freq: MS, dtype: float64>>>ser.resample('MS').quantile(.25)2023-01-01    1.52023-02-01    3.5Freq: MS, dtype: float64"
