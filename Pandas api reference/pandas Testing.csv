ライブラリ名,章,節,内容
Pandas,Testing,pandas.testing.assert_frame_equal,"pandas.testing.assert_frame_equal#pandas.testing.assert_frame_equal(left,right,check_dtype=True,check_index_type='equiv',check_column_type='equiv',check_frame_type=True,check_names=True,by_blocks=False,check_exact=False,check_datetimelike_compat=False,check_categorical=True,check_like=False,check_freq=True,check_flags=True,rtol=1e-05,atol=1e-08,obj='DataFrame')[source]#Check that left and right DataFrame are equal.This function is intended to compare two DataFrames and output any
differences. It is mostly intended for use in unit tests.
Additional parameters allow varying the strictness of the
equality checks performed.Parameters:leftDataFrameFirst DataFrame to compare.rightDataFrameSecond DataFrame to compare.check_dtypebool, default TrueWhether to check the DataFrame dtype is identical.check_index_typebool or {‘equiv’}, default ‘equiv’Whether to check the Index class, dtype and inferred_type
are identical.check_column_typebool or {‘equiv’}, default ‘equiv’Whether to check the columns class, dtype and inferred_type
are identical. Is passed as theexactargument ofassert_index_equal().check_frame_typebool, default TrueWhether to check the DataFrame class is identical.check_namesbool, default TrueWhether to check that thenamesattribute for both theindexandcolumnattributes of the DataFrame is identical.by_blocksbool, default FalseSpecify how to compare internal data. If False, compare by columns.
If True, compare by blocks.check_exactbool, default FalseWhether to compare number exactly.check_datetimelike_compatbool, default FalseCompare datetime-like which is comparable ignoring dtype.check_categoricalbool, default TrueWhether to compare internal Categorical exactly.check_likebool, default FalseIf True, ignore the order of index & columns.
Note: index labels must match their respective rows
(same as in columns) - same labels must be with the same data.check_freqbool, default TrueWhether to check thefreqattribute on a DatetimeIndex or TimedeltaIndex.check_flagsbool, default TrueWhether to check theflagsattribute.rtolfloat, default 1e-5Relative tolerance. Only used when check_exact is False.atolfloat, default 1e-8Absolute tolerance. Only used when check_exact is False.objstr, default ‘DataFrame’Specify object name being compared, internally used to show appropriate
assertion message.See alsoassert_series_equalEquivalent method for asserting Series equality.DataFrame.equalsCheck DataFrame equality.ExamplesThis example shows comparing two DataFrames that are equal
but with columns of differing dtypes.>>>frompandas.testingimportassert_frame_equal>>>df1=pd.DataFrame({'a':[1,2],'b':[3,4]})>>>df2=pd.DataFrame({'a':[1,2],'b':[3.0,4.0]})df1 equals itself.>>>assert_frame_equal(df1,df1)df1 differs from df2 as column ‘b’ is of a different type.>>>assert_frame_equal(df1,df2)Traceback (most recent call last):...AssertionError:Attributes of DataFrame.iloc[:, 1] (column name=""b"") are differentAttribute “dtype” are different
[left]: int64
[right]: float64Ignore differing dtypes in columns with check_dtype.>>>assert_frame_equal(df1,df2,check_dtype=False)"
Pandas,Testing,pandas.testing.assert_series_equal,"pandas.testing.assert_series_equal#pandas.testing.assert_series_equal(left,right,check_dtype=True,check_index_type='equiv',check_series_type=True,check_names=True,check_exact=False,check_datetimelike_compat=False,check_categorical=True,check_category_order=True,check_freq=True,check_flags=True,rtol=1e-05,atol=1e-08,obj='Series',*,check_index=True,check_like=False)[source]#Check that left and right Series are equal.Parameters:leftSeriesrightSeriescheck_dtypebool, default TrueWhether to check the Series dtype is identical.check_index_typebool or {‘equiv’}, default ‘equiv’Whether to check the Index class, dtype and inferred_type
are identical.check_series_typebool, default TrueWhether to check the Series class is identical.check_namesbool, default TrueWhether to check the Series and Index names attribute.check_exactbool, default FalseWhether to compare number exactly.check_datetimelike_compatbool, default FalseCompare datetime-like which is comparable ignoring dtype.check_categoricalbool, default TrueWhether to compare internal Categorical exactly.check_category_orderbool, default TrueWhether to compare category order of internal Categoricals.check_freqbool, default TrueWhether to check thefreqattribute on a DatetimeIndex or TimedeltaIndex.check_flagsbool, default TrueWhether to check theflagsattribute.New in version 1.2.0.rtolfloat, default 1e-5Relative tolerance. Only used when check_exact is False.atolfloat, default 1e-8Absolute tolerance. Only used when check_exact is False.objstr, default ‘Series’Specify object name being compared, internally used to show appropriate
assertion message.check_indexbool, default TrueWhether to check index equivalence. If False, then compare only values.New in version 1.3.0.check_likebool, default FalseIf True, ignore the order of the index. Must be False if check_index is False.
Note: same labels must be with the same data.New in version 1.5.0.Examples>>>frompandasimporttestingastm>>>a=pd.Series([1,2,3,4])>>>b=pd.Series([1,2,3,4])>>>tm.assert_series_equal(a,b)"
Pandas,Testing,pandas.testing.assert_index_equal,"pandas.testing.assert_index_equal#pandas.testing.assert_index_equal(left,right,exact='equiv',check_names=True,check_exact=True,check_categorical=True,check_order=True,rtol=1e-05,atol=1e-08,obj='Index')[source]#Check that left and right Index are equal.Parameters:leftIndexrightIndexexactbool or {‘equiv’}, default ‘equiv’Whether to check the Index class, dtype and inferred_type
are identical. If ‘equiv’, then RangeIndex can be substituted for
Index with an int64 dtype as well.check_namesbool, default TrueWhether to check the names attribute.check_exactbool, default TrueWhether to compare number exactly.check_categoricalbool, default TrueWhether to compare internal Categorical exactly.check_orderbool, default TrueWhether to compare the order of index entries as well as their values.
If True, both indexes must contain the same elements, in the same order.
If False, both indexes must contain the same elements, but in any order.New in version 1.2.0.rtolfloat, default 1e-5Relative tolerance. Only used when check_exact is False.atolfloat, default 1e-8Absolute tolerance. Only used when check_exact is False.objstr, default ‘Index’Specify object name being compared, internally used to show appropriate
assertion message.Examples>>>frompandasimporttestingastm>>>a=pd.Index([1,2,3])>>>b=pd.Index([1,2,3])>>>tm.assert_index_equal(a,b)"
Pandas,Testing,pandas.testing.assert_extension_array_equal,"pandas.testing.assert_extension_array_equal#pandas.testing.assert_extension_array_equal(left,right,check_dtype=True,index_values=None,check_exact=False,rtol=1e-05,atol=1e-08,obj='ExtensionArray')[source]#Check that left and right ExtensionArrays are equal.Parameters:left, rightExtensionArrayThe two arrays to compare.check_dtypebool, default TrueWhether to check if the ExtensionArray dtypes are identical.index_valuesnumpy.ndarray, default NoneOptional index (shared by both left and right), used in output.check_exactbool, default FalseWhether to compare number exactly.rtolfloat, default 1e-5Relative tolerance. Only used when check_exact is False.atolfloat, default 1e-8Absolute tolerance. Only used when check_exact is False.objstr, default ‘ExtensionArray’Specify object name being compared, internally used to show appropriate
assertion message.New in version 2.0.0.NotesMissing values are checked separately from valid values.
A mask of missing values is computed for each and checked to match.
The remaining all-valid values are cast to object dtype and checked.Examples>>>frompandasimporttestingastm>>>a=pd.Series([1,2,3,4])>>>b,c=a.array,a.array>>>tm.assert_extension_array_equal(b,c)"
Pandas,Testing,pandas.errors.AbstractMethodError,"pandas.errors.AbstractMethodError#exceptionpandas.errors.AbstractMethodError(class_instance,methodtype='method')[source]#Raise this error instead of NotImplementedError for abstract methods.Examples>>>classFoo:...@classmethod...defclassmethod(cls):...raisepd.errors.AbstractMethodError(cls,methodtype=""classmethod"")...defmethod(self):...raisepd.errors.AbstractMethodError(self)>>>test=Foo.classmethod()Traceback (most recent call last):AbstractMethodError:This classmethod must be defined in the concrete class Foo>>>test2=Foo().method()Traceback (most recent call last):AbstractMethodError:This classmethod must be defined in the concrete class Foo"
Pandas,Testing,pandas.errors.AttributeConflictWarning,"pandas.errors.AttributeConflictWarning#exceptionpandas.errors.AttributeConflictWarning[source]#Warning raised when index attributes conflict when using HDFStore.Occurs when attempting to append an index with a different
name than the existing index on an HDFStore or attempting to append an index with a
different frequency than the existing index on an HDFStore.Examples>>>idx1=pd.Index(['a','b'],name='name1')>>>df1=pd.DataFrame([[1,2],[3,4]],index=idx1)>>>df1.to_hdf('file','data','w',append=True)>>>idx2=pd.Index(['c','d'],name='name2')>>>df2=pd.DataFrame([[5,6],[7,8]],index=idx2)>>>df2.to_hdf('file','data','a',append=True)AttributeConflictWarning: the [index_name] attribute of the existing index is[name1] which conflicts with the new [name2]..."
Pandas,Testing,pandas.errors.CategoricalConversionWarning,"pandas.errors.CategoricalConversionWarning#exceptionpandas.errors.CategoricalConversionWarning[source]#Warning is raised when reading a partial labeled Stata file using a iterator.Examples>>>frompandas.io.stataimportStataReader>>>withStataReader('dta_file',chunksize=2)asreader:...fori,blockinenumerate(reader):...print(i,block)...# CategoricalConversionWarning: One or more series with value labels..."
Pandas,Testing,pandas.errors.ChainedAssignmentError,"pandas.errors.ChainedAssignmentError#exceptionpandas.errors.ChainedAssignmentError[source]#Warning raised when trying to set using chained assignment.When themode.copy_on_writeoption is enabled, chained assignment can
never work. In such a situation, we are always setting into a temporary
object that is the result of an indexing operation (getitem), which under
Copy-on-Write always behaves as a copy. Thus, assigning through a chain
can never update the original Series or DataFrame.For more information on view vs. copy,
seethe user guide.Examples>>>pd.options.mode.copy_on_write=True>>>df=pd.DataFrame({'A':[1,1,1,2,2]},columns=['A'])>>>df[""A""][0:3]=10...# ChainedAssignmentError: ...>>>pd.options.mode.copy_on_write=False"
Pandas,Testing,pandas.errors.ClosedFileError,"pandas.errors.ClosedFileError#exceptionpandas.errors.ClosedFileError[source]#Exception is raised when trying to perform an operation on a closed HDFStore file.Examples>>>store=pd.HDFStore('my-store','a')>>>store.close()>>>store.keys()...# ClosedFileError: my-store file is not open!"
Pandas,Testing,pandas.errors.CSSWarning,"pandas.errors.CSSWarning#exceptionpandas.errors.CSSWarning[source]#Warning is raised when converting css styling fails.This can be due to the styling not having an equivalent value or because the
styling isn’t properly formatted.Examples>>>df=pd.DataFrame({'A':[1,1,1]})>>>df.style.applymap(...lambdax:'background-color: blueGreenRed;'...).to_excel('styled.xlsx')CSSWarning: Unhandled color format: 'blueGreenRed'>>>df.style.applymap(...lambdax:'border: 1px solid red red;'...).to_excel('styled.xlsx')CSSWarning: Unhandled color format: 'blueGreenRed'"
Pandas,Testing,pandas.errors.DatabaseError,"pandas.errors.DatabaseError#exceptionpandas.errors.DatabaseError[source]#Error is raised when executing sql with bad syntax or sql that throws an error.Examples>>>fromsqlite3importconnect>>>conn=connect(':memory:')>>>pd.read_sql('select * test',conn)...# DatabaseError: Execution failed on sql 'test': near ""test"": syntax error"
Pandas,Testing,pandas.errors.DataError,"pandas.errors.DataError#exceptionpandas.errors.DataError[source]#Exceptionn raised when performing an operation on non-numerical data.For example, callingohlcon a non-numerical column or a function
on a rolling window.Examples>>>ser=pd.Series(['a','b','c'])>>>ser.rolling(2).sum()Traceback (most recent call last):DataError:No numeric types to aggregate"
Pandas,Testing,pandas.errors.DtypeWarning,"pandas.errors.DtypeWarning#exceptionpandas.errors.DtypeWarning[source]#Warning raised when reading different dtypes in a column from a file.Raised for a dtype incompatibility. This can happen wheneverread_csvorread_tableencounter non-uniform dtypes in a column(s) of a given
CSV file.See alsoread_csvRead CSV (comma-separated) file into a DataFrame.read_tableRead general delimited file into a DataFrame.NotesThis warning is issued when dealing with larger files because the dtype
checking happens per chunk read.Despite the warning, the CSV file is read with mixed types in a single
column which will be an object type. See the examples below to better
understand this issue.ExamplesThis example creates and reads a large CSV file with a column that containsintandstr.>>>df=pd.DataFrame({'a':(['1']*100000+['X']*100000+...['1']*100000),...'b':['b']*300000})>>>df.to_csv('test.csv',index=False)>>>df2=pd.read_csv('test.csv')...# DtypeWarning: Columns (0) have mixed typesImportant to notice thatdf2will contain bothstrandintfor the
same input, ‘1’.>>>df2.iloc[262140,0]'1'>>>type(df2.iloc[262140,0])<class 'str'>>>>df2.iloc[262150,0]1>>>type(df2.iloc[262150,0])<class 'int'>One way to solve this issue is using thedtypeparameter in theread_csvandread_tablefunctions to explicit the conversion:>>>df2=pd.read_csv('test.csv',sep=',',dtype={'a':str})No warning was issued."
Pandas,Testing,pandas.errors.DuplicateLabelError,"pandas.errors.DuplicateLabelError#exceptionpandas.errors.DuplicateLabelError[source]#Error raised when an operation would introduce duplicate labels.New in version 1.2.0.Examples>>>s=pd.Series([0,1,2],index=['a','b','c']).set_flags(...allows_duplicate_labels=False...)>>>s.reindex(['a','a','b'])Traceback (most recent call last):...DuplicateLabelError:Index has duplicates.positionslabela        [0, 1]"
Pandas,Testing,pandas.errors.EmptyDataError,pandas.errors.EmptyDataError#exceptionpandas.errors.EmptyDataError[source]#Exception raised inpd.read_csvwhen empty data or header is encountered.Examples>>>fromioimportStringIO>>>empty=StringIO()>>>pd.read_csv(empty)Traceback (most recent call last):EmptyDataError:No columns to parse from file
Pandas,Testing,pandas.errors.IncompatibilityWarning,pandas.errors.IncompatibilityWarning#exceptionpandas.errors.IncompatibilityWarning[source]#Warning raised when trying to use where criteria on an incompatible HDF5 file.
Pandas,Testing,pandas.errors.IndexingError,"pandas.errors.IndexingError#exceptionpandas.errors.IndexingError[source]#Exception is raised when trying to index and there is a mismatch in dimensions.Examples>>>df=pd.DataFrame({'A':[1,1,1]})>>>df.loc[...,...,'A']...# IndexingError: indexer may only contain one '...' entry>>>df=pd.DataFrame({'A':[1,1,1]})>>>df.loc[1,...,...]...# IndexingError: Too many indexers>>>df[pd.Series([True],dtype=bool)]...# IndexingError: Unalignable boolean Series provided as indexer...>>>s=pd.Series(range(2),...index=pd.MultiIndex.from_product([[""a"",""b""],[""c""]]))>>>s.loc[""a"",""c"",""d""]...# IndexingError: Too many indexers"
Pandas,Testing,pandas.errors.InvalidColumnName,"pandas.errors.InvalidColumnName#exceptionpandas.errors.InvalidColumnName[source]#Warning raised by to_stata the column contains a non-valid stata name.Because the column name is an invalid Stata variable, the name needs to be
converted.Examples>>>df=pd.DataFrame({""0categories"":pd.Series([2,2])})>>>df.to_stata('test')...# InvalidColumnName: Not all pandas column names were valid Stata variable..."
Pandas,Testing,pandas.errors.InvalidComparison,pandas.errors.InvalidComparison#exceptionpandas.errors.InvalidComparison[source]#Exception is raised by _validate_comparison_value to indicate an invalid comparison.NotesThis is an internal error.
Pandas,Testing,pandas.errors.InvalidIndexError,"pandas.errors.InvalidIndexError#exceptionpandas.errors.InvalidIndexError[source]#Exception raised when attempting to use an invalid index key.Examples>>>idx=pd.MultiIndex.from_product([[""x"",""y""],[0,1]])>>>df=pd.DataFrame([[1,1,2,2],...[3,3,4,4]],columns=idx)>>>dfx       y0   1   0   10   1   1   2   21   3   3   4   4>>>df[:,0]Traceback (most recent call last):InvalidIndexError:(slice(None, None, None), 0)"
Pandas,Testing,pandas.errors.InvalidVersion,"pandas.errors.InvalidVersion#exceptionpandas.errors.InvalidVersion[source]#An invalid version was found, users should refer to PEP 440.Examples>>>pd.util.version.Version('1.')Traceback (most recent call last):InvalidVersion:Invalid version: '1.'"
Pandas,Testing,pandas.errors.IntCastingNaNError,"pandas.errors.IntCastingNaNError#exceptionpandas.errors.IntCastingNaNError[source]#Exception raised when converting (astype) an array with NaN to an integer type.Examples>>>pd.DataFrame(np.array([[1,np.nan],[2,3]]),dtype=""i8"")Traceback (most recent call last):IntCastingNaNError:Cannot convert non-finite values (NA or inf) to integer"
Pandas,Testing,pandas.errors.LossySetitemError,pandas.errors.LossySetitemError#exceptionpandas.errors.LossySetitemError[source]#Raised when trying to do a __setitem__ on an np.ndarray that is not lossless.NotesThis is an internal error.
Pandas,Testing,pandas.errors.MergeError,"pandas.errors.MergeError#exceptionpandas.errors.MergeError[source]#Exception raised when merging data.Subclass ofValueError.Examples>>>left=pd.DataFrame({""a"":[""a"",""b"",""b"",""d""],...""b"":[""cat"",""dog"",""weasel"",""horse""]},...index=range(4))>>>right=pd.DataFrame({""a"":[""a"",""b"",""c"",""d""],...""c"":[""meow"",""bark"",""chirp"",""nay""]},...index=range(4)).set_index(""a"")>>>left.join(right,on=""a"",validate=""one_to_one"",)Traceback (most recent call last):MergeError:Merge keys are not unique in left dataset; not a one-to-one merge"
Pandas,Testing,pandas.errors.NoBufferPresent,pandas.errors.NoBufferPresent#exceptionpandas.errors.NoBufferPresent[source]#Exception is raised in _get_data_buffer to signal that there is no requested buffer.
Pandas,Testing,pandas.errors.NullFrequencyError,"pandas.errors.NullFrequencyError#exceptionpandas.errors.NullFrequencyError[source]#Exception raised when afreqcannot be null.ParticularlyDatetimeIndex.shift,TimedeltaIndex.shift,PeriodIndex.shift.Examples>>>df=pd.DatetimeIndex([""2011-01-01 10:00"",""2011-01-01""],freq=None)>>>df.shift(2)Traceback (most recent call last):NullFrequencyError:Cannot shift with no freq"
Pandas,Testing,pandas.errors.NumbaUtilError,"pandas.errors.NumbaUtilError#exceptionpandas.errors.NumbaUtilError[source]#Error raised for unsupported Numba engine routines.Examples>>>df=pd.DataFrame({""key"":[""a"",""a"",""b"",""b""],""data"":[1,2,3,4]},...columns=[""key"",""data""])>>>defincorrect_function(x):...returnsum(x)*2.7>>>df.groupby(""key"").agg(incorrect_function,engine=""numba"")Traceback (most recent call last):NumbaUtilError:The first 2 arguments to incorrect_functionmust be ['values', 'index']"
Pandas,Testing,pandas.errors.NumExprClobberingError,"pandas.errors.NumExprClobberingError#exceptionpandas.errors.NumExprClobberingError[source]#Exception raised when trying to use a built-in numexpr name as a variable name.evalorquerywill throw the error if the engine is set
to ‘numexpr’. ‘numexpr’ is the default engine value for these methods if the
numexpr package is installed.Examples>>>df=pd.DataFrame({'abs':[1,1,1]})>>>df.query(""abs > 2"")...# NumExprClobberingError: Variables in expression ""(abs) > (2)"" overlap...>>>sin,a=1,2>>>pd.eval(""sin + a"",engine='numexpr')...# NumExprClobberingError: Variables in expression ""(sin) + (a)"" overlap..."
Pandas,Testing,pandas.errors.OptionError,pandas.errors.OptionError#exceptionpandas.errors.OptionError[source]#Exception raised for pandas.options.Backwards compatible with KeyError checks.Examples>>>pd.options.contextTraceback (most recent call last):OptionError:No such option
Pandas,Testing,pandas.errors.OutOfBoundsDatetime,"pandas.errors.OutOfBoundsDatetime#exceptionpandas.errors.OutOfBoundsDatetime#Raised when the datetime is outside the range that can be represented.Examples>>>pd.to_datetime(""08335394550"")Traceback (most recent call last):OutOfBoundsDatetime:Parsing ""08335394550"" to datetime overflows,at position 0"
Pandas,Testing,pandas.errors.OutOfBoundsTimedelta,"pandas.errors.OutOfBoundsTimedelta#exceptionpandas.errors.OutOfBoundsTimedelta#Raised when encountering a timedelta value that cannot be represented.Representation should be within a timedelta64[ns].Examples>>>pd.date_range(start=""1/1/1700"",freq=""B"",periods=100000)Traceback (most recent call last):OutOfBoundsTimedelta:Cannot cast 139999 days 00:00:00to unit='ns' without overflow."
Pandas,Testing,pandas.errors.ParserError,"pandas.errors.ParserError#exceptionpandas.errors.ParserError[source]#Exception that is raised by an error encountered in parsing file contents.This is a generic error raised for errors encountered when functions likeread_csvorread_htmlare parsing contents of a file.See alsoread_csvRead CSV (comma-separated) file into a DataFrame.read_htmlRead HTML table into a DataFrame.Examples>>>data='''a,b,c...cat,foo,bar...dog,foo,""baz'''>>>fromioimportStringIO>>>pd.read_csv(StringIO(data),skipfooter=1,engine='python')Traceback (most recent call last):ParserError:',' expected after '""'. Error could possibly be dueto parsing errors in the skipped footer rows"
Pandas,Testing,pandas.errors.ParserWarning,"pandas.errors.ParserWarning#exceptionpandas.errors.ParserWarning[source]#Warning raised when reading a file that doesn’t use the default ‘c’ parser.Raised bypd.read_csvandpd.read_tablewhen it is necessary to change
parsers, generally from the default ‘c’ parser to ‘python’.It happens due to a lack of support or functionality for parsing a
particular attribute of a CSV file with the requested engine.Currently, ‘c’ unsupported options include the following parameters:sepother than a single character (e.g. regex separators)skipfooterhigher than 0sep=Nonewithdelim_whitespace=FalseThe warning can be avoided by addingengine=’python’as a parameter inpd.read_csvandpd.read_tablemethods.See alsopd.read_csvRead CSV (comma-separated) file into DataFrame.pd.read_tableRead general delimited file into DataFrame.ExamplesUsing asepinpd.read_csvother than a single character:>>>importio>>>csv='''a;b;c...1;1,8...1;2,1'''>>>df=pd.read_csv(io.StringIO(csv),sep='[;,]')...# ParserWarning: Falling back to the 'python' engine...Addingengine=’python’topd.read_csvremoves the Warning:>>>df=pd.read_csv(io.StringIO(csv),sep='[;,]',engine='python')"
Pandas,Testing,pandas.errors.PerformanceWarning,"pandas.errors.PerformanceWarning#exceptionpandas.errors.PerformanceWarning[source]#Warning raised when there is a possible performance impact.Examples>>>df=pd.DataFrame({""jim"":[0,0,1,1],...""joe"":[""x"",""x"",""z"",""y""],...""jolie"":[1,2,3,4]})>>>df=df.set_index([""jim"",""joe""])>>>dfjoliejim  joe0    x    1x    21    z    3y    4>>>df.loc[(1,'z')]# PerformanceWarning: indexing past lexsort depth may impact performance.df.loc[(1, 'z')]joliejim  joe1    z        3"
Pandas,Testing,pandas.errors.PossibleDataLossError,"pandas.errors.PossibleDataLossError#exceptionpandas.errors.PossibleDataLossError[source]#Exception raised when trying to open a HDFStore file when already opened.Examples>>>store=pd.HDFStore('my-store','a')>>>store.open(""w"")...# PossibleDataLossError: Re-opening the file [my-store] with mode [a]..."
Pandas,Testing,pandas.errors.PossiblePrecisionLoss,"pandas.errors.PossiblePrecisionLoss#exceptionpandas.errors.PossiblePrecisionLoss[source]#Warning raised by to_stata on a column with a value outside or equal to int64.When the column value is outside or equal to the int64 value the column is
converted to a float64 dtype.Examples>>>df=pd.DataFrame({""s"":pd.Series([1,2**53],dtype=np.int64)})>>>df.to_stata('test')...# PossiblePrecisionLoss: Column converted from int64 to float64..."
Pandas,Testing,pandas.errors.PyperclipException,pandas.errors.PyperclipException#exceptionpandas.errors.PyperclipException[source]#Exception raised when clipboard functionality is unsupported.Raised byto_clipboard()andread_clipboard().
Pandas,Testing,pandas.errors.PyperclipWindowsException,"pandas.errors.PyperclipWindowsException#exceptionpandas.errors.PyperclipWindowsException(message)[source]#Exception raised when clipboard functionality is unsupported by Windows.Access to the clipboard handle would be denied due to some other
window process is accessing it."
Pandas,Testing,pandas.errors.SettingWithCopyError,"pandas.errors.SettingWithCopyError#exceptionpandas.errors.SettingWithCopyError[source]#Exception raised when trying to set on a copied slice from aDataFrame.Themode.chained_assignmentneeds to be set to set to ‘raise.’ This can
happen unintentionally when chained indexing.For more information on evaluation order,
seethe user guide.For more information on view vs. copy,
seethe user guide.Examples>>>pd.options.mode.chained_assignment='raise'>>>df=pd.DataFrame({'A':[1,1,1,2,2]},columns=['A'])>>>df.loc[0:3]['A']='a'...# SettingWithCopyError: A value is trying to be set on a copy of a..."
Pandas,Testing,pandas.errors.SettingWithCopyWarning,"pandas.errors.SettingWithCopyWarning#exceptionpandas.errors.SettingWithCopyWarning[source]#Warning raised when trying to set on a copied slice from aDataFrame.Themode.chained_assignmentneeds to be set to set to ‘warn.’
‘Warn’ is the default option. This can happen unintentionally when
chained indexing.For more information on evaluation order,
seethe user guide.For more information on view vs. copy,
seethe user guide.Examples>>>df=pd.DataFrame({'A':[1,1,1,2,2]},columns=['A'])>>>df.loc[0:3]['A']='a'...# SettingWithCopyWarning: A value is trying to be set on a copy of a..."
Pandas,Testing,pandas.errors.SpecificationError,"pandas.errors.SpecificationError#exceptionpandas.errors.SpecificationError[source]#Exception raised byaggwhen the functions are ill-specified.The exception raised in two scenarios.The first way is callingaggon a
Dataframe or Series using a nested renamer (dict-of-dict).The second way is callingaggon a Dataframe with duplicated functions
names without assigning column name.Examples>>>df=pd.DataFrame({'A':[1,1,1,2,2],...'B':range(5),...'C':range(5)})>>>df.groupby('A').B.agg({'foo':'count'})...# SpecificationError: nested renamer is not supported>>>df.groupby('A').agg({'B':{'foo':['sum','max']}})...# SpecificationError: nested renamer is not supported>>>df.groupby('A').agg(['min','min'])...# SpecificationError: nested renamer is not supported"
Pandas,Testing,pandas.errors.UndefinedVariableError,"pandas.errors.UndefinedVariableError#exceptionpandas.errors.UndefinedVariableError(name,is_local=None)[source]#Exception raised byqueryorevalwhen using an undefined variable name.It will also specify whether the undefined variable is local or not.Examples>>>df=pd.DataFrame({'A':[1,1,1]})>>>df.query(""A > x"")...# UndefinedVariableError: name 'x' is not defined>>>df.query(""A > @y"")...# UndefinedVariableError: local variable 'y' is not defined>>>pd.eval('x + 1')...# UndefinedVariableError: name 'x' is not defined"
Pandas,Testing,pandas.errors.UnsortedIndexError,"pandas.errors.UnsortedIndexError#exceptionpandas.errors.UnsortedIndexError[source]#Error raised when slicing a MultiIndex which has not been lexsorted.Subclass ofKeyError.Examples>>>df=pd.DataFrame({""cat"":[0,0,1,1],...""color"":[""white"",""white"",""brown"",""black""],...""lives"":[4,4,3,7]},...)>>>df=df.set_index([""cat"",""color""])>>>dflivescat  color0    white    4white    41    brown    3black    7>>>df.loc[(0,""black""):(1,""white"")]Traceback (most recent call last):UnsortedIndexError:'Key length (2) was greaterthan MultiIndex lexsort depth (1)'"
Pandas,Testing,pandas.errors.UnsupportedFunctionCall,"pandas.errors.UnsupportedFunctionCall#exceptionpandas.errors.UnsupportedFunctionCall[source]#Exception raised when attempting to call a unsupported numpy function.For example,np.cumsum(groupby_object).Examples>>>df=pd.DataFrame({""A"":[0,0,1,1],...""B"":[""x"",""x"",""z"",""y""],...""C"":[1,2,3,4]}...)>>>np.cumsum(df.groupby([""A""]))Traceback (most recent call last):UnsupportedFunctionCall:numpy operations are not valid with groupby.Use .groupby(...).cumsum() instead"
Pandas,Testing,pandas.errors.ValueLabelTypeMismatch,"pandas.errors.ValueLabelTypeMismatch#exceptionpandas.errors.ValueLabelTypeMismatch[source]#Warning raised by to_stata on a category column that contains non-string values.Examples>>>df=pd.DataFrame({""categories"":pd.Series([""a"",2],dtype=""category"")})>>>df.to_stata('test')...# ValueLabelTypeMismatch: Stata value labels (pandas categories) must be str..."
Pandas,Testing,pandas.show_versions,"pandas.show_versions#pandas.show_versions(as_json=False)[source]#Provide useful information, important for bug reports.It comprises info about hosting operation system, pandas version,
and versions of other installed relative packages.Parameters:as_jsonstr or bool, default FalseIf False, outputs info in a human readable form to the console.If str, it will be considered as a path to a file.
Info will be written to that file in JSON format.If True, outputs info in JSON format to the console.Examples>>>pd.show_versions()Your output may look something like this:INSTALLED VERSIONS------------------commit           : 37ea63d540fd27274cad6585082c91b1283f963dpython           : 3.10.6.final.0python-bits      : 64OS               : LinuxOS-release       : 5.10.102.1-microsoft-standard-WSL2Version          : #1 SMP Wed Mar 2 00:30:59 UTC 2022machine          : x86_64processor        : x86_64byteorder        : littleLC_ALL           : NoneLANG             : en_GB.UTF-8LOCALE           : en_GB.UTF-8pandas           : 2.0.1numpy            : 1.24.3..."
Pandas,Testing,pandas.test,"pandas.test#pandas.test(extra_args=None,run_doctests=False)[source]#Run the pandas test suite using pytest.By default, runs with the marks -m “not slow and not network and not db”Parameters:extra_argslist[str], default NoneExtra marks to run the tests.run_doctestsbool, default FalseWhether to only run the Python and Cython doctests. If you would like to run
both doctests/regular tests, just append “–doctest-modules”/”–doctest-cython”
to extra_args.Examples>>>pd.test()running: pytest..."
