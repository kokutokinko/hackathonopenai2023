Name,Chapter,Section,Content
Pandas,DataFrame,pandas.DataFrame.isnull,"pandas.DataFrame.isnull#DataFrame.isnull()[source]#DataFrame.isnull is an alias for DataFrame.isna.Detect missing values.Return a boolean same-sized object indicating if the values are NA.
NA values, such as None ornumpy.NaN, gets mapped to True
values.
Everything else gets mapped to False values. Characters such as empty
strings''ornumpy.infare not considered NA values
(unless you setpandas.options.mode.use_inf_as_na=True).Returns:DataFrameMask of bool values for each element in DataFrame that
indicates whether an element is an NA value.See alsoDataFrame.isnullAlias of isna.DataFrame.notnaBoolean inverse of isna.DataFrame.dropnaOmit axes labels with missing values.isnaTop-level isna.ExamplesShow which entries in a DataFrame are NA.>>>df=pd.DataFrame(dict(age=[5,6,np.nan],...born=[pd.NaT,pd.Timestamp('1939-05-27'),...pd.Timestamp('1940-04-25')],...name=['Alfred','Batman',''],...toy=[None,'Batmobile','Joker']))>>>dfage       born    name        toy0  5.0        NaT  Alfred       None1  6.0 1939-05-27  Batman  Batmobile2  NaN 1940-04-25              Joker>>>df.isna()age   born   name    toy0  False   True  False   True1  False  False  False  False2   True  False  False  FalseShow which entries in a Series are NA.>>>ser=pd.Series([5,6,np.nan])>>>ser0    5.01    6.02    NaNdtype: float64>>>ser.isna()0    False1    False2     Truedtype: bool"
Pandas,DataFrame,pandas.DataFrame.drop_duplicates,"pandas.DataFrame.drop_duplicates#DataFrame.drop_duplicates(subset=None,*,keep='first',inplace=False,ignore_index=False)[source]#Return DataFrame with duplicate rows removed.Considering certain columns is optional. Indexes, including time indexes
are ignored.Parameters:subsetcolumn label or sequence of labels, optionalOnly consider certain columns for identifying duplicates, by
default use all of the columns.keep{?efirst?f, ?elast?f,False}, default ?efirst?fDetermines which duplicates (if any) to keep.?efirst?f : Drop duplicates except for the first occurrence.?elast?f : Drop duplicates except for the last occurrence.False: Drop all duplicates.inplacebool, defaultFalseWhether to modify the DataFrame rather than creating a new one.ignore_indexbool, defaultFalseIfTrue, the resulting axis will be labeled 0, 1, ?c, n - 1.Returns:DataFrame or NoneDataFrame with duplicates removed or None ifinplace=True.See alsoDataFrame.value_countsCount unique combinations of columns.ExamplesConsider dataset containing ramen rating.>>>df=pd.DataFrame({...'brand':['Yum Yum','Yum Yum','Indomie','Indomie','Indomie'],...'style':['cup','cup','cup','pack','pack'],...'rating':[4,4,3.5,15,5]...})>>>dfbrand style  rating0  Yum Yum   cup     4.01  Yum Yum   cup     4.02  Indomie   cup     3.53  Indomie  pack    15.04  Indomie  pack     5.0By default, it removes duplicate rows based on all columns.>>>df.drop_duplicates()brand style  rating0  Yum Yum   cup     4.02  Indomie   cup     3.53  Indomie  pack    15.04  Indomie  pack     5.0To remove duplicates on specific column(s), usesubset.>>>df.drop_duplicates(subset=['brand'])brand style  rating0  Yum Yum   cup     4.02  Indomie   cup     3.5To remove duplicates and keep last occurrences, usekeep.>>>df.drop_duplicates(subset=['brand','style'],keep='last')brand style  rating1  Yum Yum   cup     4.02  Indomie   cup     3.54  Indomie  pack     5.0"
Pandas,DataFrame,pandas.DataFrame.astype,"pandas.DataFrame.astype#DataFrame.astype(dtype,copy=None,errors='raise')[source]#Cast a pandas object to a specified dtypedtype.Parameters:dtypestr, data type, Series or Mapping of column name -> data typeUse a str, numpy.dtype, pandas.ExtensionDtype or Python type to
cast entire pandas object to the same type. Alternatively, use a
mapping, e.g. {col: dtype, ?c}, where col is a column label and dtype is
a numpy.dtype or Python type to cast one or more of the DataFrame?fs
columns to column-specific types.copybool, default TrueReturn a copy whencopy=True(be very careful settingcopy=Falseas changes to values then may propagate to other
pandas objects).errors{?eraise?f, ?eignore?f}, default ?eraise?fControl raising of exceptions on invalid data for provided dtype.raise: allow exceptions to be raisedignore: suppress exceptions. On error return original object.Returns:same type as callerSee alsoto_datetimeConvert argument to datetime.to_timedeltaConvert argument to timedelta.to_numericConvert argument to a numeric type.numpy.ndarray.astypeCast a numpy array to a specified type.NotesChanged in version 2.0.0:Usingastypeto convert from timezone-naive dtype to
timezone-aware dtype will raise an exception.
UseSeries.dt.tz_localize()instead.ExamplesCreate a DataFrame:>>>d={'col1':[1,2],'col2':[3,4]}>>>df=pd.DataFrame(data=d)>>>df.dtypescol1    int64col2    int64dtype: objectCast all columns to int32:>>>df.astype('int32').dtypescol1    int32col2    int32dtype: objectCast col1 to int32 using a dictionary:>>>df.astype({'col1':'int32'}).dtypescol1    int32col2    int64dtype: objectCreate a series:>>>ser=pd.Series([1,2],dtype='int32')>>>ser0    11    2dtype: int32>>>ser.astype('int64')0    11    2dtype: int64Convert to categorical type:>>>ser.astype('category')0    11    2dtype: categoryCategories (2, int32): [1, 2]Convert to ordered categorical type with custom ordering:>>>frompandas.api.typesimportCategoricalDtype>>>cat_dtype=CategoricalDtype(...categories=[2,1],ordered=True)>>>ser.astype(cat_dtype)0    11    2dtype: categoryCategories (2, int64): [2 < 1]Create a series of dates:>>>ser_date=pd.Series(pd.date_range('20200101',periods=3))>>>ser_date0   2020-01-011   2020-01-022   2020-01-03dtype: datetime64[ns]"
Pandas,DataFrame,pandas.DataFrame.head,"pandas.DataFrame.head#DataFrame.head(n=5)[source]#Return the firstnrows.This function returns the firstnrows for the object based
on position. It is useful for quickly testing if your object
has the right type of data in it.For negative values ofn, this function returns all rows except
the last|n|rows, equivalent todf[:n].If n is larger than the number of rows, this function returns all rows.Parameters:nint, default 5Number of rows to select.Returns:same type as callerThe firstnrows of the caller object.See alsoDataFrame.tailReturns the lastnrows.Examples>>>df=pd.DataFrame({'animal':['alligator','bee','falcon','lion',...'monkey','parrot','shark','whale','zebra']})>>>dfanimal0  alligator1        bee2     falcon3       lion4     monkey5     parrot6      shark7      whale8      zebraViewing the first 5 lines>>>df.head()animal0  alligator1        bee2     falcon3       lion4     monkeyViewing the firstnlines (three in this case)>>>df.head(3)animal0  alligator1        bee2     falconFor negative values ofn>>>df.head(-3)animal0  alligator1        bee2     falcon3       lion4     monkey5     parrot"
Pandas,DataFrame,pandas.DataFrame.tail,"pandas.DataFrame.tail#DataFrame.tail(n=5)[source]#Return the lastnrows.This function returns lastnrows from the object based on
position. It is useful for quickly verifying data, for example,
after sorting or appending rows.For negative values ofn, this function returns all rows except
the first|n|rows, equivalent todf[|n|:].If n is larger than the number of rows, this function returns all rows.Parameters:nint, default 5Number of rows to select.Returns:type of callerThe lastnrows of the caller object.See alsoDataFrame.headThe firstnrows of the caller object.Examples>>>df=pd.DataFrame({'animal':['alligator','bee','falcon','lion',...'monkey','parrot','shark','whale','zebra']})>>>dfanimal0  alligator1        bee2     falcon3       lion4     monkey5     parrot6      shark7      whale8      zebraViewing the last 5 lines>>>df.tail()animal4  monkey5  parrot6   shark7   whale8   zebraViewing the lastnlines (three in this case)>>>df.tail(3)animal6  shark7  whale8  zebraFor negative values ofn>>>df.tail(-3)animal3    lion4  monkey5  parrot6   shark7   whale8   zebra"
Pandas,DataFrame,pandas.Series.value_counts,"pandas.Series.value_counts#Series.value_counts(normalize=False,sort=True,ascending=False,bins=None,dropna=True)[source]#Return a Series containing counts of unique values.The resulting object will be in descending order so that the
first element is the most frequently-occurring element.
Excludes NA values by default.Parameters:normalizebool, default FalseIf True then the object returned will contain the relative
frequencies of the unique values.sortbool, default TrueSort by frequencies when True. Preserve the order of the data when False.ascendingbool, default FalseSort in ascending order.binsint, optionalRather than count values, group them into half-open bins,
a convenience forpd.cut, only works with numeric data.dropnabool, default TrueDon?ft include counts of NaN.Returns:SeriesSee alsoSeries.countNumber of non-NA elements in a Series.DataFrame.countNumber of non-NA elements in a DataFrame.DataFrame.value_countsEquivalent method on DataFrames.Examples>>>index=pd.Index([3,1,2,3,4,np.nan])>>>index.value_counts()3.0    21.0    12.0    14.0    1Name: count, dtype: int64Withnormalizeset toTrue, returns the relative frequency by
dividing all values by the sum of values.>>>s=pd.Series([3,1,2,3,4,np.nan])>>>s.value_counts(normalize=True)3.0    0.41.0    0.22.0    0.24.0    0.2Name: proportion, dtype: float64binsBins can be useful for going from a continuous variable to a
categorical variable; instead of counting unique
apparitions of values, divide the index in the specified
number of half-open bins.>>>s.value_counts(bins=3)(0.996, 2.0]    2(2.0, 3.0]      2(3.0, 4.0]      1Name: count, dtype: int64dropnaWithdropnaset toFalsewe can also see NaN index values.>>>s.value_counts(dropna=False)3.0    21.0    12.0    14.0    1NaN    1Name: count, dtype: int64"
Pandas,DataFrame,pandas.DataFrame.idxmax,"pandas.DataFrame.idxmax#DataFrame.idxmax(axis=0,skipna=True,numeric_only=False)[source]#Return index of first occurrence of maximum over requested axis.NA/null values are excluded.Parameters:axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0The axis to use. 0 or ?eindex?f for row-wise, 1 or ?ecolumns?f for column-wise.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result
will be NA.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Returns:SeriesIndexes of maxima along the specified axis.Raises:ValueErrorIf the row/column is emptySee alsoSeries.idxmaxReturn index of the maximum element.NotesThis method is the DataFrame version ofndarray.argmax.ExamplesConsider a dataset containing food consumption in Argentina.>>>df=pd.DataFrame({'consumption':[10.51,103.11,55.48],...'co2_emissions':[37.2,19.66,1712]},...index=['Pork','Wheat Products','Beef'])>>>dfconsumption  co2_emissionsPork                  10.51         37.20Wheat Products       103.11         19.66Beef                  55.48       1712.00By default, it returns the index for the maximum value in each column.>>>df.idxmax()consumption     Wheat Productsco2_emissions             Beefdtype: objectTo return the index for the maximum value in each row, useaxis=""columns"".>>>df.idxmax(axis=""columns"")Pork              co2_emissionsWheat Products     consumptionBeef              co2_emissionsdtype: object"
Pandas,DataFrame,pandas.DataFrame.dtypes,"pandas.DataFrame.dtypes#propertyDataFrame.dtypes[source]#Return the dtypes in the DataFrame.This returns a Series with the data type of each column.
The result?fs index is the original DataFrame?fs columns. Columns
with mixed types are stored with theobjectdtype. Seethe User Guidefor more.Returns:pandas.SeriesThe data type of each column.Examples>>>df=pd.DataFrame({'float':[1.0],...'int':[1],...'datetime':[pd.Timestamp('20180310')],...'string':['foo']})>>>df.dtypesfloat              float64int                  int64datetime    datetime64[ns]string              objectdtype: object"
Pandas,DataFrame,pandas.DataFrame.set_index,"pandas.DataFrame.set_index#DataFrame.set_index(keys,*,drop=True,append=False,inplace=False,verify_integrity=False)[source]#Set the DataFrame index using existing columns.Set the DataFrame index (row labels) using one or more existing
columns or arrays (of the correct length). The index can replace the
existing index or expand on it.Parameters:keyslabel or array-like or list of labels/arraysThis parameter can be either a single column key, a single array of
the same length as the calling DataFrame, or a list containing an
arbitrary combination of column keys and arrays. Here, ?garray?h
encompassesSeries,Index,np.ndarray, and
instances ofIterator.dropbool, default TrueDelete columns to be used as the new index.appendbool, default FalseWhether to append columns to existing index.inplacebool, default FalseWhether to modify the DataFrame rather than creating a new one.verify_integritybool, default FalseCheck the new index for duplicates. Otherwise defer the check until
necessary. Setting to False will improve the performance of this
method.Returns:DataFrame or NoneChanged row labels or None ifinplace=True.See alsoDataFrame.reset_indexOpposite of set_index.DataFrame.reindexChange to new indices or expand indices.DataFrame.reindex_likeChange to same indices as other DataFrame.Examples>>>df=pd.DataFrame({'month':[1,4,7,10],...'year':[2012,2014,2013,2014],...'sale':[55,40,84,31]})>>>dfmonth  year  sale0      1  2012    551      4  2014    402      7  2013    843     10  2014    31Set the index to become the ?emonth?f column:>>>df.set_index('month')year  salemonth1      2012    554      2014    407      2013    8410     2014    31Create a MultiIndex using columns ?eyear?f and ?emonth?f:>>>df.set_index(['year','month'])saleyear  month2012  1     552014  4     402013  7     842014  10    31Create a MultiIndex using an Index and a column:>>>df.set_index([pd.Index([1,2,3,4]),'year'])month  saleyear1  2012  1      552  2014  4      403  2013  7      844  2014  10     31Create a MultiIndex using two Series:>>>s=pd.Series([1,2,3,4])>>>df.set_index([s,s**2])month  year  sale1 1       1  2012    552 4       4  2014    403 9       7  2013    844 16     10  2014    31"
Pandas,DataFrame,pandas.Series.unique,"pandas.Series.unique#Series.unique()[source]#Return unique values of Series object.Uniques are returned in order of appearance. Hash table-based unique,
therefore does NOT sort.Returns:ndarray or ExtensionArrayThe unique values returned as a NumPy array. See Notes.See alsoSeries.drop_duplicatesReturn Series with duplicate values removed.uniqueTop-level unique method for any 1-d array-like object.Index.uniqueReturn Index with unique values from an Index object.NotesReturns the unique values as a NumPy array. In case of an
extension-array backed Series, a newExtensionArrayof that type with just
the unique values is returned. This includesCategoricalPeriodDatetime with TimezoneDatetime without TimezoneTimedeltaIntervalSparseIntegerNASee Examples section.Examples>>>pd.Series([2,1,3,3],name='A').unique()array([2, 1, 3])>>>pd.Series([pd.Timestamp('2016-01-01')for_inrange(3)]).unique()<DatetimeArray>['2016-01-01 00:00:00']Length: 1, dtype: datetime64[ns]>>>pd.Series([pd.Timestamp('2016-01-01',tz='US/Eastern')...for_inrange(3)]).unique()<DatetimeArray>['2016-01-01 00:00:00-05:00']Length: 1, dtype: datetime64[ns, US/Eastern]An Categorical will return categories in the order of
appearance and with the same dtype.>>>pd.Series(pd.Categorical(list('baabc'))).unique()['b', 'a', 'c']Categories (3, object): ['a', 'b', 'c']>>>pd.Series(pd.Categorical(list('baabc'),categories=list('abc'),...ordered=True)).unique()['b', 'a', 'c']Categories (3, object): ['a' < 'b' < 'c']"
Pandas,DataFrame,pandas.Series.clip,"pandas.Series.clip#Series.clip(lower=None,upper=None,*,axis=None,inplace=False,**kwargs)[source]#Trim values at input threshold(s).Assigns values outside boundary to boundary values. Thresholds
can be singular values or array like, and in the latter case
the clipping is performed element-wise in the specified axis.Parameters:lowerfloat or array-like, default NoneMinimum threshold value. All values below this
threshold will be set to it. A missing
threshold (e.gNA) will not clip the value.upperfloat or array-like, default NoneMaximum threshold value. All values above this
threshold will be set to it. A missing
threshold (e.gNA) will not clip the value.axis{{0 or ?eindex?f, 1 or ?ecolumns?f, None}}, default NoneAlign object with lower and upper along the given axis.
ForSeriesthis parameter is unused and defaults toNone.inplacebool, default FalseWhether to perform the operation in place on the data.*args, **kwargsAdditional keywords have no effect but might be accepted
for compatibility with numpy.Returns:Series or DataFrame or NoneSame type as calling object with the values outside the
clip boundaries replaced or None ifinplace=True.See alsoSeries.clipTrim values at input threshold in series.DataFrame.clipTrim values at input threshold in dataframe.numpy.clipClip (limit) the values in an array.Examples>>>data={'col_0':[9,-3,0,-1,5],'col_1':[-2,-7,6,8,-5]}>>>df=pd.DataFrame(data)>>>dfcol_0  col_10      9     -21     -3     -72      0      63     -1      84      5     -5Clips per column using lower and upper thresholds:>>>df.clip(-4,6)col_0  col_10      6     -21     -3     -42      0      63     -1      64      5     -4Clips using specific lower and upper thresholds per column element:>>>t=pd.Series([2,-4,-1,6,3])>>>t0    21   -42   -13    64    3dtype: int64>>>df.clip(t,t+4,axis=0)col_0  col_10      6      21     -3     -42      0      33      6      84      5      3Clips using specific lower threshold per column element, with missing values:>>>t=pd.Series([2,-4,np.nan,6,3])>>>t0    2.01   -4.02    NaN3    6.04    3.0dtype: float64>>>df.clip(t,axis=0)col_0  col_10      9      21     -3     -42      0      63      6      84      5      3"
Pandas,DataFrame,pandas.DataFrame.diff,"pandas.DataFrame.diff#DataFrame.diff(periods=1,axis=0)[source]#First discrete difference of element.Calculates the difference of a DataFrame element compared with another
element in the DataFrame (default is element in previous row).Parameters:periodsint, default 1Periods to shift for calculating difference, accepts negative
values.axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0Take difference over rows (0) or columns (1).Returns:DataFrameFirst differences of the Series.See alsoDataFrame.pct_changePercent change over given number of periods.DataFrame.shiftShift index by desired number of periods with an optional time freq.Series.diffFirst discrete difference of object.NotesFor boolean dtypes, this usesoperator.xor()rather thanoperator.sub().
The result is calculated according to current dtype in DataFrame,
however dtype of the result is always float64.ExamplesDifference with previous row>>>df=pd.DataFrame({'a':[1,2,3,4,5,6],...'b':[1,1,2,3,5,8],...'c':[1,4,9,16,25,36]})>>>dfa  b   c0  1  1   11  2  1   42  3  2   93  4  3  164  5  5  255  6  8  36>>>df.diff()a    b     c0  NaN  NaN   NaN1  1.0  0.0   3.02  1.0  1.0   5.03  1.0  1.0   7.04  1.0  2.0   9.05  1.0  3.0  11.0Difference with previous column>>>df.diff(axis=1)a  b   c0 NaN  0   01 NaN -1   32 NaN -1   73 NaN -1  134 NaN  0  205 NaN  2  28Difference with 3rd previous row>>>df.diff(periods=3)a    b     c0  NaN  NaN   NaN1  NaN  NaN   NaN2  NaN  NaN   NaN3  3.0  2.0  15.04  3.0  4.0  21.05  3.0  6.0  27.0Difference with following row>>>df.diff(periods=-1)a    b     c0 -1.0  0.0  -3.01 -1.0 -1.0  -5.02 -1.0 -1.0  -7.03 -1.0 -2.0  -9.04 -1.0 -3.0 -11.05  NaN  NaN   NaNOverflow in input dtype>>>df=pd.DataFrame({'a':[1,0]},dtype=np.uint8)>>>df.diff()a0    NaN1  255.0"
Pandas,DataFrame,pandas.DataFrame.cumsum,"pandas.DataFrame.cumsum#DataFrame.cumsum(axis=None,skipna=True,*args,**kwargs)[source]#Return cumulative sum over a DataFrame or Series axis.Returns a DataFrame or Series of the same size containing the cumulative
sum.Parameters:axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0The index or the name of the axis. 0 is equivalent to None or ?eindex?f.
ForSeriesthis parameter is unused and defaults to 0.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result
will be NA.*args, **kwargsAdditional keywords have no effect but might be accepted for
compatibility with NumPy.Returns:Series or DataFrameReturn cumulative sum of Series or DataFrame.See alsocore.window.expanding.Expanding.sumSimilar functionality but ignoresNaNvalues.DataFrame.sumReturn the sum over DataFrame axis.DataFrame.cummaxReturn cumulative maximum over DataFrame axis.DataFrame.cumminReturn cumulative minimum over DataFrame axis.DataFrame.cumsumReturn cumulative sum over DataFrame axis.DataFrame.cumprodReturn cumulative product over DataFrame axis.ExamplesSeries>>>s=pd.Series([2,np.nan,5,-1,0])>>>s0    2.01    NaN2    5.03   -1.04    0.0dtype: float64By default, NA values are ignored.>>>s.cumsum()0    2.01    NaN2    7.03    6.04    6.0dtype: float64To include NA values in the operation, useskipna=False>>>s.cumsum(skipna=False)0    2.01    NaN2    NaN3    NaN4    NaNdtype: float64DataFrame>>>df=pd.DataFrame([[2.0,1.0],...[3.0,np.nan],...[1.0,0.0]],...columns=list('AB'))>>>dfA    B0  2.0  1.01  3.0  NaN2  1.0  0.0By default, iterates over rows and finds the sum
in each column. This is equivalent toaxis=Noneoraxis='index'.>>>df.cumsum()A    B0  2.0  1.01  5.0  NaN2  6.0  1.0To iterate over columns and find the sum in each row,
useaxis=1>>>df.cumsum(axis=1)A    B0  2.0  3.01  3.0  NaN2  1.0  1.0"
Pandas,DataFrame,pandas.DataFrame.cumprod,"pandas.DataFrame.cumprod#DataFrame.cumprod(axis=None,skipna=True,*args,**kwargs)[source]#Return cumulative product over a DataFrame or Series axis.Returns a DataFrame or Series of the same size containing the cumulative
product.Parameters:axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0The index or the name of the axis. 0 is equivalent to None or ?eindex?f.
ForSeriesthis parameter is unused and defaults to 0.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result
will be NA.*args, **kwargsAdditional keywords have no effect but might be accepted for
compatibility with NumPy.Returns:Series or DataFrameReturn cumulative product of Series or DataFrame.See alsocore.window.expanding.Expanding.prodSimilar functionality but ignoresNaNvalues.DataFrame.prodReturn the product over DataFrame axis.DataFrame.cummaxReturn cumulative maximum over DataFrame axis.DataFrame.cumminReturn cumulative minimum over DataFrame axis.DataFrame.cumsumReturn cumulative sum over DataFrame axis.DataFrame.cumprodReturn cumulative product over DataFrame axis.ExamplesSeries>>>s=pd.Series([2,np.nan,5,-1,0])>>>s0    2.01    NaN2    5.03   -1.04    0.0dtype: float64By default, NA values are ignored.>>>s.cumprod()0     2.01     NaN2    10.03   -10.04    -0.0dtype: float64To include NA values in the operation, useskipna=False>>>s.cumprod(skipna=False)0    2.01    NaN2    NaN3    NaN4    NaNdtype: float64DataFrame>>>df=pd.DataFrame([[2.0,1.0],...[3.0,np.nan],...[1.0,0.0]],...columns=list('AB'))>>>dfA    B0  2.0  1.01  3.0  NaN2  1.0  0.0By default, iterates over rows and finds the product
in each column. This is equivalent toaxis=Noneoraxis='index'.>>>df.cumprod()A    B0  2.0  1.01  6.0  NaN2  6.0  0.0To iterate over columns and find the product in each row,
useaxis=1>>>df.cumprod(axis=1)A    B0  2.0  2.01  3.0  NaN2  1.0  0.0"
Pandas,DataFrame,pandas.DataFrame.cummax,"pandas.DataFrame.cummax#DataFrame.cummax(axis=None,skipna=True,*args,**kwargs)[source]#Return cumulative maximum over a DataFrame or Series axis.Returns a DataFrame or Series of the same size containing the cumulative
maximum.Parameters:axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0The index or the name of the axis. 0 is equivalent to None or ?eindex?f.
ForSeriesthis parameter is unused and defaults to 0.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result
will be NA.*args, **kwargsAdditional keywords have no effect but might be accepted for
compatibility with NumPy.Returns:Series or DataFrameReturn cumulative maximum of Series or DataFrame.See alsocore.window.expanding.Expanding.maxSimilar functionality but ignoresNaNvalues.DataFrame.maxReturn the maximum over DataFrame axis.DataFrame.cummaxReturn cumulative maximum over DataFrame axis.DataFrame.cumminReturn cumulative minimum over DataFrame axis.DataFrame.cumsumReturn cumulative sum over DataFrame axis.DataFrame.cumprodReturn cumulative product over DataFrame axis.ExamplesSeries>>>s=pd.Series([2,np.nan,5,-1,0])>>>s0    2.01    NaN2    5.03   -1.04    0.0dtype: float64By default, NA values are ignored.>>>s.cummax()0    2.01    NaN2    5.03    5.04    5.0dtype: float64To include NA values in the operation, useskipna=False>>>s.cummax(skipna=False)0    2.01    NaN2    NaN3    NaN4    NaNdtype: float64DataFrame>>>df=pd.DataFrame([[2.0,1.0],...[3.0,np.nan],...[1.0,0.0]],...columns=list('AB'))>>>dfA    B0  2.0  1.01  3.0  NaN2  1.0  0.0By default, iterates over rows and finds the maximum
in each column. This is equivalent toaxis=Noneoraxis='index'.>>>df.cummax()A    B0  2.0  1.01  3.0  NaN2  3.0  1.0To iterate over columns and find the maximum in each row,
useaxis=1>>>df.cummax(axis=1)A    B0  2.0  2.01  3.0  NaN2  1.0  1.0"
Pandas,DataFrame,pandas.DataFrame.cummin,"pandas.DataFrame.cummin#DataFrame.cummin(axis=None,skipna=True,*args,**kwargs)[source]#Return cumulative minimum over a DataFrame or Series axis.Returns a DataFrame or Series of the same size containing the cumulative
minimum.Parameters:axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0The index or the name of the axis. 0 is equivalent to None or ?eindex?f.
ForSeriesthis parameter is unused and defaults to 0.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result
will be NA.*args, **kwargsAdditional keywords have no effect but might be accepted for
compatibility with NumPy.Returns:Series or DataFrameReturn cumulative minimum of Series or DataFrame.See alsocore.window.expanding.Expanding.minSimilar functionality but ignoresNaNvalues.DataFrame.minReturn the minimum over DataFrame axis.DataFrame.cummaxReturn cumulative maximum over DataFrame axis.DataFrame.cumminReturn cumulative minimum over DataFrame axis.DataFrame.cumsumReturn cumulative sum over DataFrame axis.DataFrame.cumprodReturn cumulative product over DataFrame axis.ExamplesSeries>>>s=pd.Series([2,np.nan,5,-1,0])>>>s0    2.01    NaN2    5.03   -1.04    0.0dtype: float64By default, NA values are ignored.>>>s.cummin()0    2.01    NaN2    2.03   -1.04   -1.0dtype: float64To include NA values in the operation, useskipna=False>>>s.cummin(skipna=False)0    2.01    NaN2    NaN3    NaN4    NaNdtype: float64DataFrame>>>df=pd.DataFrame([[2.0,1.0],...[3.0,np.nan],...[1.0,0.0]],...columns=list('AB'))>>>dfA    B0  2.0  1.01  3.0  NaN2  1.0  0.0By default, iterates over rows and finds the minimum
in each column. This is equivalent toaxis=Noneoraxis='index'.>>>df.cummin()A    B0  2.0  1.01  2.0  NaN2  1.0  0.0To iterate over columns and find the minimum in each row,
useaxis=1>>>df.cummin(axis=1)A    B0  2.0  1.01  3.0  NaN2  1.0  0.0"
Pandas,DataFrame,pandas.DataFrame.mean,"pandas.DataFrame.mean#DataFrame.mean(axis=0,skipna=True,numeric_only=False,**kwargs)[source]#Return the mean of the values over the requested axis.Parameters:axis{index (0), columns (1)}Axis for the function to be applied on.
ForSeriesthis parameter is unused and defaults to 0.For DataFrames, specifyingaxis=Nonewill apply the aggregation
across both axes.New in version 2.0.0.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.**kwargsAdditional keyword arguments to be passed to the function.Returns:Series or scalarExamples>>>s=pd.Series([1,2,3])>>>s.mean()2.0With a DataFrame>>>df=pd.DataFrame({'a':[1,2],'b':[2,3]},index=['tiger','zebra'])>>>dfa   btiger  1   2zebra  2   3>>>df.mean()a   1.5b   2.5dtype: float64Using axis=1>>>df.mean(axis=1)tiger   1.5zebra   2.5dtype: float64In this case,numeric_onlyshould be set toTrueto avoid
getting an error.>>>df=pd.DataFrame({'a':[1,2],'b':['T','Z']},...index=['tiger','zebra'])>>>df.mean(numeric_only=True)a   1.5dtype: float64"
Pandas,DataFrame,pandas.DataFrame.median,"pandas.DataFrame.median#DataFrame.median(axis=0,skipna=True,numeric_only=False,**kwargs)[source]#Return the median of the values over the requested axis.Parameters:axis{index (0), columns (1)}Axis for the function to be applied on.
ForSeriesthis parameter is unused and defaults to 0.For DataFrames, specifyingaxis=Nonewill apply the aggregation
across both axes.New in version 2.0.0.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.**kwargsAdditional keyword arguments to be passed to the function.Returns:Series or scalarExamples>>>s=pd.Series([1,2,3])>>>s.median()2.0With a DataFrame>>>df=pd.DataFrame({'a':[1,2],'b':[2,3]},index=['tiger','zebra'])>>>dfa   btiger  1   2zebra  2   3>>>df.median()a   1.5b   2.5dtype: float64Using axis=1>>>df.median(axis=1)tiger   1.5zebra   2.5dtype: float64In this case,numeric_onlyshould be set toTrueto avoid getting an error.>>>df=pd.DataFrame({'a':[1,2],'b':['T','Z']},...index=['tiger','zebra'])>>>df.median(numeric_only=True)a   1.5dtype: float64"
Pandas,DataFrame,pandas.DataFrame.sum,"pandas.DataFrame.sum#DataFrame.sum(axis=0,skipna=True,numeric_only=False,min_count=0,**kwargs)[source]#Return the sum of the values over the requested axis.This is equivalent to the methodnumpy.sum.Parameters:axis{index (0), columns (1)}Axis for the function to be applied on.
ForSeriesthis parameter is unused and defaults to 0.For DataFrames, specifyingaxis=Nonewill apply the aggregation
across both axes.New in version 2.0.0.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.min_countint, default 0The required number of valid values to perform the operation. If fewer thanmin_countnon-NA values are present the result will be NA.**kwargsAdditional keyword arguments to be passed to the function.Returns:Series or scalarSee alsoSeries.sumReturn the sum.Series.minReturn the minimum.Series.maxReturn the maximum.Series.idxminReturn the index of the minimum.Series.idxmaxReturn the index of the maximum.DataFrame.sumReturn the sum over the requested axis.DataFrame.minReturn the minimum over the requested axis.DataFrame.maxReturn the maximum over the requested axis.DataFrame.idxminReturn the index of the minimum over the requested axis.DataFrame.idxmaxReturn the index of the maximum over the requested axis.Examples>>>idx=pd.MultiIndex.from_arrays([...['warm','warm','cold','cold'],...['dog','falcon','fish','spider']],...names=['blooded','animal'])>>>s=pd.Series([4,2,0,8],name='legs',index=idx)>>>sblooded  animalwarm     dog       4falcon    2cold     fish      0spider    8Name: legs, dtype: int64>>>s.sum()14By default, the sum of an empty or all-NA Series is0.>>>pd.Series([],dtype=""float64"").sum()# min_count=0 is the default0.0This can be controlled with themin_countparameter. For example, if
you?fd like the sum of an empty series to be NaN, passmin_count=1.>>>pd.Series([],dtype=""float64"").sum(min_count=1)nanThanks to theskipnaparameter,min_counthandles all-NA and
empty series identically.>>>pd.Series([np.nan]).sum()0.0>>>pd.Series([np.nan]).sum(min_count=1)nan"
Pandas,DataFrame,pandas.DataFrame.min,"pandas.DataFrame.min#DataFrame.min(axis=0,skipna=True,numeric_only=False,**kwargs)[source]#Return the minimum of the values over the requested axis.If you want theindexof the minimum, useidxmin. This is the equivalent of thenumpy.ndarraymethodargmin.Parameters:axis{index (0), columns (1)}Axis for the function to be applied on.
ForSeriesthis parameter is unused and defaults to 0.For DataFrames, specifyingaxis=Nonewill apply the aggregation
across both axes.New in version 2.0.0.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.**kwargsAdditional keyword arguments to be passed to the function.Returns:Series or scalarSee alsoSeries.sumReturn the sum.Series.minReturn the minimum.Series.maxReturn the maximum.Series.idxminReturn the index of the minimum.Series.idxmaxReturn the index of the maximum.DataFrame.sumReturn the sum over the requested axis.DataFrame.minReturn the minimum over the requested axis.DataFrame.maxReturn the maximum over the requested axis.DataFrame.idxminReturn the index of the minimum over the requested axis.DataFrame.idxmaxReturn the index of the maximum over the requested axis.Examples>>>idx=pd.MultiIndex.from_arrays([...['warm','warm','cold','cold'],...['dog','falcon','fish','spider']],...names=['blooded','animal'])>>>s=pd.Series([4,2,0,8],name='legs',index=idx)>>>sblooded  animalwarm     dog       4falcon    2cold     fish      0spider    8Name: legs, dtype: int64>>>s.min()0"
Pandas,DataFrame,pandas.DataFrame.max,"pandas.DataFrame.max#DataFrame.max(axis=0,skipna=True,numeric_only=False,**kwargs)[source]#Return the maximum of the values over the requested axis.If you want theindexof the maximum, useidxmax. This is the equivalent of thenumpy.ndarraymethodargmax.Parameters:axis{index (0), columns (1)}Axis for the function to be applied on.
ForSeriesthis parameter is unused and defaults to 0.For DataFrames, specifyingaxis=Nonewill apply the aggregation
across both axes.New in version 2.0.0.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.**kwargsAdditional keyword arguments to be passed to the function.Returns:Series or scalarSee alsoSeries.sumReturn the sum.Series.minReturn the minimum.Series.maxReturn the maximum.Series.idxminReturn the index of the minimum.Series.idxmaxReturn the index of the maximum.DataFrame.sumReturn the sum over the requested axis.DataFrame.minReturn the minimum over the requested axis.DataFrame.maxReturn the maximum over the requested axis.DataFrame.idxminReturn the index of the minimum over the requested axis.DataFrame.idxmaxReturn the index of the maximum over the requested axis.Examples>>>idx=pd.MultiIndex.from_arrays([...['warm','warm','cold','cold'],...['dog','falcon','fish','spider']],...names=['blooded','animal'])>>>s=pd.Series([4,2,0,8],name='legs',index=idx)>>>sblooded  animalwarm     dog       4falcon    2cold     fish      0spider    8Name: legs, dtype: int64>>>s.max()8"
Pandas,DataFrame,pandas.DataFrame.std,"pandas.DataFrame.std#DataFrame.std(axis=0,skipna=True,ddof=1,numeric_only=False,**kwargs)[source]#Return sample standard deviation over requested axis.Normalized by N-1 by default. This can be changed using the ddof argument.Parameters:axis{index (0), columns (1)}ForSeriesthis parameter is unused and defaults to 0.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result
will be NA.ddofint, default 1Delta Degrees of Freedom. The divisor used in calculations is N - ddof,
where N represents the number of elements.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.Returns:Series or DataFrame (if level specified)NotesTo have the same behaviour asnumpy.std, useddof=0(instead of the
defaultddof=1)Examples>>>df=pd.DataFrame({'person_id':[0,1,2,3],...'age':[21,25,62,43],...'height':[1.61,1.87,1.49,2.01]}...).set_index('person_id')>>>dfage  heightperson_id0           21    1.611           25    1.872           62    1.493           43    2.01The standard deviation of the columns can be found as follows:>>>df.std()age       18.786076height     0.237417dtype: float64Alternatively,ddof=0can be set to normalize by N instead of N-1:>>>df.std(ddof=0)age       16.269219height     0.205609dtype: float64"
Pandas,DataFrame,pandas.DataFrame.var,"pandas.DataFrame.var#DataFrame.var(axis=0,skipna=True,ddof=1,numeric_only=False,**kwargs)[source]#Return unbiased variance over requested axis.Normalized by N-1 by default. This can be changed using the ddof argument.Parameters:axis{index (0), columns (1)}ForSeriesthis parameter is unused and defaults to 0.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result
will be NA.ddofint, default 1Delta Degrees of Freedom. The divisor used in calculations is N - ddof,
where N represents the number of elements.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.Returns:Series or DataFrame (if level specified)Examples>>>df=pd.DataFrame({'person_id':[0,1,2,3],...'age':[21,25,62,43],...'height':[1.61,1.87,1.49,2.01]}...).set_index('person_id')>>>dfage  heightperson_id0           21    1.611           25    1.872           62    1.493           43    2.01>>>df.var()age       352.916667height      0.056367dtype: float64Alternatively,ddof=0can be set to normalize by N instead of N-1:>>>df.var(ddof=0)age       264.687500height      0.042275dtype: float64"
Pandas,DataFrame,pandas.DataFrame.skew,"pandas.DataFrame.skew#DataFrame.skew(axis=0,skipna=True,numeric_only=False,**kwargs)[source]#Return unbiased skew over requested axis.Normalized by N-1.Parameters:axis{index (0), columns (1)}Axis for the function to be applied on.
ForSeriesthis parameter is unused and defaults to 0.For DataFrames, specifyingaxis=Nonewill apply the aggregation
across both axes.New in version 2.0.0.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.**kwargsAdditional keyword arguments to be passed to the function.Returns:Series or scalarExamples>>>s=pd.Series([1,2,3])>>>s.skew()0.0With a DataFrame>>>df=pd.DataFrame({'a':[1,2,3],'b':[2,3,4],'c':[1,3,5]},...index=['tiger','zebra','cow'])>>>dfa   b   ctiger   1   2   1zebra   2   3   3cow     3   4   5>>>df.skew()a   0.0b   0.0c   0.0dtype: float64Using axis=1>>>df.skew(axis=1)tiger   1.732051zebra  -1.732051cow     0.000000dtype: float64In this case,numeric_onlyshould be set toTrueto avoid
getting an error.>>>df=pd.DataFrame({'a':[1,2,3],'b':['T','Z','X']},...index=['tiger','zebra','cow'])>>>df.skew(numeric_only=True)a   0.0dtype: float64"
Pandas,DataFrame,pandas.DataFrame.kurt,"pandas.DataFrame.kurt#DataFrame.kurt(axis=0,skipna=True,numeric_only=False,**kwargs)[source]#Return unbiased kurtosis over requested axis.Kurtosis obtained using Fisher?fs definition of
kurtosis (kurtosis of normal == 0.0). Normalized by N-1.Parameters:axis{index (0), columns (1)}Axis for the function to be applied on.
ForSeriesthis parameter is unused and defaults to 0.For DataFrames, specifyingaxis=Nonewill apply the aggregation
across both axes.New in version 2.0.0.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.**kwargsAdditional keyword arguments to be passed to the function.Returns:Series or scalarExamples>>>s=pd.Series([1,2,2,3],index=['cat','dog','dog','mouse'])>>>scat    1dog    2dog    2mouse  3dtype: int64>>>s.kurt()1.5With a DataFrame>>>df=pd.DataFrame({'a':[1,2,2,3],'b':[3,4,4,4]},...index=['cat','dog','dog','mouse'])>>>dfa   bcat  1   3dog  2   4dog  2   4mouse  3   4>>>df.kurt()a   1.5b   4.0dtype: float64With axis=None>>>df.kurt(axis=None).round(6)-0.988693Using axis=1>>>df=pd.DataFrame({'a':[1,2],'b':[3,4],'c':[3,4],'d':[1,2]},...index=['cat','dog'])>>>df.kurt(axis=1)cat   -6.0dog   -6.0dtype: float64"
Pandas,DataFrame,pandas.DataFrame.sem,"pandas.DataFrame.sem#DataFrame.sem(axis=0,skipna=True,ddof=1,numeric_only=False,**kwargs)[source]#Return unbiased standard error of the mean over requested axis.Normalized by N-1 by default. This can be changed using the ddof argumentParameters:axis{index (0), columns (1)}ForSeriesthis parameter is unused and defaults to 0.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result
will be NA.ddofint, default 1Delta Degrees of Freedom. The divisor used in calculations is N - ddof,
where N represents the number of elements.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.Returns:Series or DataFrame (if level specified)Examples>>>s=pd.Series([1,2,3])>>>s.sem().round(6)0.57735With a DataFrame>>>df=pd.DataFrame({'a':[1,2],'b':[2,3]},index=['tiger','zebra'])>>>dfa   btiger  1   2zebra  2   3>>>df.sem()a   0.5b   0.5dtype: float64Using axis=1>>>df.sem(axis=1)tiger   0.5zebra   0.5dtype: float64In this case,numeric_onlyshould be set toTrueto avoid getting an error.>>>df=pd.DataFrame({'a':[1,2],'b':['T','Z']},...index=['tiger','zebra'])>>>df.sem(numeric_only=True)a   0.5dtype: float64"
Pandas,DataFrame,pandas.DataFrame.quantile,"pandas.DataFrame.quantile#DataFrame.quantile(q=0.5,axis=0,numeric_only=False,interpolation='linear',method='single')[source]#Return values at the given quantile over requested axis.Parameters:qfloat or array-like, default 0.5 (50% quantile)Value between 0 <= q <= 1, the quantile(s) to compute.axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0Equals 0 or ?eindex?f for row-wise, 1 or ?ecolumns?f for column-wise.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.Changed in version 2.0.0:The default value ofnumeric_onlyis nowFalse.interpolation{?elinear?f, ?elower?f, ?ehigher?f, ?emidpoint?f, ?enearest?f}This optional parameter specifies the interpolation method to use,
when the desired quantile lies between two data pointsiandj:linear:i + (j - i) * fraction, wherefractionis the
fractional part of the index surrounded byiandj.lower:i.higher:j.nearest:iorjwhichever is nearest.midpoint: (i+j) / 2.method{?esingle?f, ?etable?f}, default ?esingle?fWhether to compute quantiles per-column (?esingle?f) or over all columns
(?etable?f). When ?etable?f, the only allowed interpolation methods are
?enearest?f, ?elower?f, and ?ehigher?f.Returns:Series or DataFrameIfqis an array, a DataFrame will be returned where theindex isq, the columns are the columns of self, and the
values are the quantiles.Ifqis a float, a Series will be returned where theindex is the columns of self and the values are the quantiles.See alsocore.window.rolling.Rolling.quantileRolling quantile.numpy.percentileNumpy function to compute the percentile.Examples>>>df=pd.DataFrame(np.array([[1,1],[2,10],[3,100],[4,100]]),...columns=['a','b'])>>>df.quantile(.1)a    1.3b    3.7Name: 0.1, dtype: float64>>>df.quantile([.1,.5])a     b0.1  1.3   3.70.5  2.5  55.0Specifyingmethod=?ftable?fwill compute the quantile over all columns.>>>df.quantile(.1,method=""table"",interpolation=""nearest"")a    1b    1Name: 0.1, dtype: int64>>>df.quantile([.1,.5],method=""table"",interpolation=""nearest"")a    b0.1  1    10.5  3  100Specifyingnumeric_only=Falsewill also compute the quantile of
datetime and timedelta data.>>>df=pd.DataFrame({'A':[1,2],...'B':[pd.Timestamp('2010'),...pd.Timestamp('2011')],...'C':[pd.Timedelta('1 days'),...pd.Timedelta('2 days')]})>>>df.quantile(0.5,numeric_only=False)A                    1.5B    2010-07-02 12:00:00C        1 days 12:00:00Name: 0.5, dtype: object"
Pandas,DataFrame,pandas.DataFrame.corr,"pandas.DataFrame.corr#DataFrame.corr(method='pearson',min_periods=1,numeric_only=False)[source]#Compute pairwise correlation of columns, excluding NA/null values.Parameters:method{?epearson?f, ?ekendall?f, ?espearman?f} or callableMethod of correlation:pearson : standard correlation coefficientkendall : Kendall Tau correlation coefficientspearman : Spearman rank correlationcallable: callable with input two 1d ndarraysand returning a float. Note that the returned matrix from corr
will have 1 along the diagonals and will be symmetric
regardless of the callable?fs behavior.min_periodsint, optionalMinimum number of observations required per pair of columns
to have a valid result. Currently only available for Pearson
and Spearman correlation.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:The default value ofnumeric_onlyis nowFalse.Returns:DataFrameCorrelation matrix.See alsoDataFrame.corrwithCompute pairwise correlation with another DataFrame or Series.Series.corrCompute the correlation between two Series.NotesPearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.Pearson correlation coefficientKendall rank correlation coefficientSpearman?fs rank correlation coefficientExamples>>>defhistogram_intersection(a,b):...v=np.minimum(a,b).sum().round(decimals=1)...returnv>>>df=pd.DataFrame([(.2,.3),(.0,.6),(.6,.0),(.2,.1)],...columns=['dogs','cats'])>>>df.corr(method=histogram_intersection)dogs  catsdogs   1.0   0.3cats   0.3   1.0>>>df=pd.DataFrame([(1,1),(2,np.nan),(np.nan,3),(4,4)],...columns=['dogs','cats'])>>>df.corr(min_periods=3)dogs  catsdogs   1.0   NaNcats   NaN   1.0"
Pandas,DataFrame,pandas.DataFrame.mode,"pandas.DataFrame.mode#DataFrame.mode(axis=0,numeric_only=False,dropna=True)[source]#Get the mode(s) of each element along the selected axis.The mode of a set of values is the value that appears most often.
It can be multiple values.Parameters:axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0The axis to iterate over while searching for the mode:0 or ?eindex?f : get mode of each column1 or ?ecolumns?f : get mode of each row.numeric_onlybool, default FalseIf True, only apply to numeric columns.dropnabool, default TrueDon?ft consider counts of NaN/NaT.Returns:DataFrameThe modes of each column or row.See alsoSeries.modeReturn the highest frequency value in a Series.Series.value_countsReturn the counts of values in a Series.Examples>>>df=pd.DataFrame([('bird',2,2),...('mammal',4,np.nan),...('arthropod',8,0),...('bird',2,np.nan)],...index=('falcon','horse','spider','ostrich'),...columns=('species','legs','wings'))>>>dfspecies  legs  wingsfalcon        bird     2    2.0horse       mammal     4    NaNspider   arthropod     8    0.0ostrich       bird     2    NaNBy default, missing values are not considered, and the mode of wings
are both 0 and 2. Because the resulting DataFrame has two rows,
the second row ofspeciesandlegscontainsNaN.>>>df.mode()species  legs  wings0    bird   2.0    0.01     NaN   NaN    2.0Settingdropna=FalseNaNvalues are considered and they can be
the mode (like for wings).>>>df.mode(dropna=False)species  legs  wings0    bird     2    NaNSettingnumeric_only=True, only the mode of numeric columns is
computed, and columns of other types are ignored.>>>df.mode(numeric_only=True)legs  wings0   2.0    0.01   NaN    2.0To compute the mode over columns and not rows, use the axis parameter:>>>df.mode(axis='columns',numeric_only=True)0    1falcon   2.0  NaNhorse    4.0  NaNspider   0.0  8.0ostrich  2.0  NaN"
Pandas,DataFrame,pandas.DataFrame.abs,"pandas.DataFrame.abs#DataFrame.abs()[source]#Return a Series/DataFrame with absolute numeric value of each element.This function only applies to elements that are all numeric.Returns:absSeries/DataFrame containing the absolute value of each element.See alsonumpy.absoluteCalculate the absolute value element-wise.NotesForcomplexinputs,1.2+1j, the absolute value is\(\sqrt{ a^2 + b^2 }\).ExamplesAbsolute numeric values in a Series.>>>s=pd.Series([-1.10,2,-3.33,4])>>>s.abs()0    1.101    2.002    3.333    4.00dtype: float64Absolute numeric values in a Series with complex numbers.>>>s=pd.Series([1.2+1j])>>>s.abs()0    1.56205dtype: float64Absolute numeric values in a Series with a Timedelta element.>>>s=pd.Series([pd.Timedelta('1 days')])>>>s.abs()0   1 daysdtype: timedelta64[ns]Select rows with data closest to certain value using argsort (fromStackOverflow).>>>df=pd.DataFrame({...'a':[4,5,6,7],...'b':[10,20,30,40],...'c':[100,50,-30,-50]...})>>>dfa    b    c0    4   10  1001    5   20   502    6   30  -303    7   40  -50>>>df.loc[(df.c-43).abs().argsort()]a    b    c1    5   20   500    4   10  1002    6   30  -303    7   40  -50"
Pandas,DataFrame,pandas.DataFrame.round,"pandas.DataFrame.round#DataFrame.round(decimals=0,*args,**kwargs)[source]#Round a DataFrame to a variable number of decimal places.Parameters:decimalsint, dict, SeriesNumber of decimal places to round each column to. If an int is
given, round each column to the same number of places.
Otherwise dict and Series round to variable numbers of places.
Column names should be in the keys ifdecimalsis a
dict-like, or in the index ifdecimalsis a Series. Any
columns not included indecimalswill be left as is. Elements
ofdecimalswhich are not columns of the input will be
ignored.*argsAdditional keywords have no effect but might be accepted for
compatibility with numpy.**kwargsAdditional keywords have no effect but might be accepted for
compatibility with numpy.Returns:DataFrameA DataFrame with the affected columns rounded to the specified
number of decimal places.See alsonumpy.aroundRound a numpy array to the given number of decimals.Series.roundRound a Series to the given number of decimals.Examples>>>df=pd.DataFrame([(.21,.32),(.01,.67),(.66,.03),(.21,.18)],...columns=['dogs','cats'])>>>dfdogs  cats0  0.21  0.321  0.01  0.672  0.66  0.033  0.21  0.18By providing an integer each column is rounded to the same number
of decimal places>>>df.round(1)dogs  cats0   0.2   0.31   0.0   0.72   0.7   0.03   0.2   0.2With a dict, the number of places for specific columns can be
specified with the column names as key and the number of decimal
places as value>>>df.round({'dogs':1,'cats':0})dogs  cats0   0.2   0.01   0.0   1.02   0.7   0.03   0.2   0.0Using a Series, the number of places for specific columns can be
specified with the column names as index and the number of
decimal places as value>>>decimals=pd.Series([0,1],index=['cats','dogs'])>>>df.round(decimals)dogs  cats0   0.2   0.01   0.0   1.02   0.7   0.03   0.2   0.0"
Pandas,DataFrame,pandas.DataFrame.pop,"pandas.DataFrame.pop#DataFrame.pop(item)[source]#Return item and drop from frame. Raise KeyError if not found.Parameters:itemlabelLabel of column to be popped.Returns:SeriesExamples>>>df=pd.DataFrame([('falcon','bird',389.0),...('parrot','bird',24.0),...('lion','mammal',80.5),...('monkey','mammal',np.nan)],...columns=('name','class','max_speed'))>>>dfname   class  max_speed0  falcon    bird      389.01  parrot    bird       24.02    lion  mammal       80.53  monkey  mammal        NaN>>>df.pop('class')0      bird1      bird2    mammal3    mammalName: class, dtype: object>>>dfname  max_speed0  falcon      389.01  parrot       24.02    lion       80.53  monkey        NaN"
Pandas,DataFrame,pandas.DataFrame.dropna,"pandas.DataFrame.dropna#DataFrame.dropna(*,axis=0,how=_NoDefault.no_default,thresh=_NoDefault.no_default,subset=None,inplace=False,ignore_index=False)[source]#Remove missing values.See theUser Guidefor more on which values are
considered missing, and how to work with missing data.Parameters:axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0Determine if rows or columns which contain missing values are
removed.0, or ?eindex?f : Drop rows which contain missing values.1, or ?ecolumns?f : Drop columns which contain missing value.Only a single axis is allowed.how{?eany?f, ?eall?f}, default ?eany?fDetermine if row or column is removed from DataFrame, when we have
at least one NA or all NA.?eany?f : If any NA values are present, drop that row or column.?eall?f : If all values are NA, drop that row or column.threshint, optionalRequire that many non-NA values. Cannot be combined with how.subsetcolumn label or sequence of labels, optionalLabels along other axis to consider, e.g. if you are dropping rows
these would be a list of columns to include.inplacebool, default FalseWhether to modify the DataFrame rather than creating a new one.ignore_indexbool, defaultFalseIfTrue, the resulting axis will be labeled 0, 1, ?c, n - 1.New in version 2.0.0.Returns:DataFrame or NoneDataFrame with NA entries dropped from it or None ifinplace=True.See alsoDataFrame.isnaIndicate missing values.DataFrame.notnaIndicate existing (non-missing) values.DataFrame.fillnaReplace missing values.Series.dropnaDrop missing values.Index.dropnaDrop missing indices.Examples>>>df=pd.DataFrame({""name"":['Alfred','Batman','Catwoman'],...""toy"":[np.nan,'Batmobile','Bullwhip'],...""born"":[pd.NaT,pd.Timestamp(""1940-04-25""),...pd.NaT]})>>>dfname        toy       born0    Alfred        NaN        NaT1    Batman  Batmobile 1940-04-252  Catwoman   Bullwhip        NaTDrop the rows where at least one element is missing.>>>df.dropna()name        toy       born1  Batman  Batmobile 1940-04-25Drop the columns where at least one element is missing.>>>df.dropna(axis='columns')name0    Alfred1    Batman2  CatwomanDrop the rows where all elements are missing.>>>df.dropna(how='all')name        toy       born0    Alfred        NaN        NaT1    Batman  Batmobile 1940-04-252  Catwoman   Bullwhip        NaTKeep only the rows with at least 2 non-NA values.>>>df.dropna(thresh=2)name        toy       born1    Batman  Batmobile 1940-04-252  Catwoman   Bullwhip        NaTDefine in which columns to look for missing values.>>>df.dropna(subset=['name','toy'])name        toy       born1    Batman  Batmobile 1940-04-252  Catwoman   Bullwhip        NaT"
Pandas,DataFrame,pandas.DataFrame.duplicated,"pandas.DataFrame.duplicated#DataFrame.duplicated(subset=None,keep='first')[source]#Return boolean Series denoting duplicate rows.Considering certain columns is optional.Parameters:subsetcolumn label or sequence of labels, optionalOnly consider certain columns for identifying duplicates, by
default use all of the columns.keep{?efirst?f, ?elast?f, False}, default ?efirst?fDetermines which duplicates (if any) to mark.first: Mark duplicates asTrueexcept for the first occurrence.last: Mark duplicates asTrueexcept for the last occurrence.False : Mark all duplicates asTrue.Returns:SeriesBoolean series for each duplicated rows.See alsoIndex.duplicatedEquivalent method on index.Series.duplicatedEquivalent method on Series.Series.drop_duplicatesRemove duplicate values from Series.DataFrame.drop_duplicatesRemove duplicate values from DataFrame.ExamplesConsider dataset containing ramen rating.>>>df=pd.DataFrame({...'brand':['Yum Yum','Yum Yum','Indomie','Indomie','Indomie'],...'style':['cup','cup','cup','pack','pack'],...'rating':[4,4,3.5,15,5]...})>>>dfbrand style  rating0  Yum Yum   cup     4.01  Yum Yum   cup     4.02  Indomie   cup     3.53  Indomie  pack    15.04  Indomie  pack     5.0By default, for each set of duplicated values, the first occurrence
is set on False and all others on True.>>>df.duplicated()0    False1     True2    False3    False4    Falsedtype: boolBy using ?elast?f, the last occurrence of each set of duplicated values
is set on False and all others on True.>>>df.duplicated(keep='last')0     True1    False2    False3    False4    Falsedtype: boolBy settingkeepon False, all duplicates are True.>>>df.duplicated(keep=False)0     True1     True2    False3    False4    Falsedtype: boolTo find duplicates on specific column(s), usesubset.>>>df.duplicated(subset=['brand'])0    False1     True2    False3     True4     Truedtype: bool"
Pandas,DataFrame,pandas.DataFrame.equals,"pandas.DataFrame.equals#DataFrame.equals(other)[source]#Test whether two objects contain the same elements.This function allows two Series or DataFrames to be compared against
each other to see if they have the same shape and elements. NaNs in
the same location are considered equal.The row/column index do not need to have the same type, as long
as the values are considered equal. Corresponding columns must be of
the same dtype.Parameters:otherSeries or DataFrameThe other Series or DataFrame to be compared with the first.Returns:boolTrue if all elements are the same in both objects, False
otherwise.See alsoSeries.eqCompare two Series objects of the same length and return a Series where each element is True if the element in each Series is equal, False otherwise.DataFrame.eqCompare two DataFrame objects of the same shape and return a DataFrame where each element is True if the respective element in each DataFrame is equal, False otherwise.testing.assert_series_equalRaises an AssertionError if left and right are not equal. Provides an easy interface to ignore inequality in dtypes, indexes and precision among others.testing.assert_frame_equalLike assert_series_equal, but targets DataFrames.numpy.array_equalReturn True if two arrays have the same shape and elements, False otherwise.Examples>>>df=pd.DataFrame({1:[10],2:[20]})>>>df1   20  10  20DataFrames df and exactly_equal have the same types and values for
their elements and column labels, which will return True.>>>exactly_equal=pd.DataFrame({1:[10],2:[20]})>>>exactly_equal1   20  10  20>>>df.equals(exactly_equal)TrueDataFrames df and different_column_type have the same element
types and values, but have different types for the column labels,
which will still return True.>>>different_column_type=pd.DataFrame({1.0:[10],2.0:[20]})>>>different_column_type1.0  2.00   10   20>>>df.equals(different_column_type)TrueDataFrames df and different_data_type have different types for the
same values for their elements, and will return False even though
their column labels are the same values and types.>>>different_data_type=pd.DataFrame({1:[10.0],2:[20.0]})>>>different_data_type1     20  10.0  20.0>>>df.equals(different_data_type)False"
