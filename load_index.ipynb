{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d12ce70-3d52-4062-9e79-c69071ceae2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "from llama_index import (\n",
    "    Document,\n",
    "    GPTVectorStoreIndex,\n",
    "    LLMPredictor,\n",
    "    PromptHelper,\n",
    "    ServiceContext,\n",
    "    LangchainEmbedding\n",
    ")\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from llama_index.prompts.prompts import QuestionAnswerPrompt\n",
    "\n",
    "# APIキーなどの設定\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_type = 'azure'\n",
    "openai.api_version = '2023-05-15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b154ae0-0ed4-4d98-bf57-4505f518ccb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#service_contextの生成\n",
    "def create_service_context():\n",
    "    # LLM Predictor\n",
    "    llm_predictor = LLMPredictor(llm=AzureChatOpenAI(\n",
    "        deployment_name='GPT35TURBO',         #デプロイ名\n",
    "        max_tokens=3000,                        #最大トークン数\n",
    "        temperature=1,                          #出力のランダム度合い\n",
    "        openai_api_version=openai.api_version   #openaiのapiのバージョン情報\n",
    "    ))\n",
    "\n",
    "    # テキストの埋め込みベクトル変換(Embedding)に関する設定\n",
    "    embeddings = LangchainEmbedding(OpenAIEmbeddings(\n",
    "        engine=\"ADA\",        #エンベディングに使うモデル\n",
    "        chunk_size=1,                           #ここでのチャンクサイズはバッチサイズ\n",
    "        openai_api_version=openai.api_version   #openaiのapiのバージョン情報\n",
    "    ))\n",
    "\n",
    "    # Prompt Helper（テキスト分割に関する設定）\n",
    "    prompt_helper = PromptHelper(\n",
    "        max_input_size=3000,    # 最大入力サイズ\n",
    "        num_output=1000,        # LLMの出力サイズ\n",
    "        chunk_size_limit=1000,  # 使用する最大チャンクサイズ（チャンク：テキストを細かく分割したもの）\n",
    "        max_chunk_overlap=0,    # チャンクオーバーラップの最大トークン数\n",
    "        separator=\"。\"        # テキスト分割の区切り文字\n",
    "    )\n",
    "\n",
    "    # Service Contextの生成\n",
    "    service_context = ServiceContext.from_defaults(\n",
    "        llm_predictor=llm_predictor,    # LLM Predictor\n",
    "        embed_model=embeddings,         # エンベディングについての設定\n",
    "        prompt_helper=prompt_helper     # Prompt Helper\n",
    "    )\n",
    "\n",
    "    return service_context, prompt_helper\n",
    "\n",
    "def llama_generate(index, query, top_k):\n",
    "    \"\"\"llama-indexによる回答の生成\"\"\"\n",
    "    # 与えるコンテキスト（商品リストのうちクエリとの類似度が高いもの）をもとに回答をもとめるようなプロンプト\n",
    "    QA_PROMPT_TMPL = (\n",
    "        \"私たちは以下の情報をコンテキスト情報として与えます。 \\n\"\n",
    "        \"---------------------\\n\"\n",
    "        \"{context_str}\"\n",
    "        \"\\n---------------------\\n\"\n",
    "        \"この情報をもとに質問に日本語で回答してください。: {query_str}\\n\"\n",
    "    )\n",
    "    qa_prompt = QuestionAnswerPrompt(QA_PROMPT_TMPL)\n",
    "    \n",
    "    # 回答生成\n",
    "    \n",
    "    # プロンプトと上位いくつまでの類似度を使用するか設定\n",
    "    query_engine = index.as_query_engine(\n",
    "        engine='GPT35TURBO',#←ここを変更\n",
    "        text_qa_template=qa_prompt, # 上記のプロンプトを与える（デフォルトは英語文）\n",
    "        similarity_top_k=top_k      # 参考情報（商品リスト）のうちクエリとの類似度上位何件を生成に利用するか\n",
    "    )\n",
    "    # 生成\n",
    "    response = query_engine.query(query)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9143f877-754c-40fb-b678-6ade315ed89e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_context, prompt_helper = create_service_context()\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage_pandas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b31ddd-6dab-4280-bfed-c99142c9457e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = load_index_from_storage(storage_context, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efc95ccf-1ea9-4da3-9d00-75c61c1e278d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.indices.vector_store.base.GPTVectorStoreIndex at 0x7f7abbf4ad50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2163329a-5d68-448a-ae05-8c30c6510a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# クエリ （description：アップロードした顧客情報)\n",
    "query = f\"\"\"# Background\n",
    "            You are an expert in the field of data collection in data science.\n",
    "            Your job is to use your data collection expertise in data science to support user learning. \n",
    "            However, you can also enjoy stories other than data science.\n",
    "\n",
    "            # Customer Info\n",
    "            initial_prompt: あなたはデータサイエンスのデータ収集分野におけるスペシャリストです。\n",
    "データ収集の分野でユーザーをサポートしてください。\n",
    "            User request: pandasについて教えてください。\n",
    "            # Instructions\n",
    "            データサイエンスに関する質問をされた場合、そのプロセスを最適化するために、ユーザーをサポートしてください。\n",
    "            具体的には、User requestを解決するライブラリ名や選定理由、コードと使用方法、ベストプラクティスなどを含めてください。\n",
    "            ユーザーの要求に対して役立つコードを提示し、説明をセットで\n",
    "            詳しく説明することを意識してください。ライブラリを使用するために必要なimport文、基本的な使用方法から実戦的な使い方まで順を追って説明してください。\n",
    "            コードは見やすくするために、他の文章と続けて文章にせず、コードとして区別してください。\n",
    "            コードを書いた場合には、そのコードの実行結果として出力を必ずセットで提供してください。\n",
    "                        \"\"\"\n",
    "\n",
    "# llama-indexによる回答の生成\n",
    "result = llama_generate(index=index, query=query, top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66ac0529-c00c-422e-b6b0-576e7ac53949",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='pandasについて教えてください。\\n\\npandasは、Pythonにおけるデータ分析のためのライブラリであり、特に表形式のデータを扱う際に便利です。その中のDataFrame.dropnaメソッドは、欠損値を含む行や列を削除するためのメソッドです。\\n\\nまず、このメソッドは以下のように使うことができます。\\n\\n```python\\nimport pandas as pd\\n\\n# サンプルのDataFrameを作成\\ndf = pd.DataFrame({\\n    \"name\": [\\'Alfred\\', \\'Batman\\', \\'Catwoman\\'],\\n    \"toy\": [np.nan, \\'Batmobile\\', \\'Bullwhip\\'],\\n    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"), pd.NaT]\\n})\\n\\n# 欠損値を含む行を削除\\nresult = df.dropna()\\nprint(result)\\n# 出力結果\\n#    name        toy       born\\n# 1  Batman  Batmobile 1940-04-25\\n```\\n\\nまた、特定の軸（行または列）、特定の条件（欠損値が一つでも含まれるか、全てが欠損値か）、特定の非欠損値の数などに基づいて、削除の方法を細かく指定することもできます。\\n\\n例えば、特定の列（カラム）に欠損値が含まれている場合にその列を削除する場合は、次のようにします。\\n\\n```python\\n# 欠損値を含む列を削除\\nresult = df.dropna(axis=\\'columns\\')\\nprint(result)\\n# 出力結果\\n#      name\\n# 0  Alfred\\n# 1  Batman\\n# 2 Catwoman\\n```\\n\\nこのように、pandasのDataFrame.dropnaメソッドは、データの前処理やクリーニングにおいて非常に便利なメソッドです。', source_nodes=[NodeWithScore(node=Node(text='【Name】Pandas【Chapter】DataFrame【Section】pandas.DataFrame.dropna【Content】pandas.DataFrame.dropna#DataFrame.dropna(*,axis=0,how=_NoDefault.no_default,thresh=_NoDefault.no_default,subset=None,inplace=False,ignore_index=False)[source]#Remove missing values.See theUser Guidefor more on which values are\\nconsidered missing, and how to work with missing data.Parameters:axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0Determine if rows or columns which contain missing values are\\nremoved.0, or ?eindex?f : Drop rows which contain missing values.1, or ?ecolumns?f : Drop columns which contain missing value.Only a single axis is allowed.how{?eany?f, ?eall?f}, default ?eany?fDetermine if row or column is removed from DataFrame, when we have\\nat least one NA or all NA.?eany?f : If any NA values are present, drop that row or column.?eall?f : If all values are NA, drop that row or column.threshint, optionalRequire that many non-NA values. Cannot be combined with how.subsetcolumn label or sequence of labels, optionalLabels along other axis to consider, e.g. if you are dropping rows\\nthese would be a list of columns to include.inplacebool, default FalseWhether to modify the DataFrame rather than creating a new one.ignore_indexbool, defaultFalseIfTrue, the resulting axis will be labeled 0, 1, ?c, n - 1.New in version 2.0.0.Returns:DataFrame or NoneDataFrame with NA entries dropped from it or None ifinplace=True.See alsoDataFrame.isnaIndicate missing values.DataFrame.notnaIndicate existing (non-missing) values.DataFrame.fillnaReplace missing values.Series.dropnaDrop missing values.Index.dropnaDrop missing indices.Examples>>>df=pd.DataFrame({\"name\":[\\'Alfred\\',\\'Batman\\',\\'Catwoman\\'],...\"toy\":[np.nan,\\'Batmobile\\',\\'Bullwhip\\'],...\"born\":[pd.NaT,pd.Timestamp(\"1940-04-25\"),...pd.NaT]})>>>dfname        toy       born0    Alfred        NaN        NaT1    Batman  Batmobile 1940-04-252  Catwoman   Bullwhip        NaTDrop the rows where at least one element is missing.>>>df.dropna()name        toy       born1  Batman  Batmobile 1940-04-25Drop the columns where at least one element is missing.>>>df.dropna(axis=\\'columns\\')name0    Alfred1    Batman2  CatwomanDrop the rows where all elements are missing.>>>df.dropna(how=\\'all\\')name        toy       born0    Alfred        NaN        NaT1    Batman  Batmobile 1940-04-252  Catwoman   Bullwhip        NaTKeep only the rows with at least 2 non-NA values.>>>df.dropna(thresh=2)name        toy       born1    Batman  Batmobile 1940-04-252  Catwoman   Bullwhip        NaTDefine in which columns to look for missing values.>>>df.dropna(subset=[\\'name\\',\\'toy\\'])name        toy       born1    Batman  Batmobile 1940-04-252  Catwoman   Bullwhip        NaT', doc_id='204cea12-d396-4161-9ab5-8b7ec50a0f41', embedding=None, doc_hash='909ef097eb71f5408a53cfff3f03d500008e7a999ea984de7809d2f7ae9ba621', extra_info=None, node_info={'start': 0, 'end': 2687, '_node_type': '1'}, relationships={<DocumentRelationship.SOURCE: '1'>: 'bf4d4f5a-7754-4af0-a598-16d38a479263'}), score=0.7084188099728235)], extra_info={'204cea12-d396-4161-9ab5-8b7ec50a0f41': None})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02bb114-531a-4470-9b0c-0d73afe302d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
