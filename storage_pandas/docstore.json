{"docstore/metadata": {"9a5f3d9a-c16a-412d-999d-ca54a2191e59": {"doc_hash": "27ca291aa1f798d74eb64a3bf4a173ea0c1d6f79e0d63574bb8b8d8fd117d0c0"}, "5e8ef3b3-cc67-4ab6-91ca-a554edf2df41": {"doc_hash": "ebd1d82022aa0a52dbc3aa7dd066bec32a1cfdad507172f4928b5f55fe459c0c"}, "d21f6a97-9294-4d2b-9297-7aa52fc127c2": {"doc_hash": "68b6a7322ba03de453c3cfb6d0891a378353e889360ae66b2c1717cb845d9fff"}, "a661fb42-d081-4cf0-ba96-d3fbadef8ea5": {"doc_hash": "b2c8a06980dcd29015c487ab90f1b581c60d651376d9f20ea3cbf6c539a85f6f"}, "389521de-714f-420d-8956-caf754c8b89e": {"doc_hash": "4d7bff8371c0bed30366710ada31b85510b2e55984952f4e513f9cd9cfd2d7ea"}, "bc45a9af-4978-48e0-ab1c-27c19177cbb1": {"doc_hash": "d7975312aacb1758e1ea97df09ad650c7ca5e7505927c5a9e747ae6e70e49a1b"}, "c9932f46-7bd2-46ba-8e03-49bc5d469d4f": {"doc_hash": "cc6199f5ea2b2d297d138ae6a3f86368b5cc421c7b88e8ad5ac56d026cb91446"}, "762b8cef-a093-4edd-9738-4fe49ef50f8d": {"doc_hash": "36fd455a53c16fd2e5e73ede599c1f0d650fc335a43344d65cdd0c395eb4be14"}, "4b99342d-fec9-42eb-a553-e6ddc3e2afb1": {"doc_hash": "1ffc86971c2141e5deac9915ffdf3111ccc04a8e5f2b1832e15b3d5b503d5838"}, "172bd16d-950b-4744-94b3-ec5d6e7baa3e": {"doc_hash": "522a0aab7dde86638750f94bb9aafcb217c3b00b06f1e7755c491a175c88354c"}, "895f34e7-2b9d-496a-9877-600385fb955a": {"doc_hash": "2d4dce5ec2e9ae3abc278a5744c74d7487201b7578f2c342ae21dad6842de862"}, "33b57311-8718-4107-9620-a7e89042259f": {"doc_hash": "c298a09adf5f655de7a013950e68f7bb04ebf69090138ca8b5df190b25d49dd3"}, "ed96a6e6-c840-4bfd-a386-5be441da6823": {"doc_hash": "c60c639904a0538d4d24f4a380de0719381cc53a2d233a6aca376d6693f68fca"}, "cd7a7c60-93bc-47c8-8ce6-f5143759f9f1": {"doc_hash": "d947ea019c080bb7226050eb55a3c24e1e6a0c297bf70126afe19d0ccfa130c4"}, "88524674-45ae-445a-bce7-3cd9feb65bce": {"doc_hash": "0b3270a9c469bb6fb13371b6bc8f493f844b785eda9fb6a491ecc93d4729bd22"}, "dbf2310a-15ad-484f-99cc-76c0495b2b56": {"doc_hash": "1aed7df43535158e2ab7410f5444495bdbd9fca93d911ffaacf12921686302f9"}, "51b5d81e-792a-4c92-8df4-7a7eb132fdda": {"doc_hash": "28033cf4ae010d655b2d1058be530fb437c34ecaddf48d247897480dbe511aef"}, "1465b92f-69ab-4b88-9360-9f5a8a5126a3": {"doc_hash": "19d0a58fc4207b8c07cbea79d518753f02fb2fe440751635c356f988994d6930"}, "e6ec4e97-0a7d-4c63-b620-ebd7e88fc0ca": {"doc_hash": "ea9b69f0d84ac822b2a8869db7827b935904306c9f6bbb05ff0d19bc23dac8fa"}, "e0d962ec-c1d1-400d-ac9a-d546ab932031": {"doc_hash": "8ec16ec51885457953752614d31ee4ab719ea6571db316002196c6ed012f09bf"}, "bb718a40-40e6-41e4-8332-c92cc79ad239": {"doc_hash": "d1ec5a7a10d8a624fd68e31c2cf1b17e6eaedf76550f42076f79f57088112b3f"}, "c9d11f43-2de3-42a9-b523-8225a085e473": {"doc_hash": "57d1a81564d3580838aff55783859218352a2e2a49d0c2434c7a2bf9a8dce96d"}, "aeda5bd8-675b-4d70-9aae-5e7784ead1b6": {"doc_hash": "2c57ff3e23b1ff2f38cfe9ac174c18a12dc13be1baf689509f3190ca0d0c909a"}, "468a47d4-ef37-42aa-8bfc-2322fd76a4dd": {"doc_hash": "d9f574e3614899892869a11098db1efeebadf8abb9c4b12c4760728ffc1016f7"}, "afa2205d-6815-4ce4-befa-4229ac2a8de0": {"doc_hash": "d62b1e8b616359c6d7f1633d9b97046975a05a7fc658c66373d1145c9b9e31cf"}, "fe1f9849-aa2e-4a11-b0fb-e6897dfe4f58": {"doc_hash": "90a4b5437077345de804bf561d77001f0086599b09127e46d9c79c476688fb81"}, "af8a56a8-f890-4460-a2c1-28f861c5aedf": {"doc_hash": "036afdf50bde1034a89a7b81cd86417e84735d06904ef76a3ab4a4908e1b29d9"}, "eb90b7af-d851-422e-8994-49769682193e": {"doc_hash": "56cdeec2ec01f2f3c70510980cbadfe9a2bb5455f7d416b7a6921a6f2e1aaf5c"}, "6fbafa42-9168-41c7-aea7-5e2666c48d14": {"doc_hash": "7b5822e9e2a5c295e5540efa237c8597278c005e733a70d31dc115a6869798e4"}, "91227d93-2c2b-4263-9de1-0f5bfd5795a5": {"doc_hash": "af6e27c01b60e1a96dc8ac632f24800037864b67c6fd349ada4f0c9675e08037"}, "7f2baa64-60ee-4f3d-8127-7071e6d052d8": {"doc_hash": "168c4c800776b5ee6f2775b94daf5ea6743fa3763cbfbb22cf3d709eccfb2c75"}, "52052435-b5de-4911-9462-45e0e2d86663": {"doc_hash": "7a85856c4694f9a30f669f932751367fffed76de49b095eb932ab133ede962a1"}, "bf4d4f5a-7754-4af0-a598-16d38a479263": {"doc_hash": "909ef097eb71f5408a53cfff3f03d500008e7a999ea984de7809d2f7ae9ba621"}, "9bf200ed-1e6f-4bd1-b685-3bbfa09b3931": {"doc_hash": "48d87fa631c492536142df149c45d6918ef05ee7776e4a772005ac475ca0c2b0"}, "3ce0f070-e518-4da5-95cf-f5cc68136f9b": {"doc_hash": "8e367a7f53ff193fccbe4224b3cb646ac36bad597088ca0f4cbdd70a995867d3"}, "8e5261b7-b23b-4809-8928-355efb5d0dc3": {"doc_hash": "27ca291aa1f798d74eb64a3bf4a173ea0c1d6f79e0d63574bb8b8d8fd117d0c0"}, "be7d8a5a-9fa6-4fa4-aabb-37431c7a5837": {"doc_hash": "ebd1d82022aa0a52dbc3aa7dd066bec32a1cfdad507172f4928b5f55fe459c0c"}, "cbe6d0cc-8d67-40a3-9653-069e53ca1e96": {"doc_hash": "68b6a7322ba03de453c3cfb6d0891a378353e889360ae66b2c1717cb845d9fff"}, "742069ac-4f6a-48bb-8e5a-a039a11c62b6": {"doc_hash": "b2c8a06980dcd29015c487ab90f1b581c60d651376d9f20ea3cbf6c539a85f6f"}, "5f1acf15-b4ce-4941-b0bf-75ac49f5f422": {"doc_hash": "4d7bff8371c0bed30366710ada31b85510b2e55984952f4e513f9cd9cfd2d7ea"}, "77061459-045e-4e65-aea0-72eecff2a97d": {"doc_hash": "d7975312aacb1758e1ea97df09ad650c7ca5e7505927c5a9e747ae6e70e49a1b"}, "af6be3ee-eaa1-40b9-ba91-d4af5fcbaef6": {"doc_hash": "cc6199f5ea2b2d297d138ae6a3f86368b5cc421c7b88e8ad5ac56d026cb91446"}, "642bfb3e-03a0-4676-a431-b883a068b147": {"doc_hash": "36fd455a53c16fd2e5e73ede599c1f0d650fc335a43344d65cdd0c395eb4be14"}, "07b67187-0bd8-40d5-b08c-c8d77729fb85": {"doc_hash": "1ffc86971c2141e5deac9915ffdf3111ccc04a8e5f2b1832e15b3d5b503d5838"}, "6dccf2ce-c03d-49ba-afab-fd4a6507ee7c": {"doc_hash": "522a0aab7dde86638750f94bb9aafcb217c3b00b06f1e7755c491a175c88354c"}, "1ac1fcff-d5c6-4eb0-95b8-5969f49866c3": {"doc_hash": "2d4dce5ec2e9ae3abc278a5744c74d7487201b7578f2c342ae21dad6842de862"}, "7974763b-06c5-4c2f-a373-25e320a4bcb9": {"doc_hash": "c298a09adf5f655de7a013950e68f7bb04ebf69090138ca8b5df190b25d49dd3"}, "419c1ad8-d9cd-40b0-8340-fb4530048da4": {"doc_hash": "c60c639904a0538d4d24f4a380de0719381cc53a2d233a6aca376d6693f68fca"}, "4bda8ae8-547f-4e56-9321-d6df14b58676": {"doc_hash": "d947ea019c080bb7226050eb55a3c24e1e6a0c297bf70126afe19d0ccfa130c4"}, "787b5c70-f995-4b8c-a4b6-f97aa6a39a17": {"doc_hash": "0b3270a9c469bb6fb13371b6bc8f493f844b785eda9fb6a491ecc93d4729bd22"}, "8c7774c9-7e2e-42ad-acc0-99315cbb291e": {"doc_hash": "1aed7df43535158e2ab7410f5444495bdbd9fca93d911ffaacf12921686302f9"}, "424cd141-cc31-45ce-9ac6-0c726d88962c": {"doc_hash": "28033cf4ae010d655b2d1058be530fb437c34ecaddf48d247897480dbe511aef"}, "0546b7b1-2beb-449e-9644-eb2bc500beb6": {"doc_hash": "19d0a58fc4207b8c07cbea79d518753f02fb2fe440751635c356f988994d6930"}, "bf5edab7-70f9-4edc-88b5-6d9137771220": {"doc_hash": "ea9b69f0d84ac822b2a8869db7827b935904306c9f6bbb05ff0d19bc23dac8fa"}, "f83640b1-bf3a-49cf-831e-a9f9a718d440": {"doc_hash": "8ec16ec51885457953752614d31ee4ab719ea6571db316002196c6ed012f09bf"}, "c7aa52a7-bf72-4295-ae45-98ec6a8d1506": {"doc_hash": "d1ec5a7a10d8a624fd68e31c2cf1b17e6eaedf76550f42076f79f57088112b3f"}, "7910fb65-c533-4a28-a783-e1552f2b8c37": {"doc_hash": "57d1a81564d3580838aff55783859218352a2e2a49d0c2434c7a2bf9a8dce96d"}, "b024ad80-ea9c-462d-9d1c-cf46942f1f56": {"doc_hash": "2c57ff3e23b1ff2f38cfe9ac174c18a12dc13be1baf689509f3190ca0d0c909a"}, "61e83df3-39a7-44e7-be17-6bd1620ebbe7": {"doc_hash": "d9f574e3614899892869a11098db1efeebadf8abb9c4b12c4760728ffc1016f7"}, "e272a857-e791-4dc2-b006-d45e5fed598a": {"doc_hash": "d62b1e8b616359c6d7f1633d9b97046975a05a7fc658c66373d1145c9b9e31cf"}, "0f234ad5-3f00-44aa-acf2-aeab45705c70": {"doc_hash": "90a4b5437077345de804bf561d77001f0086599b09127e46d9c79c476688fb81"}, "a3491f0a-40ae-44ac-b2e6-091baffbd9df": {"doc_hash": "036afdf50bde1034a89a7b81cd86417e84735d06904ef76a3ab4a4908e1b29d9"}, "0c1c976f-369c-4165-b993-4db44ef4718f": {"doc_hash": "56cdeec2ec01f2f3c70510980cbadfe9a2bb5455f7d416b7a6921a6f2e1aaf5c"}, "b890918c-2c74-42b6-b23d-7ca56a623d7c": {"doc_hash": "7b5822e9e2a5c295e5540efa237c8597278c005e733a70d31dc115a6869798e4"}, "eb32a0eb-ce0b-47c1-9259-1164981953e1": {"doc_hash": "af6e27c01b60e1a96dc8ac632f24800037864b67c6fd349ada4f0c9675e08037"}, "84517590-4cdf-4808-9700-a047fe181585": {"doc_hash": "168c4c800776b5ee6f2775b94daf5ea6743fa3763cbfbb22cf3d709eccfb2c75"}, "79302c81-80ed-4555-a1d3-95840467d668": {"doc_hash": "7a85856c4694f9a30f669f932751367fffed76de49b095eb932ab133ede962a1"}, "204cea12-d396-4161-9ab5-8b7ec50a0f41": {"doc_hash": "909ef097eb71f5408a53cfff3f03d500008e7a999ea984de7809d2f7ae9ba621"}, "147facc3-24e8-4143-b79f-0596ccbf7e70": {"doc_hash": "48d87fa631c492536142df149c45d6918ef05ee7776e4a772005ac475ca0c2b0"}, "57003b76-e2cf-4136-912c-804a970d6483": {"doc_hash": "8e367a7f53ff193fccbe4224b3cb646ac36bad597088ca0f4cbdd70a995867d3"}}, "docstore/data": {"8e5261b7-b23b-4809-8928-355efb5d0dc3": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.isnull\u3010Content\u3011pandas.DataFrame.isnull#DataFrame.isnull()[source]#DataFrame.isnull is an alias for DataFrame.isna.Detect missing values.Return a boolean same-sized object indicating if the values are NA.\nNA values, such as None ornumpy.NaN, gets mapped to True\nvalues.\nEverything else gets mapped to False values. Characters such as empty\nstrings''ornumpy.infare not considered NA values\n(unless you setpandas.options.mode.use_inf_as_na=True).Returns:DataFrameMask of bool values for each element in DataFrame that\nindicates whether an element is an NA value.See alsoDataFrame.isnullAlias of isna.DataFrame.notnaBoolean inverse of isna.DataFrame.dropnaOmit axes labels with missing values.isnaTop-level isna.ExamplesShow which entries in a DataFrame are NA.>>>df=pd.DataFrame(dict(age=[5,6,np.nan],...born=[pd.NaT,pd.Timestamp('1939-05-27'),...pd.Timestamp('1940-04-25')],...name=['Alfred','Batman',''],...toy=[None,'Batmobile','Joker']))>>>dfage       born    name        toy0  5.0        NaT  Alfred       None1  6.0 1939-05-27  Batman  Batmobile2  NaN 1940-04-25              Joker>>>df.isna()age   born   name    toy0  False   True  False   True1  False  False  False  False2   True  False  False  FalseShow which entries in a Series are NA.>>>ser=pd.Series([5,6,np.nan])>>>ser0    5.01    6.02    NaNdtype: float64>>>ser.isna()0    False1    False2     Truedtype: bool", "doc_id": "8e5261b7-b23b-4809-8928-355efb5d0dc3", "embedding": null, "doc_hash": "27ca291aa1f798d74eb64a3bf4a173ea0c1d6f79e0d63574bb8b8d8fd117d0c0", "extra_info": null, "node_info": {"start": 0, "end": 1429, "_node_type": "1"}, "relationships": {"1": "9a5f3d9a-c16a-412d-999d-ca54a2191e59"}}, "__type__": "1"}, "be7d8a5a-9fa6-4fa4-aabb-37431c7a5837": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.drop_duplicates\u3010Content\u3011pandas.DataFrame.drop_duplicates#DataFrame.drop_duplicates(subset=None,*,keep='first',inplace=False,ignore_index=False)[source]#Return DataFrame with duplicate rows removed.Considering certain columns is optional. Indexes, including time indexes\nare ignored.Parameters:subsetcolumn label or sequence of labels, optionalOnly consider certain columns for identifying duplicates, by\ndefault use all of the columns.keep{?efirst?f, ?elast?f,False}, default ?efirst?fDetermines which duplicates (if any) to keep.?efirst?f : Drop duplicates except for the first occurrence.?elast?f : Drop duplicates except for the last occurrence.False: Drop all duplicates.inplacebool, defaultFalseWhether to modify the DataFrame rather than creating a new one.ignore_indexbool, defaultFalseIfTrue, the resulting axis will be labeled 0, 1, ?c, n - 1.Returns:DataFrame or NoneDataFrame with duplicates removed or None ifinplace=True.See alsoDataFrame.value_countsCount unique combinations of columns.ExamplesConsider dataset containing ramen rating.>>>df=pd.DataFrame({...'brand':['Yum Yum','Yum Yum','Indomie','Indomie','Indomie'],...'style':['cup','cup','cup','pack','pack'],...'rating':[4,4,3.5,15,5]...})>>>dfbrand style  rating0  Yum Yum   cup     4.01  Yum Yum   cup     4.02  Indomie   cup     3.53  Indomie  pack    15.04  Indomie  pack     5.0By default, it removes duplicate rows based on all columns.>>>df.drop_duplicates()brand style  rating0  Yum Yum   cup     4.02  Indomie   cup     3.53  Indomie  pack    15.04  Indomie  pack     5.0To remove duplicates on specific column(s), usesubset.>>>df.drop_duplicates(subset=['brand'])brand style  rating0  Yum Yum   cup     4.02  Indomie   cup     3.5To remove duplicates and keep last occurrences, usekeep.>>>df.drop_duplicates(subset=['brand','style'],keep='last')brand style  rating1  Yum Yum   cup     4.02  Indomie   cup     3.54  Indomie  pack     5.0", "doc_id": "be7d8a5a-9fa6-4fa4-aabb-37431c7a5837", "embedding": null, "doc_hash": "ebd1d82022aa0a52dbc3aa7dd066bec32a1cfdad507172f4928b5f55fe459c0c", "extra_info": null, "node_info": {"start": 0, "end": 1972, "_node_type": "1"}, "relationships": {"1": "5e8ef3b3-cc67-4ab6-91ca-a554edf2df41"}}, "__type__": "1"}, "cbe6d0cc-8d67-40a3-9653-069e53ca1e96": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.astype\u3010Content\u3011pandas.DataFrame.astype#DataFrame.astype(dtype,copy=None,errors='raise')[source]#Cast a pandas object to a specified dtypedtype.Parameters:dtypestr, data type, Series or Mapping of column name -> data typeUse a str, numpy.dtype, pandas.ExtensionDtype or Python type to\ncast entire pandas object to the same type. Alternatively, use a\nmapping, e.g. {col: dtype, ?c}, where col is a column label and dtype is\na numpy.dtype or Python type to cast one or more of the DataFrame?fs\ncolumns to column-specific types.copybool, default TrueReturn a copy whencopy=True(be very careful settingcopy=Falseas changes to values then may propagate to other\npandas objects).errors{?eraise?f, ?eignore?f}, default ?eraise?fControl raising of exceptions on invalid data for provided dtype.raise: allow exceptions to be raisedignore: suppress exceptions. On error return original object.Returns:same type as callerSee alsoto_datetimeConvert argument to datetime.to_timedeltaConvert argument to timedelta.to_numericConvert argument to a numeric type.numpy.ndarray.astypeCast a numpy array to a specified type.NotesChanged in version 2.0.0:Usingastypeto convert from timezone-naive dtype to\ntimezone-aware dtype will raise an exception.\nUseSeries.dt.tz_localize()instead.ExamplesCreate a DataFrame:>>>d={'col1':[1,2],'col2':[3,4]}>>>df=pd.DataFrame(data=d)>>>df.dtypescol1    int64col2    int64dtype: objectCast all columns to int32:>>>df.astype('int32').dtypescol1    int32col2    int32dtype: objectCast col1 to int32 using a dictionary:>>>df.astype({'col1':'int32'}).dtypescol1    int32col2    int64dtype: objectCreate a series:>>>ser=pd.Series([1,2],dtype='int32')>>>ser0    11    2dtype: int32>>>ser.astype('int64')0    11    2dtype: int64Convert to categorical type:>>>ser.astype('category')0    11    2dtype: categoryCategories (2, int32): [1, 2]Convert to ordered categorical type with custom ordering:>>>frompandas.api.typesimportCategoricalDtype>>>cat_dtype=CategoricalDtype(...categories=[2,1],ordered=True)>>>ser.astype(cat_dtype)0    11    2dtype: categoryCategories (2, int64): [2 < 1]Create a series of dates:>>>ser_date=pd.Series(pd.date_range('20200101',periods=3))>>>ser_date0   2020-01-011   2020-01-022   2020-01-03dtype: datetime64[ns]", "doc_id": "cbe6d0cc-8d67-40a3-9653-069e53ca1e96", "embedding": null, "doc_hash": "68b6a7322ba03de453c3cfb6d0891a378353e889360ae66b2c1717cb845d9fff", "extra_info": null, "node_info": {"start": 0, "end": 2304, "_node_type": "1"}, "relationships": {"1": "d21f6a97-9294-4d2b-9297-7aa52fc127c2"}}, "__type__": "1"}, "742069ac-4f6a-48bb-8e5a-a039a11c62b6": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.head\u3010Content\u3011pandas.DataFrame.head#DataFrame.head(n=5)[source]#Return the firstnrows.This function returns the firstnrows for the object based\non position. It is useful for quickly testing if your object\nhas the right type of data in it.For negative values ofn, this function returns all rows except\nthe last|n|rows, equivalent todf[:n].If n is larger than the number of rows, this function returns all rows.Parameters:nint, default 5Number of rows to select.Returns:same type as callerThe firstnrows of the caller object.See alsoDataFrame.tailReturns the lastnrows.Examples>>>df=pd.DataFrame({'animal':['alligator','bee','falcon','lion',...'monkey','parrot','shark','whale','zebra']})>>>dfanimal0  alligator1        bee2     falcon3       lion4     monkey5     parrot6      shark7      whale8      zebraViewing the first 5 lines>>>df.head()animal0  alligator1        bee2     falcon3       lion4     monkeyViewing the firstnlines (three in this case)>>>df.head(3)animal0  alligator1        bee2     falconFor negative values ofn>>>df.head(-3)animal0  alligator1        bee2     falcon3       lion4     monkey5     parrot", "doc_id": "742069ac-4f6a-48bb-8e5a-a039a11c62b6", "embedding": null, "doc_hash": "b2c8a06980dcd29015c487ab90f1b581c60d651376d9f20ea3cbf6c539a85f6f", "extra_info": null, "node_info": {"start": 0, "end": 1177, "_node_type": "1"}, "relationships": {"1": "a661fb42-d081-4cf0-ba96-d3fbadef8ea5"}}, "__type__": "1"}, "5f1acf15-b4ce-4941-b0bf-75ac49f5f422": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.tail\u3010Content\u3011pandas.DataFrame.tail#DataFrame.tail(n=5)[source]#Return the lastnrows.This function returns lastnrows from the object based on\nposition. It is useful for quickly verifying data, for example,\nafter sorting or appending rows.For negative values ofn, this function returns all rows except\nthe first|n|rows, equivalent todf[|n|:].If n is larger than the number of rows, this function returns all rows.Parameters:nint, default 5Number of rows to select.Returns:type of callerThe lastnrows of the caller object.See alsoDataFrame.headThe firstnrows of the caller object.Examples>>>df=pd.DataFrame({'animal':['alligator','bee','falcon','lion',...'monkey','parrot','shark','whale','zebra']})>>>dfanimal0  alligator1        bee2     falcon3       lion4     monkey5     parrot6      shark7      whale8      zebraViewing the last 5 lines>>>df.tail()animal4  monkey5  parrot6   shark7   whale8   zebraViewing the lastnlines (three in this case)>>>df.tail(3)animal6  shark7  whale8  zebraFor negative values ofn>>>df.tail(-3)animal3    lion4  monkey5  parrot6   shark7   whale8   zebra", "doc_id": "5f1acf15-b4ce-4941-b0bf-75ac49f5f422", "embedding": null, "doc_hash": "4d7bff8371c0bed30366710ada31b85510b2e55984952f4e513f9cd9cfd2d7ea", "extra_info": null, "node_info": {"start": 0, "end": 1141, "_node_type": "1"}, "relationships": {"1": "389521de-714f-420d-8956-caf754c8b89e"}}, "__type__": "1"}, "77061459-045e-4e65-aea0-72eecff2a97d": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.Series.value_counts\u3010Content\u3011pandas.Series.value_counts#Series.value_counts(normalize=False,sort=True,ascending=False,bins=None,dropna=True)[source]#Return a Series containing counts of unique values.The resulting object will be in descending order so that the\nfirst element is the most frequently-occurring element.\nExcludes NA values by default.Parameters:normalizebool, default FalseIf True then the object returned will contain the relative\nfrequencies of the unique values.sortbool, default TrueSort by frequencies when True. Preserve the order of the data when False.ascendingbool, default FalseSort in ascending order.binsint, optionalRather than count values, group them into half-open bins,\na convenience forpd.cut, only works with numeric data.dropnabool, default TrueDon?ft include counts of NaN.Returns:SeriesSee alsoSeries.countNumber of non-NA elements in a Series.DataFrame.countNumber of non-NA elements in a DataFrame.DataFrame.value_countsEquivalent method on DataFrames.Examples>>>index=pd.Index([3,1,2,3,4,np.nan])>>>index.value_counts()3.0    21.0    12.0    14.0    1Name: count, dtype: int64Withnormalizeset toTrue, returns the relative frequency by\ndividing all values by the sum of values.>>>s=pd.Series([3,1,2,3,4,np.nan])>>>s.value_counts(normalize=True)3.0    0.41.0    0.22.0    0.24.0    0.2Name: proportion, dtype: float64binsBins can be useful for going from a continuous variable to a\ncategorical variable; instead of counting unique\napparitions of values, divide the index in the specified\nnumber of half-open bins.>>>s.value_counts(bins=3)(0.996, 2.0]    2(2.0, 3.0]      2(3.0, 4.0]      1Name: count, dtype: int64dropnaWithdropnaset toFalsewe can also see NaN index values.>>>s.value_counts(dropna=False)3.0    21.0    12.0    14.0    1NaN    1Name: count, dtype: int64", "doc_id": "77061459-045e-4e65-aea0-72eecff2a97d", "embedding": null, "doc_hash": "d7975312aacb1758e1ea97df09ad650c7ca5e7505927c5a9e747ae6e70e49a1b", "extra_info": null, "node_info": {"start": 0, "end": 1851, "_node_type": "1"}, "relationships": {"1": "bc45a9af-4978-48e0-ab1c-27c19177cbb1"}}, "__type__": "1"}, "af6be3ee-eaa1-40b9-ba91-d4af5fcbaef6": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.idxmax\u3010Content\u3011pandas.DataFrame.idxmax#DataFrame.idxmax(axis=0,skipna=True,numeric_only=False)[source]#Return index of first occurrence of maximum over requested axis.NA/null values are excluded.Parameters:axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0The axis to use. 0 or ?eindex?f for row-wise, 1 or ?ecolumns?f for column-wise.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result\nwill be NA.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Returns:SeriesIndexes of maxima along the specified axis.Raises:ValueErrorIf the row/column is emptySee alsoSeries.idxmaxReturn index of the maximum element.NotesThis method is the DataFrame version ofndarray.argmax.ExamplesConsider a dataset containing food consumption in Argentina.>>>df=pd.DataFrame({'consumption':[10.51,103.11,55.48],...'co2_emissions':[37.2,19.66,1712]},...index=['Pork','Wheat Products','Beef'])>>>dfconsumption  co2_emissionsPork                  10.51         37.20Wheat Products       103.11         19.66Beef                  55.48       1712.00By default, it returns the index for the maximum value in each column.>>>df.idxmax()consumption     Wheat Productsco2_emissions             Beefdtype: objectTo return the index for the maximum value in each row, useaxis=\"columns\".>>>df.idxmax(axis=\"columns\")Pork              co2_emissionsWheat Products     consumptionBeef              co2_emissionsdtype: object", "doc_id": "af6be3ee-eaa1-40b9-ba91-d4af5fcbaef6", "embedding": null, "doc_hash": "cc6199f5ea2b2d297d138ae6a3f86368b5cc421c7b88e8ad5ac56d026cb91446", "extra_info": null, "node_info": {"start": 0, "end": 1514, "_node_type": "1"}, "relationships": {"1": "c9932f46-7bd2-46ba-8e03-49bc5d469d4f"}}, "__type__": "1"}, "642bfb3e-03a0-4676-a431-b883a068b147": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.dtypes\u3010Content\u3011pandas.DataFrame.dtypes#propertyDataFrame.dtypes[source]#Return the dtypes in the DataFrame.This returns a Series with the data type of each column.\nThe result?fs index is the original DataFrame?fs columns. Columns\nwith mixed types are stored with theobjectdtype. Seethe User Guidefor more.Returns:pandas.SeriesThe data type of each column.Examples>>>df=pd.DataFrame({'float':[1.0],...'int':[1],...'datetime':[pd.Timestamp('20180310')],...'string':['foo']})>>>df.dtypesfloat              float64int                  int64datetime    datetime64[ns]string              objectdtype: object", "doc_id": "642bfb3e-03a0-4676-a431-b883a068b147", "embedding": null, "doc_hash": "36fd455a53c16fd2e5e73ede599c1f0d650fc335a43344d65cdd0c395eb4be14", "extra_info": null, "node_info": {"start": 0, "end": 657, "_node_type": "1"}, "relationships": {"1": "762b8cef-a093-4edd-9738-4fe49ef50f8d"}}, "__type__": "1"}, "07b67187-0bd8-40d5-b08c-c8d77729fb85": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.set_index\u3010Content\u3011pandas.DataFrame.set_index#DataFrame.set_index(keys,*,drop=True,append=False,inplace=False,verify_integrity=False)[source]#Set the DataFrame index using existing columns.Set the DataFrame index (row labels) using one or more existing\ncolumns or arrays (of the correct length). The index can replace the\nexisting index or expand on it.Parameters:keyslabel or array-like or list of labels/arraysThis parameter can be either a single column key, a single array of\nthe same length as the calling DataFrame, or a list containing an\narbitrary combination of column keys and arrays. Here, ?garray?h\nencompassesSeries,Index,np.ndarray, and\ninstances ofIterator.dropbool, default TrueDelete columns to be used as the new index.appendbool, default FalseWhether to append columns to existing index.inplacebool, default FalseWhether to modify the DataFrame rather than creating a new one.verify_integritybool, default FalseCheck the new index for duplicates. Otherwise defer the check until\nnecessary. Setting to False will improve the performance of this\nmethod.Returns:DataFrame or NoneChanged row labels or None ifinplace=True.See alsoDataFrame.reset_indexOpposite of set_index.DataFrame.reindexChange to new indices or expand indices.DataFrame.reindex_likeChange to same indices as other DataFrame.Examples>>>df=pd.DataFrame({'month':[1,4,7,10],...'year':[2012,2014,2013,2014],...'sale':[55,40,84,31]})>>>dfmonth  year  sale0      1  2012    551      4  2014    402      7  2013    843     10  2014    31Set the index to become the ?emonth?f column:>>>df.set_index('month')year  salemonth1      2012    554      2014    407      2013    8410     2014    31Create a MultiIndex using columns ?eyear?f and ?emonth?f:>>>df.set_index(['year','month'])saleyear  month2012  1     552014  4     402013  7     842014  10    31Create a MultiIndex using an Index and a column:>>>df.set_index([pd.Index([1,2,3,4]),'year'])month  saleyear1  2012  1      552  2014  4      403  2013  7      844  2014  10     31Create a MultiIndex using two Series:>>>s=pd.Series([1,2,3,4])>>>df.set_index([s,s**2])month  year  sale1 1       1  2012    552 4       4  2014    403 9       7  2013    844 16     10  2014    31", "doc_id": "07b67187-0bd8-40d5-b08c-c8d77729fb85", "embedding": null, "doc_hash": "1ffc86971c2141e5deac9915ffdf3111ccc04a8e5f2b1832e15b3d5b503d5838", "extra_info": null, "node_info": {"start": 0, "end": 2259, "_node_type": "1"}, "relationships": {"1": "4b99342d-fec9-42eb-a553-e6ddc3e2afb1"}}, "__type__": "1"}, "6dccf2ce-c03d-49ba-afab-fd4a6507ee7c": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.Series.unique\u3010Content\u3011pandas.Series.unique#Series.unique()[source]#Return unique values of Series object.Uniques are returned in order of appearance. Hash table-based unique,\ntherefore does NOT sort.Returns:ndarray or ExtensionArrayThe unique values returned as a NumPy array. See Notes.See alsoSeries.drop_duplicatesReturn Series with duplicate values removed.uniqueTop-level unique method for any 1-d array-like object.Index.uniqueReturn Index with unique values from an Index object.NotesReturns the unique values as a NumPy array. In case of an\nextension-array backed Series, a newExtensionArrayof that type with just\nthe unique values is returned. This includesCategoricalPeriodDatetime with TimezoneDatetime without TimezoneTimedeltaIntervalSparseIntegerNASee Examples section.Examples>>>pd.Series([2,1,3,3],name='A').unique()array([2, 1, 3])>>>pd.Series([pd.Timestamp('2016-01-01')for_inrange(3)]).unique()<DatetimeArray>['2016-01-01 00:00:00']Length: 1, dtype: datetime64[ns]>>>pd.Series([pd.Timestamp('2016-01-01',tz='US/Eastern')...for_inrange(3)]).unique()<DatetimeArray>['2016-01-01 00:00:00-05:00']Length: 1, dtype: datetime64[ns, US/Eastern]An Categorical will return categories in the order of\nappearance and with the same dtype.>>>pd.Series(pd.Categorical(list('baabc'))).unique()['b', 'a', 'c']Categories (3, object): ['a', 'b', 'c']>>>pd.Series(pd.Categorical(list('baabc'),categories=list('abc'),...ordered=True)).unique()['b', 'a', 'c']Categories (3, object): ['a' < 'b' < 'c']", "doc_id": "6dccf2ce-c03d-49ba-afab-fd4a6507ee7c", "embedding": null, "doc_hash": "522a0aab7dde86638750f94bb9aafcb217c3b00b06f1e7755c491a175c88354c", "extra_info": null, "node_info": {"start": 0, "end": 1543, "_node_type": "1"}, "relationships": {"1": "172bd16d-950b-4744-94b3-ec5d6e7baa3e"}}, "__type__": "1"}, "1ac1fcff-d5c6-4eb0-95b8-5969f49866c3": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.Series.clip\u3010Content\u3011pandas.Series.clip#Series.clip(lower=None,upper=None,*,axis=None,inplace=False,**kwargs)[source]#Trim values at input threshold(s).Assigns values outside boundary to boundary values. Thresholds\ncan be singular values or array like, and in the latter case\nthe clipping is performed element-wise in the specified axis.Parameters:lowerfloat or array-like, default NoneMinimum threshold value. All values below this\nthreshold will be set to it. A missing\nthreshold (e.gNA) will not clip the value.upperfloat or array-like, default NoneMaximum threshold value. All values above this\nthreshold will be set to it. A missing\nthreshold (e.gNA) will not clip the value.axis{{0 or ?eindex?f, 1 or ?ecolumns?f, None}}, default NoneAlign object with lower and upper along the given axis.\nForSeriesthis parameter is unused and defaults toNone.inplacebool, default FalseWhether to perform the operation in place on the data.*args, **kwargsAdditional keywords have no effect but might be accepted\nfor compatibility with numpy.Returns:Series or DataFrame or NoneSame type as calling object with the values outside the\nclip boundaries replaced or None ifinplace=True.See alsoSeries.clipTrim values at input threshold in series.DataFrame.clipTrim values at input threshold in dataframe.numpy.clipClip (limit) the values in an array.Examples>>>data={'col_0':[9,-3,0,-1,5],'col_1':[-2,-7,6,8,-5]}>>>df=pd.DataFrame(data)>>>dfcol_0  col_10      9     -21     -3     -72      0      63     -1      84      5     -5Clips per column using lower and upper thresholds:>>>df.clip(-4,6)col_0  col_10      6     -21     -3     -42      0      63     -1      64      5     -4Clips using specific lower and upper thresholds per column element:>>>t=pd.Series([2,-4,-1,6,3])>>>t0    21   -42   -13    64    3dtype: int64>>>df.clip(t,t+4,axis=0)col_0  col_10      6      21     -3     -42      0      33      6      84      5      3Clips using specific lower threshold per column element, with missing values:>>>t=pd.Series([2,-4,np.nan,6,3])>>>t0    2.01   -4.02    NaN3    6.04    3.0dtype: float64>>>df.clip(t,axis=0)col_0  col_10      9      21     -3     -42      0      63      6      84      5      3", "doc_id": "1ac1fcff-d5c6-4eb0-95b8-5969f49866c3", "embedding": null, "doc_hash": "2d4dce5ec2e9ae3abc278a5744c74d7487201b7578f2c342ae21dad6842de862", "extra_info": null, "node_info": {"start": 0, "end": 2238, "_node_type": "1"}, "relationships": {"1": "895f34e7-2b9d-496a-9877-600385fb955a"}}, "__type__": "1"}, "7974763b-06c5-4c2f-a373-25e320a4bcb9": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.diff\u3010Content\u3011pandas.DataFrame.diff#DataFrame.diff(periods=1,axis=0)[source]#First discrete difference of element.Calculates the difference of a DataFrame element compared with another\nelement in the DataFrame (default is element in previous row).Parameters:periodsint, default 1Periods to shift for calculating difference, accepts negative\nvalues.axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0Take difference over rows (0) or columns (1).Returns:DataFrameFirst differences of the Series.See alsoDataFrame.pct_changePercent change over given number of periods.DataFrame.shiftShift index by desired number of periods with an optional time freq.Series.diffFirst discrete difference of object.NotesFor boolean dtypes, this usesoperator.xor()rather thanoperator.sub().\nThe result is calculated according to current dtype in DataFrame,\nhowever dtype of the result is always float64.ExamplesDifference with previous row>>>df=pd.DataFrame({'a':[1,2,3,4,5,6],...'b':[1,1,2,3,5,8],...'c':[1,4,9,16,25,36]})>>>dfa  b   c0  1  1   11  2  1   42  3  2   93  4  3  164  5  5  255  6  8  36>>>df.diff()a    b     c0  NaN  NaN   NaN1  1.0  0.0   3.02  1.0  1.0   5.03  1.0  1.0   7.04  1.0  2.0   9.05  1.0  3.0  11.0Difference with previous column>>>df.diff(axis=1)a  b   c0 NaN  0   01 NaN -1   32 NaN -1   73 NaN -1  134 NaN  0  205 NaN  2  28Difference with 3rd previous row>>>df.diff(periods=3)a    b     c0  NaN  NaN   NaN1  NaN  NaN   NaN2  NaN  NaN   NaN3  3.0  2.0  15.04  3.0  4.0  21.05  3.0  6.0  27.0Difference with following row>>>df.diff(periods=-1)a    b     c0 -1.0  0.0  -3.01 -1.0 -1.0  -5.02 -1.0 -1.0  -7.03 -1.0 -2.0  -9.04 -1.0 -3.0 -11.05  NaN  NaN   NaNOverflow in input dtype>>>df=pd.DataFrame({'a':[1,0]},dtype=np.uint8)>>>df.diff()a0    NaN1  255.0", "doc_id": "7974763b-06c5-4c2f-a373-25e320a4bcb9", "embedding": null, "doc_hash": "c298a09adf5f655de7a013950e68f7bb04ebf69090138ca8b5df190b25d49dd3", "extra_info": null, "node_info": {"start": 0, "end": 1819, "_node_type": "1"}, "relationships": {"1": "33b57311-8718-4107-9620-a7e89042259f"}}, "__type__": "1"}, "419c1ad8-d9cd-40b0-8340-fb4530048da4": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.cumsum\u3010Content\u3011pandas.DataFrame.cumsum#DataFrame.cumsum(axis=None,skipna=True,*args,**kwargs)[source]#Return cumulative sum over a DataFrame or Series axis.Returns a DataFrame or Series of the same size containing the cumulative\nsum.Parameters:axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0The index or the name of the axis. 0 is equivalent to None or ?eindex?f.\nForSeriesthis parameter is unused and defaults to 0.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result\nwill be NA.*args, **kwargsAdditional keywords have no effect but might be accepted for\ncompatibility with NumPy.Returns:Series or DataFrameReturn cumulative sum of Series or DataFrame.See alsocore.window.expanding.Expanding.sumSimilar functionality but ignoresNaNvalues.DataFrame.sumReturn the sum over DataFrame axis.DataFrame.cummaxReturn cumulative maximum over DataFrame axis.DataFrame.cumminReturn cumulative minimum over DataFrame axis.DataFrame.cumsumReturn cumulative sum over DataFrame axis.DataFrame.cumprodReturn cumulative product over DataFrame axis.ExamplesSeries>>>s=pd.Series([2,np.nan,5,-1,0])>>>s0    2.01    NaN2    5.03   -1.04    0.0dtype: float64By default, NA values are ignored.>>>s.cumsum()0    2.01    NaN2    7.03    6.04    6.0dtype: float64To include NA values in the operation, useskipna=False>>>s.cumsum(skipna=False)0    2.01    NaN2    NaN3    NaN4    NaNdtype: float64DataFrame>>>df=pd.DataFrame([[2.0,1.0],...[3.0,np.nan],...[1.0,0.0]],...columns=list('AB'))>>>dfA    B0  2.0  1.01  3.0  NaN2  1.0  0.0By default, iterates over rows and finds the sum\nin each column. This is equivalent toaxis=Noneoraxis='index'.>>>df.cumsum()A    B0  2.0  1.01  5.0  NaN2  6.0  1.0To iterate over columns and find the sum in each row,\nuseaxis=1>>>df.cumsum(axis=1)A    B0  2.0  3.01  3.0  NaN2  1.0  1.0", "doc_id": "419c1ad8-d9cd-40b0-8340-fb4530048da4", "embedding": null, "doc_hash": "c60c639904a0538d4d24f4a380de0719381cc53a2d233a6aca376d6693f68fca", "extra_info": null, "node_info": {"start": 0, "end": 1886, "_node_type": "1"}, "relationships": {"1": "ed96a6e6-c840-4bfd-a386-5be441da6823"}}, "__type__": "1"}, "4bda8ae8-547f-4e56-9321-d6df14b58676": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.cumprod\u3010Content\u3011pandas.DataFrame.cumprod#DataFrame.cumprod(axis=None,skipna=True,*args,**kwargs)[source]#Return cumulative product over a DataFrame or Series axis.Returns a DataFrame or Series of the same size containing the cumulative\nproduct.Parameters:axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0The index or the name of the axis. 0 is equivalent to None or ?eindex?f.\nForSeriesthis parameter is unused and defaults to 0.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result\nwill be NA.*args, **kwargsAdditional keywords have no effect but might be accepted for\ncompatibility with NumPy.Returns:Series or DataFrameReturn cumulative product of Series or DataFrame.See alsocore.window.expanding.Expanding.prodSimilar functionality but ignoresNaNvalues.DataFrame.prodReturn the product over DataFrame axis.DataFrame.cummaxReturn cumulative maximum over DataFrame axis.DataFrame.cumminReturn cumulative minimum over DataFrame axis.DataFrame.cumsumReturn cumulative sum over DataFrame axis.DataFrame.cumprodReturn cumulative product over DataFrame axis.ExamplesSeries>>>s=pd.Series([2,np.nan,5,-1,0])>>>s0    2.01    NaN2    5.03   -1.04    0.0dtype: float64By default, NA values are ignored.>>>s.cumprod()0     2.01     NaN2    10.03   -10.04    -0.0dtype: float64To include NA values in the operation, useskipna=False>>>s.cumprod(skipna=False)0    2.01    NaN2    NaN3    NaN4    NaNdtype: float64DataFrame>>>df=pd.DataFrame([[2.0,1.0],...[3.0,np.nan],...[1.0,0.0]],...columns=list('AB'))>>>dfA    B0  2.0  1.01  3.0  NaN2  1.0  0.0By default, iterates over rows and finds the product\nin each column. This is equivalent toaxis=Noneoraxis='index'.>>>df.cumprod()A    B0  2.0  1.01  6.0  NaN2  6.0  0.0To iterate over columns and find the product in each row,\nuseaxis=1>>>df.cumprod(axis=1)A    B0  2.0  2.01  3.0  NaN2  1.0  0.0", "doc_id": "4bda8ae8-547f-4e56-9321-d6df14b58676", "embedding": null, "doc_hash": "d947ea019c080bb7226050eb55a3c24e1e6a0c297bf70126afe19d0ccfa130c4", "extra_info": null, "node_info": {"start": 0, "end": 1924, "_node_type": "1"}, "relationships": {"1": "cd7a7c60-93bc-47c8-8ce6-f5143759f9f1"}}, "__type__": "1"}, "787b5c70-f995-4b8c-a4b6-f97aa6a39a17": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.cummax\u3010Content\u3011pandas.DataFrame.cummax#DataFrame.cummax(axis=None,skipna=True,*args,**kwargs)[source]#Return cumulative maximum over a DataFrame or Series axis.Returns a DataFrame or Series of the same size containing the cumulative\nmaximum.Parameters:axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0The index or the name of the axis. 0 is equivalent to None or ?eindex?f.\nForSeriesthis parameter is unused and defaults to 0.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result\nwill be NA.*args, **kwargsAdditional keywords have no effect but might be accepted for\ncompatibility with NumPy.Returns:Series or DataFrameReturn cumulative maximum of Series or DataFrame.See alsocore.window.expanding.Expanding.maxSimilar functionality but ignoresNaNvalues.DataFrame.maxReturn the maximum over DataFrame axis.DataFrame.cummaxReturn cumulative maximum over DataFrame axis.DataFrame.cumminReturn cumulative minimum over DataFrame axis.DataFrame.cumsumReturn cumulative sum over DataFrame axis.DataFrame.cumprodReturn cumulative product over DataFrame axis.ExamplesSeries>>>s=pd.Series([2,np.nan,5,-1,0])>>>s0    2.01    NaN2    5.03   -1.04    0.0dtype: float64By default, NA values are ignored.>>>s.cummax()0    2.01    NaN2    5.03    5.04    5.0dtype: float64To include NA values in the operation, useskipna=False>>>s.cummax(skipna=False)0    2.01    NaN2    NaN3    NaN4    NaNdtype: float64DataFrame>>>df=pd.DataFrame([[2.0,1.0],...[3.0,np.nan],...[1.0,0.0]],...columns=list('AB'))>>>dfA    B0  2.0  1.01  3.0  NaN2  1.0  0.0By default, iterates over rows and finds the maximum\nin each column. This is equivalent toaxis=Noneoraxis='index'.>>>df.cummax()A    B0  2.0  1.01  3.0  NaN2  3.0  1.0To iterate over columns and find the maximum in each row,\nuseaxis=1>>>df.cummax(axis=1)A    B0  2.0  2.01  3.0  NaN2  1.0  1.0", "doc_id": "787b5c70-f995-4b8c-a4b6-f97aa6a39a17", "embedding": null, "doc_hash": "0b3270a9c469bb6fb13371b6bc8f493f844b785eda9fb6a491ecc93d4729bd22", "extra_info": null, "node_info": {"start": 0, "end": 1910, "_node_type": "1"}, "relationships": {"1": "88524674-45ae-445a-bce7-3cd9feb65bce"}}, "__type__": "1"}, "8c7774c9-7e2e-42ad-acc0-99315cbb291e": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.cummin\u3010Content\u3011pandas.DataFrame.cummin#DataFrame.cummin(axis=None,skipna=True,*args,**kwargs)[source]#Return cumulative minimum over a DataFrame or Series axis.Returns a DataFrame or Series of the same size containing the cumulative\nminimum.Parameters:axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0The index or the name of the axis. 0 is equivalent to None or ?eindex?f.\nForSeriesthis parameter is unused and defaults to 0.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result\nwill be NA.*args, **kwargsAdditional keywords have no effect but might be accepted for\ncompatibility with NumPy.Returns:Series or DataFrameReturn cumulative minimum of Series or DataFrame.See alsocore.window.expanding.Expanding.minSimilar functionality but ignoresNaNvalues.DataFrame.minReturn the minimum over DataFrame axis.DataFrame.cummaxReturn cumulative maximum over DataFrame axis.DataFrame.cumminReturn cumulative minimum over DataFrame axis.DataFrame.cumsumReturn cumulative sum over DataFrame axis.DataFrame.cumprodReturn cumulative product over DataFrame axis.ExamplesSeries>>>s=pd.Series([2,np.nan,5,-1,0])>>>s0    2.01    NaN2    5.03   -1.04    0.0dtype: float64By default, NA values are ignored.>>>s.cummin()0    2.01    NaN2    2.03   -1.04   -1.0dtype: float64To include NA values in the operation, useskipna=False>>>s.cummin(skipna=False)0    2.01    NaN2    NaN3    NaN4    NaNdtype: float64DataFrame>>>df=pd.DataFrame([[2.0,1.0],...[3.0,np.nan],...[1.0,0.0]],...columns=list('AB'))>>>dfA    B0  2.0  1.01  3.0  NaN2  1.0  0.0By default, iterates over rows and finds the minimum\nin each column. This is equivalent toaxis=Noneoraxis='index'.>>>df.cummin()A    B0  2.0  1.01  2.0  NaN2  1.0  0.0To iterate over columns and find the minimum in each row,\nuseaxis=1>>>df.cummin(axis=1)A    B0  2.0  1.01  3.0  NaN2  1.0  0.0", "doc_id": "8c7774c9-7e2e-42ad-acc0-99315cbb291e", "embedding": null, "doc_hash": "1aed7df43535158e2ab7410f5444495bdbd9fca93d911ffaacf12921686302f9", "extra_info": null, "node_info": {"start": 0, "end": 1910, "_node_type": "1"}, "relationships": {"1": "dbf2310a-15ad-484f-99cc-76c0495b2b56"}}, "__type__": "1"}, "424cd141-cc31-45ce-9ac6-0c726d88962c": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.mean\u3010Content\u3011pandas.DataFrame.mean#DataFrame.mean(axis=0,skipna=True,numeric_only=False,**kwargs)[source]#Return the mean of the values over the requested axis.Parameters:axis{index (0), columns (1)}Axis for the function to be applied on.\nForSeriesthis parameter is unused and defaults to 0.For DataFrames, specifyingaxis=Nonewill apply the aggregation\nacross both axes.New in version 2.0.0.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.**kwargsAdditional keyword arguments to be passed to the function.Returns:Series or scalarExamples>>>s=pd.Series([1,2,3])>>>s.mean()2.0With a DataFrame>>>df=pd.DataFrame({'a':[1,2],'b':[2,3]},index=['tiger','zebra'])>>>dfa   btiger  1   2zebra  2   3>>>df.mean()a   1.5b   2.5dtype: float64Using axis=1>>>df.mean(axis=1)tiger   1.5zebra   2.5dtype: float64In this case,numeric_onlyshould be set toTrueto avoid\ngetting an error.>>>df=pd.DataFrame({'a':[1,2],'b':['T','Z']},...index=['tiger','zebra'])>>>df.mean(numeric_only=True)a   1.5dtype: float64", "doc_id": "424cd141-cc31-45ce-9ac6-0c726d88962c", "embedding": null, "doc_hash": "28033cf4ae010d655b2d1058be530fb437c34ecaddf48d247897480dbe511aef", "extra_info": null, "node_info": {"start": 0, "end": 1169, "_node_type": "1"}, "relationships": {"1": "51b5d81e-792a-4c92-8df4-7a7eb132fdda"}}, "__type__": "1"}, "0546b7b1-2beb-449e-9644-eb2bc500beb6": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.median\u3010Content\u3011pandas.DataFrame.median#DataFrame.median(axis=0,skipna=True,numeric_only=False,**kwargs)[source]#Return the median of the values over the requested axis.Parameters:axis{index (0), columns (1)}Axis for the function to be applied on.\nForSeriesthis parameter is unused and defaults to 0.For DataFrames, specifyingaxis=Nonewill apply the aggregation\nacross both axes.New in version 2.0.0.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.**kwargsAdditional keyword arguments to be passed to the function.Returns:Series or scalarExamples>>>s=pd.Series([1,2,3])>>>s.median()2.0With a DataFrame>>>df=pd.DataFrame({'a':[1,2],'b':[2,3]},index=['tiger','zebra'])>>>dfa   btiger  1   2zebra  2   3>>>df.median()a   1.5b   2.5dtype: float64Using axis=1>>>df.median(axis=1)tiger   1.5zebra   2.5dtype: float64In this case,numeric_onlyshould be set toTrueto avoid getting an error.>>>df=pd.DataFrame({'a':[1,2],'b':['T','Z']},...index=['tiger','zebra'])>>>df.median(numeric_only=True)a   1.5dtype: float64", "doc_id": "0546b7b1-2beb-449e-9644-eb2bc500beb6", "embedding": null, "doc_hash": "19d0a58fc4207b8c07cbea79d518753f02fb2fe440751635c356f988994d6930", "extra_info": null, "node_info": {"start": 0, "end": 1185, "_node_type": "1"}, "relationships": {"1": "1465b92f-69ab-4b88-9360-9f5a8a5126a3"}}, "__type__": "1"}, "bf5edab7-70f9-4edc-88b5-6d9137771220": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.sum\u3010Content\u3011pandas.DataFrame.sum#DataFrame.sum(axis=0,skipna=True,numeric_only=False,min_count=0,**kwargs)[source]#Return the sum of the values over the requested axis.This is equivalent to the methodnumpy.sum.Parameters:axis{index (0), columns (1)}Axis for the function to be applied on.\nForSeriesthis parameter is unused and defaults to 0.For DataFrames, specifyingaxis=Nonewill apply the aggregation\nacross both axes.New in version 2.0.0.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.min_countint, default 0The required number of valid values to perform the operation. If fewer thanmin_countnon-NA values are present the result will be NA.**kwargsAdditional keyword arguments to be passed to the function.Returns:Series or scalarSee alsoSeries.sumReturn the sum.Series.minReturn the minimum.Series.maxReturn the maximum.Series.idxminReturn the index of the minimum.Series.idxmaxReturn the index of the maximum.DataFrame.sumReturn the sum over the requested axis.DataFrame.minReturn the minimum over the requested axis.DataFrame.maxReturn the maximum over the requested axis.DataFrame.idxminReturn the index of the minimum over the requested axis.DataFrame.idxmaxReturn the index of the maximum over the requested axis.Examples>>>idx=pd.MultiIndex.from_arrays([...['warm','warm','cold','cold'],...['dog','falcon','fish','spider']],...names=['blooded','animal'])>>>s=pd.Series([4,2,0,8],name='legs',index=idx)>>>sblooded  animalwarm     dog       4falcon    2cold     fish      0spider    8Name: legs, dtype: int64>>>s.sum()14By default, the sum of an empty or all-NA Series is0.>>>pd.Series([],dtype=\"float64\").sum()# min_count=0 is the default0.0This can be controlled with themin_countparameter. For example, if\nyou?fd like the sum of an empty series to be NaN, passmin_count=1.>>>pd.Series([],dtype=\"float64\").sum(min_count=1)nanThanks to theskipnaparameter,min_counthandles all-NA and\nempty series identically.>>>pd.Series([np.nan]).sum()0.0>>>pd.Series([np.nan]).sum(min_count=1)nan", "doc_id": "bf5edab7-70f9-4edc-88b5-6d9137771220", "embedding": null, "doc_hash": "ea9b69f0d84ac822b2a8869db7827b935904306c9f6bbb05ff0d19bc23dac8fa", "extra_info": null, "node_info": {"start": 0, "end": 2172, "_node_type": "1"}, "relationships": {"1": "e6ec4e97-0a7d-4c63-b620-ebd7e88fc0ca"}}, "__type__": "1"}, "f83640b1-bf3a-49cf-831e-a9f9a718d440": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.min\u3010Content\u3011pandas.DataFrame.min#DataFrame.min(axis=0,skipna=True,numeric_only=False,**kwargs)[source]#Return the minimum of the values over the requested axis.If you want theindexof the minimum, useidxmin. This is the equivalent of thenumpy.ndarraymethodargmin.Parameters:axis{index (0), columns (1)}Axis for the function to be applied on.\nForSeriesthis parameter is unused and defaults to 0.For DataFrames, specifyingaxis=Nonewill apply the aggregation\nacross both axes.New in version 2.0.0.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.**kwargsAdditional keyword arguments to be passed to the function.Returns:Series or scalarSee alsoSeries.sumReturn the sum.Series.minReturn the minimum.Series.maxReturn the maximum.Series.idxminReturn the index of the minimum.Series.idxmaxReturn the index of the maximum.DataFrame.sumReturn the sum over the requested axis.DataFrame.minReturn the minimum over the requested axis.DataFrame.maxReturn the maximum over the requested axis.DataFrame.idxminReturn the index of the minimum over the requested axis.DataFrame.idxmaxReturn the index of the maximum over the requested axis.Examples>>>idx=pd.MultiIndex.from_arrays([...['warm','warm','cold','cold'],...['dog','falcon','fish','spider']],...names=['blooded','animal'])>>>s=pd.Series([4,2,0,8],name='legs',index=idx)>>>sblooded  animalwarm     dog       4falcon    2cold     fish      0spider    8Name: legs, dtype: int64>>>s.min()0", "doc_id": "f83640b1-bf3a-49cf-831e-a9f9a718d440", "embedding": null, "doc_hash": "8ec16ec51885457953752614d31ee4ab719ea6571db316002196c6ed012f09bf", "extra_info": null, "node_info": {"start": 0, "end": 1606, "_node_type": "1"}, "relationships": {"1": "e0d962ec-c1d1-400d-ac9a-d546ab932031"}}, "__type__": "1"}, "c7aa52a7-bf72-4295-ae45-98ec6a8d1506": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.max\u3010Content\u3011pandas.DataFrame.max#DataFrame.max(axis=0,skipna=True,numeric_only=False,**kwargs)[source]#Return the maximum of the values over the requested axis.If you want theindexof the maximum, useidxmax. This is the equivalent of thenumpy.ndarraymethodargmax.Parameters:axis{index (0), columns (1)}Axis for the function to be applied on.\nForSeriesthis parameter is unused and defaults to 0.For DataFrames, specifyingaxis=Nonewill apply the aggregation\nacross both axes.New in version 2.0.0.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.**kwargsAdditional keyword arguments to be passed to the function.Returns:Series or scalarSee alsoSeries.sumReturn the sum.Series.minReturn the minimum.Series.maxReturn the maximum.Series.idxminReturn the index of the minimum.Series.idxmaxReturn the index of the maximum.DataFrame.sumReturn the sum over the requested axis.DataFrame.minReturn the minimum over the requested axis.DataFrame.maxReturn the maximum over the requested axis.DataFrame.idxminReturn the index of the minimum over the requested axis.DataFrame.idxmaxReturn the index of the maximum over the requested axis.Examples>>>idx=pd.MultiIndex.from_arrays([...['warm','warm','cold','cold'],...['dog','falcon','fish','spider']],...names=['blooded','animal'])>>>s=pd.Series([4,2,0,8],name='legs',index=idx)>>>sblooded  animalwarm     dog       4falcon    2cold     fish      0spider    8Name: legs, dtype: int64>>>s.max()8", "doc_id": "c7aa52a7-bf72-4295-ae45-98ec6a8d1506", "embedding": null, "doc_hash": "d1ec5a7a10d8a624fd68e31c2cf1b17e6eaedf76550f42076f79f57088112b3f", "extra_info": null, "node_info": {"start": 0, "end": 1606, "_node_type": "1"}, "relationships": {"1": "bb718a40-40e6-41e4-8332-c92cc79ad239"}}, "__type__": "1"}, "7910fb65-c533-4a28-a783-e1552f2b8c37": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.std\u3010Content\u3011pandas.DataFrame.std#DataFrame.std(axis=0,skipna=True,ddof=1,numeric_only=False,**kwargs)[source]#Return sample standard deviation over requested axis.Normalized by N-1 by default. This can be changed using the ddof argument.Parameters:axis{index (0), columns (1)}ForSeriesthis parameter is unused and defaults to 0.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result\nwill be NA.ddofint, default 1Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.Returns:Series or DataFrame (if level specified)NotesTo have the same behaviour asnumpy.std, useddof=0(instead of the\ndefaultddof=1)Examples>>>df=pd.DataFrame({'person_id':[0,1,2,3],...'age':[21,25,62,43],...'height':[1.61,1.87,1.49,2.01]}...).set_index('person_id')>>>dfage  heightperson_id0           21    1.611           25    1.872           62    1.493           43    2.01The standard deviation of the columns can be found as follows:>>>df.std()age       18.786076height     0.237417dtype: float64Alternatively,ddof=0can be set to normalize by N instead of N-1:>>>df.std(ddof=0)age       16.269219height     0.205609dtype: float64", "doc_id": "7910fb65-c533-4a28-a783-e1552f2b8c37", "embedding": null, "doc_hash": "57d1a81564d3580838aff55783859218352a2e2a49d0c2434c7a2bf9a8dce96d", "extra_info": null, "node_info": {"start": 0, "end": 1354, "_node_type": "1"}, "relationships": {"1": "c9d11f43-2de3-42a9-b523-8225a085e473"}}, "__type__": "1"}, "b024ad80-ea9c-462d-9d1c-cf46942f1f56": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.var\u3010Content\u3011pandas.DataFrame.var#DataFrame.var(axis=0,skipna=True,ddof=1,numeric_only=False,**kwargs)[source]#Return unbiased variance over requested axis.Normalized by N-1 by default. This can be changed using the ddof argument.Parameters:axis{index (0), columns (1)}ForSeriesthis parameter is unused and defaults to 0.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result\nwill be NA.ddofint, default 1Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.Returns:Series or DataFrame (if level specified)Examples>>>df=pd.DataFrame({'person_id':[0,1,2,3],...'age':[21,25,62,43],...'height':[1.61,1.87,1.49,2.01]}...).set_index('person_id')>>>dfage  heightperson_id0           21    1.611           25    1.872           62    1.493           43    2.01>>>df.var()age       352.916667height      0.056367dtype: float64Alternatively,ddof=0can be set to normalize by N instead of N-1:>>>df.var(ddof=0)age       264.687500height      0.042275dtype: float64", "doc_id": "b024ad80-ea9c-462d-9d1c-cf46942f1f56", "embedding": null, "doc_hash": "2c57ff3e23b1ff2f38cfe9ac174c18a12dc13be1baf689509f3190ca0d0c909a", "extra_info": null, "node_info": {"start": 0, "end": 1204, "_node_type": "1"}, "relationships": {"1": "aeda5bd8-675b-4d70-9aae-5e7784ead1b6"}}, "__type__": "1"}, "61e83df3-39a7-44e7-be17-6bd1620ebbe7": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.skew\u3010Content\u3011pandas.DataFrame.skew#DataFrame.skew(axis=0,skipna=True,numeric_only=False,**kwargs)[source]#Return unbiased skew over requested axis.Normalized by N-1.Parameters:axis{index (0), columns (1)}Axis for the function to be applied on.\nForSeriesthis parameter is unused and defaults to 0.For DataFrames, specifyingaxis=Nonewill apply the aggregation\nacross both axes.New in version 2.0.0.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.**kwargsAdditional keyword arguments to be passed to the function.Returns:Series or scalarExamples>>>s=pd.Series([1,2,3])>>>s.skew()0.0With a DataFrame>>>df=pd.DataFrame({'a':[1,2,3],'b':[2,3,4],'c':[1,3,5]},...index=['tiger','zebra','cow'])>>>dfa   b   ctiger   1   2   1zebra   2   3   3cow     3   4   5>>>df.skew()a   0.0b   0.0c   0.0dtype: float64Using axis=1>>>df.skew(axis=1)tiger   1.732051zebra  -1.732051cow     0.000000dtype: float64In this case,numeric_onlyshould be set toTrueto avoid\ngetting an error.>>>df=pd.DataFrame({'a':[1,2,3],'b':['T','Z','X']},...index=['tiger','zebra','cow'])>>>df.skew(numeric_only=True)a   0.0dtype: float64", "doc_id": "61e83df3-39a7-44e7-be17-6bd1620ebbe7", "embedding": null, "doc_hash": "d9f574e3614899892869a11098db1efeebadf8abb9c4b12c4760728ffc1016f7", "extra_info": null, "node_info": {"start": 0, "end": 1275, "_node_type": "1"}, "relationships": {"1": "468a47d4-ef37-42aa-8bfc-2322fd76a4dd"}}, "__type__": "1"}, "e272a857-e791-4dc2-b006-d45e5fed598a": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.kurt\u3010Content\u3011pandas.DataFrame.kurt#DataFrame.kurt(axis=0,skipna=True,numeric_only=False,**kwargs)[source]#Return unbiased kurtosis over requested axis.Kurtosis obtained using Fisher?fs definition of\nkurtosis (kurtosis of normal == 0.0). Normalized by N-1.Parameters:axis{index (0), columns (1)}Axis for the function to be applied on.\nForSeriesthis parameter is unused and defaults to 0.For DataFrames, specifyingaxis=Nonewill apply the aggregation\nacross both axes.New in version 2.0.0.skipnabool, default TrueExclude NA/null values when computing the result.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.**kwargsAdditional keyword arguments to be passed to the function.Returns:Series or scalarExamples>>>s=pd.Series([1,2,2,3],index=['cat','dog','dog','mouse'])>>>scat    1dog    2dog    2mouse  3dtype: int64>>>s.kurt()1.5With a DataFrame>>>df=pd.DataFrame({'a':[1,2,2,3],'b':[3,4,4,4]},...index=['cat','dog','dog','mouse'])>>>dfa   bcat  1   3dog  2   4dog  2   4mouse  3   4>>>df.kurt()a   1.5b   4.0dtype: float64With axis=None>>>df.kurt(axis=None).round(6)-0.988693Using axis=1>>>df=pd.DataFrame({'a':[1,2],'b':[3,4],'c':[3,4],'d':[1,2]},...index=['cat','dog'])>>>df.kurt(axis=1)cat   -6.0dog   -6.0dtype: float64", "doc_id": "e272a857-e791-4dc2-b006-d45e5fed598a", "embedding": null, "doc_hash": "d62b1e8b616359c6d7f1633d9b97046975a05a7fc658c66373d1145c9b9e31cf", "extra_info": null, "node_info": {"start": 0, "end": 1329, "_node_type": "1"}, "relationships": {"1": "afa2205d-6815-4ce4-befa-4229ac2a8de0"}}, "__type__": "1"}, "0f234ad5-3f00-44aa-acf2-aeab45705c70": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.sem\u3010Content\u3011pandas.DataFrame.sem#DataFrame.sem(axis=0,skipna=True,ddof=1,numeric_only=False,**kwargs)[source]#Return unbiased standard error of the mean over requested axis.Normalized by N-1 by default. This can be changed using the ddof argumentParameters:axis{index (0), columns (1)}ForSeriesthis parameter is unused and defaults to 0.skipnabool, default TrueExclude NA/null values. If an entire row/column is NA, the result\nwill be NA.ddofint, default 1Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\nwhere N represents the number of elements.numeric_onlybool, default FalseInclude only float, int, boolean columns. Not implemented for Series.Returns:Series or DataFrame (if level specified)Examples>>>s=pd.Series([1,2,3])>>>s.sem().round(6)0.57735With a DataFrame>>>df=pd.DataFrame({'a':[1,2],'b':[2,3]},index=['tiger','zebra'])>>>dfa   btiger  1   2zebra  2   3>>>df.sem()a   0.5b   0.5dtype: float64Using axis=1>>>df.sem(axis=1)tiger   0.5zebra   0.5dtype: float64In this case,numeric_onlyshould be set toTrueto avoid getting an error.>>>df=pd.DataFrame({'a':[1,2],'b':['T','Z']},...index=['tiger','zebra'])>>>df.sem(numeric_only=True)a   0.5dtype: float64", "doc_id": "0f234ad5-3f00-44aa-acf2-aeab45705c70", "embedding": null, "doc_hash": "90a4b5437077345de804bf561d77001f0086599b09127e46d9c79c476688fb81", "extra_info": null, "node_info": {"start": 0, "end": 1242, "_node_type": "1"}, "relationships": {"1": "fe1f9849-aa2e-4a11-b0fb-e6897dfe4f58"}}, "__type__": "1"}, "a3491f0a-40ae-44ac-b2e6-091baffbd9df": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.quantile\u3010Content\u3011pandas.DataFrame.quantile#DataFrame.quantile(q=0.5,axis=0,numeric_only=False,interpolation='linear',method='single')[source]#Return values at the given quantile over requested axis.Parameters:qfloat or array-like, default 0.5 (50% quantile)Value between 0 <= q <= 1, the quantile(s) to compute.axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0Equals 0 or ?eindex?f for row-wise, 1 or ?ecolumns?f for column-wise.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.Changed in version 2.0.0:The default value ofnumeric_onlyis nowFalse.interpolation{?elinear?f, ?elower?f, ?ehigher?f, ?emidpoint?f, ?enearest?f}This optional parameter specifies the interpolation method to use,\nwhen the desired quantile lies between two data pointsiandj:linear:i + (j - i) * fraction, wherefractionis the\nfractional part of the index surrounded byiandj.lower:i.higher:j.nearest:iorjwhichever is nearest.midpoint: (i+j) / 2.method{?esingle?f, ?etable?f}, default ?esingle?fWhether to compute quantiles per-column (?esingle?f) or over all columns\n(?etable?f). When ?etable?f, the only allowed interpolation methods are\n?enearest?f, ?elower?f, and ?ehigher?f.Returns:Series or DataFrameIfqis an array, a DataFrame will be returned where theindex isq, the columns are the columns of self, and the\nvalues are the quantiles.Ifqis a float, a Series will be returned where theindex is the columns of self and the values are the quantiles.See alsocore.window.rolling.Rolling.quantileRolling quantile.numpy.percentileNumpy function to compute the percentile.Examples>>>df=pd.DataFrame(np.array([[1,1],[2,10],[3,100],[4,100]]),...columns=['a','b'])>>>df.quantile(.1)a    1.3b    3.7Name: 0.1, dtype: float64>>>df.quantile([.1,.5])a     b0.1  1.3   3.70.5  2.5  55.0Specifyingmethod=?ftable?fwill compute the quantile over all columns.>>>df.quantile(.1,method=\"table\",interpolation=\"nearest\")a    1b    1Name: 0.1, dtype: int64>>>df.quantile([.1,.5],method=\"table\",interpolation=\"nearest\")a    b0.1  1    10.5  3  100Specifyingnumeric_only=Falsewill also compute the quantile of\ndatetime and timedelta data.>>>df=pd.DataFrame({'A':[1,2],...'B':[pd.Timestamp('2010'),...pd.Timestamp('2011')],...'C':[pd.Timedelta('1 days'),...pd.Timedelta('2 days')]})>>>df.quantile(0.5,numeric_only=False)A                    1.5B    2010-07-02 12:00:00C        1 days 12:00:00Name: 0.5, dtype: object", "doc_id": "a3491f0a-40ae-44ac-b2e6-091baffbd9df", "embedding": null, "doc_hash": "036afdf50bde1034a89a7b81cd86417e84735d06904ef76a3ab4a4908e1b29d9", "extra_info": null, "node_info": {"start": 0, "end": 2440, "_node_type": "1"}, "relationships": {"1": "af8a56a8-f890-4460-a2c1-28f861c5aedf"}}, "__type__": "1"}, "0c1c976f-369c-4165-b993-4db44ef4718f": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.corr\u3010Content\u3011pandas.DataFrame.corr#DataFrame.corr(method='pearson',min_periods=1,numeric_only=False)[source]#Compute pairwise correlation of columns, excluding NA/null values.Parameters:method{?epearson?f, ?ekendall?f, ?espearman?f} or callableMethod of correlation:pearson : standard correlation coefficientkendall : Kendall Tau correlation coefficientspearman : Spearman rank correlationcallable: callable with input two 1d ndarraysand returning a float. Note that the returned matrix from corr\nwill have 1 along the diagonals and will be symmetric\nregardless of the callable?fs behavior.min_periodsint, optionalMinimum number of observations required per pair of columns\nto have a valid result. Currently only available for Pearson\nand Spearman correlation.numeric_onlybool, default FalseInclude onlyfloat,intorbooleandata.New in version 1.5.0.Changed in version 2.0.0:The default value ofnumeric_onlyis nowFalse.Returns:DataFrameCorrelation matrix.See alsoDataFrame.corrwithCompute pairwise correlation with another DataFrame or Series.Series.corrCompute the correlation between two Series.NotesPearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.Pearson correlation coefficientKendall rank correlation coefficientSpearman?fs rank correlation coefficientExamples>>>defhistogram_intersection(a,b):...v=np.minimum(a,b).sum().round(decimals=1)...returnv>>>df=pd.DataFrame([(.2,.3),(.0,.6),(.6,.0),(.2,.1)],...columns=['dogs','cats'])>>>df.corr(method=histogram_intersection)dogs  catsdogs   1.0   0.3cats   0.3   1.0>>>df=pd.DataFrame([(1,1),(2,np.nan),(np.nan,3),(4,4)],...columns=['dogs','cats'])>>>df.corr(min_periods=3)dogs  catsdogs   1.0   NaNcats   NaN   1.0", "doc_id": "0c1c976f-369c-4165-b993-4db44ef4718f", "embedding": null, "doc_hash": "56cdeec2ec01f2f3c70510980cbadfe9a2bb5455f7d416b7a6921a6f2e1aaf5c", "extra_info": null, "node_info": {"start": 0, "end": 1772, "_node_type": "1"}, "relationships": {"1": "eb90b7af-d851-422e-8994-49769682193e"}}, "__type__": "1"}, "b890918c-2c74-42b6-b23d-7ca56a623d7c": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.mode\u3010Content\u3011pandas.DataFrame.mode#DataFrame.mode(axis=0,numeric_only=False,dropna=True)[source]#Get the mode(s) of each element along the selected axis.The mode of a set of values is the value that appears most often.\nIt can be multiple values.Parameters:axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0The axis to iterate over while searching for the mode:0 or ?eindex?f : get mode of each column1 or ?ecolumns?f : get mode of each row.numeric_onlybool, default FalseIf True, only apply to numeric columns.dropnabool, default TrueDon?ft consider counts of NaN/NaT.Returns:DataFrameThe modes of each column or row.See alsoSeries.modeReturn the highest frequency value in a Series.Series.value_countsReturn the counts of values in a Series.Examples>>>df=pd.DataFrame([('bird',2,2),...('mammal',4,np.nan),...('arthropod',8,0),...('bird',2,np.nan)],...index=('falcon','horse','spider','ostrich'),...columns=('species','legs','wings'))>>>dfspecies  legs  wingsfalcon        bird     2    2.0horse       mammal     4    NaNspider   arthropod     8    0.0ostrich       bird     2    NaNBy default, missing values are not considered, and the mode of wings\nare both 0 and 2. Because the resulting DataFrame has two rows,\nthe second row ofspeciesandlegscontainsNaN.>>>df.mode()species  legs  wings0    bird   2.0    0.01     NaN   NaN    2.0Settingdropna=FalseNaNvalues are considered and they can be\nthe mode (like for wings).>>>df.mode(dropna=False)species  legs  wings0    bird     2    NaNSettingnumeric_only=True, only the mode of numeric columns is\ncomputed, and columns of other types are ignored.>>>df.mode(numeric_only=True)legs  wings0   2.0    0.01   NaN    2.0To compute the mode over columns and not rows, use the axis parameter:>>>df.mode(axis='columns',numeric_only=True)0    1falcon   2.0  NaNhorse    4.0  NaNspider   0.0  8.0ostrich  2.0  NaN", "doc_id": "b890918c-2c74-42b6-b23d-7ca56a623d7c", "embedding": null, "doc_hash": "7b5822e9e2a5c295e5540efa237c8597278c005e733a70d31dc115a6869798e4", "extra_info": null, "node_info": {"start": 0, "end": 1909, "_node_type": "1"}, "relationships": {"1": "6fbafa42-9168-41c7-aea7-5e2666c48d14"}}, "__type__": "1"}, "eb32a0eb-ce0b-47c1-9259-1164981953e1": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.abs\u3010Content\u3011pandas.DataFrame.abs#DataFrame.abs()[source]#Return a Series/DataFrame with absolute numeric value of each element.This function only applies to elements that are all numeric.Returns:absSeries/DataFrame containing the absolute value of each element.See alsonumpy.absoluteCalculate the absolute value element-wise.NotesForcomplexinputs,1.2+1j, the absolute value is\\(\\sqrt{ a^2 + b^2 }\\).ExamplesAbsolute numeric values in a Series.>>>s=pd.Series([-1.10,2,-3.33,4])>>>s.abs()0    1.101    2.002    3.333    4.00dtype: float64Absolute numeric values in a Series with complex numbers.>>>s=pd.Series([1.2+1j])>>>s.abs()0    1.56205dtype: float64Absolute numeric values in a Series with a Timedelta element.>>>s=pd.Series([pd.Timedelta('1 days')])>>>s.abs()0   1 daysdtype: timedelta64[ns]Select rows with data closest to certain value using argsort (fromStackOverflow).>>>df=pd.DataFrame({...'a':[4,5,6,7],...'b':[10,20,30,40],...'c':[100,50,-30,-50]...})>>>dfa    b    c0    4   10  1001    5   20   502    6   30  -303    7   40  -50>>>df.loc[(df.c-43).abs().argsort()]a    b    c1    5   20   500    4   10  1002    6   30  -303    7   40  -50", "doc_id": "eb32a0eb-ce0b-47c1-9259-1164981953e1", "embedding": null, "doc_hash": "af6e27c01b60e1a96dc8ac632f24800037864b67c6fd349ada4f0c9675e08037", "extra_info": null, "node_info": {"start": 0, "end": 1210, "_node_type": "1"}, "relationships": {"1": "91227d93-2c2b-4263-9de1-0f5bfd5795a5"}}, "__type__": "1"}, "84517590-4cdf-4808-9700-a047fe181585": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.round\u3010Content\u3011pandas.DataFrame.round#DataFrame.round(decimals=0,*args,**kwargs)[source]#Round a DataFrame to a variable number of decimal places.Parameters:decimalsint, dict, SeriesNumber of decimal places to round each column to. If an int is\ngiven, round each column to the same number of places.\nOtherwise dict and Series round to variable numbers of places.\nColumn names should be in the keys ifdecimalsis a\ndict-like, or in the index ifdecimalsis a Series. Any\ncolumns not included indecimalswill be left as is. Elements\nofdecimalswhich are not columns of the input will be\nignored.*argsAdditional keywords have no effect but might be accepted for\ncompatibility with numpy.**kwargsAdditional keywords have no effect but might be accepted for\ncompatibility with numpy.Returns:DataFrameA DataFrame with the affected columns rounded to the specified\nnumber of decimal places.See alsonumpy.aroundRound a numpy array to the given number of decimals.Series.roundRound a Series to the given number of decimals.Examples>>>df=pd.DataFrame([(.21,.32),(.01,.67),(.66,.03),(.21,.18)],...columns=['dogs','cats'])>>>dfdogs  cats0  0.21  0.321  0.01  0.672  0.66  0.033  0.21  0.18By providing an integer each column is rounded to the same number\nof decimal places>>>df.round(1)dogs  cats0   0.2   0.31   0.0   0.72   0.7   0.03   0.2   0.2With a dict, the number of places for specific columns can be\nspecified with the column names as key and the number of decimal\nplaces as value>>>df.round({'dogs':1,'cats':0})dogs  cats0   0.2   0.01   0.0   1.02   0.7   0.03   0.2   0.0Using a Series, the number of places for specific columns can be\nspecified with the column names as index and the number of\ndecimal places as value>>>decimals=pd.Series([0,1],index=['cats','dogs'])>>>df.round(decimals)dogs  cats0   0.2   0.01   0.0   1.02   0.7   0.03   0.2   0.0", "doc_id": "84517590-4cdf-4808-9700-a047fe181585", "embedding": null, "doc_hash": "168c4c800776b5ee6f2775b94daf5ea6743fa3763cbfbb22cf3d709eccfb2c75", "extra_info": null, "node_info": {"start": 0, "end": 1902, "_node_type": "1"}, "relationships": {"1": "7f2baa64-60ee-4f3d-8127-7071e6d052d8"}}, "__type__": "1"}, "79302c81-80ed-4555-a1d3-95840467d668": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.pop\u3010Content\u3011pandas.DataFrame.pop#DataFrame.pop(item)[source]#Return item and drop from frame. Raise KeyError if not found.Parameters:itemlabelLabel of column to be popped.Returns:SeriesExamples>>>df=pd.DataFrame([('falcon','bird',389.0),...('parrot','bird',24.0),...('lion','mammal',80.5),...('monkey','mammal',np.nan)],...columns=('name','class','max_speed'))>>>dfname   class  max_speed0  falcon    bird      389.01  parrot    bird       24.02    lion  mammal       80.53  monkey  mammal        NaN>>>df.pop('class')0      bird1      bird2    mammal3    mammalName: class, dtype: object>>>dfname  max_speed0  falcon      389.01  parrot       24.02    lion       80.53  monkey        NaN", "doc_id": "79302c81-80ed-4555-a1d3-95840467d668", "embedding": null, "doc_hash": "7a85856c4694f9a30f669f932751367fffed76de49b095eb932ab133ede962a1", "extra_info": null, "node_info": {"start": 0, "end": 744, "_node_type": "1"}, "relationships": {"1": "52052435-b5de-4911-9462-45e0e2d86663"}}, "__type__": "1"}, "204cea12-d396-4161-9ab5-8b7ec50a0f41": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.dropna\u3010Content\u3011pandas.DataFrame.dropna#DataFrame.dropna(*,axis=0,how=_NoDefault.no_default,thresh=_NoDefault.no_default,subset=None,inplace=False,ignore_index=False)[source]#Remove missing values.See theUser Guidefor more on which values are\nconsidered missing, and how to work with missing data.Parameters:axis{0 or ?eindex?f, 1 or ?ecolumns?f}, default 0Determine if rows or columns which contain missing values are\nremoved.0, or ?eindex?f : Drop rows which contain missing values.1, or ?ecolumns?f : Drop columns which contain missing value.Only a single axis is allowed.how{?eany?f, ?eall?f}, default ?eany?fDetermine if row or column is removed from DataFrame, when we have\nat least one NA or all NA.?eany?f : If any NA values are present, drop that row or column.?eall?f : If all values are NA, drop that row or column.threshint, optionalRequire that many non-NA values. Cannot be combined with how.subsetcolumn label or sequence of labels, optionalLabels along other axis to consider, e.g. if you are dropping rows\nthese would be a list of columns to include.inplacebool, default FalseWhether to modify the DataFrame rather than creating a new one.ignore_indexbool, defaultFalseIfTrue, the resulting axis will be labeled 0, 1, ?c, n - 1.New in version 2.0.0.Returns:DataFrame or NoneDataFrame with NA entries dropped from it or None ifinplace=True.See alsoDataFrame.isnaIndicate missing values.DataFrame.notnaIndicate existing (non-missing) values.DataFrame.fillnaReplace missing values.Series.dropnaDrop missing values.Index.dropnaDrop missing indices.Examples>>>df=pd.DataFrame({\"name\":['Alfred','Batman','Catwoman'],...\"toy\":[np.nan,'Batmobile','Bullwhip'],...\"born\":[pd.NaT,pd.Timestamp(\"1940-04-25\"),...pd.NaT]})>>>dfname        toy       born0    Alfred        NaN        NaT1    Batman  Batmobile 1940-04-252  Catwoman   Bullwhip        NaTDrop the rows where at least one element is missing.>>>df.dropna()name        toy       born1  Batman  Batmobile 1940-04-25Drop the columns where at least one element is missing.>>>df.dropna(axis='columns')name0    Alfred1    Batman2  CatwomanDrop the rows where all elements are missing.>>>df.dropna(how='all')name        toy       born0    Alfred        NaN        NaT1    Batman  Batmobile 1940-04-252  Catwoman   Bullwhip        NaTKeep only the rows with at least 2 non-NA values.>>>df.dropna(thresh=2)name        toy       born1    Batman  Batmobile 1940-04-252  Catwoman   Bullwhip        NaTDefine in which columns to look for missing values.>>>df.dropna(subset=['name','toy'])name        toy       born1    Batman  Batmobile 1940-04-252  Catwoman   Bullwhip        NaT", "doc_id": "204cea12-d396-4161-9ab5-8b7ec50a0f41", "embedding": null, "doc_hash": "909ef097eb71f5408a53cfff3f03d500008e7a999ea984de7809d2f7ae9ba621", "extra_info": null, "node_info": {"start": 0, "end": 2687, "_node_type": "1"}, "relationships": {"1": "bf4d4f5a-7754-4af0-a598-16d38a479263"}}, "__type__": "1"}, "147facc3-24e8-4143-b79f-0596ccbf7e70": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.duplicated\u3010Content\u3011pandas.DataFrame.duplicated#DataFrame.duplicated(subset=None,keep='first')[source]#Return boolean Series denoting duplicate rows.Considering certain columns is optional.Parameters:subsetcolumn label or sequence of labels, optionalOnly consider certain columns for identifying duplicates, by\ndefault use all of the columns.keep{?efirst?f, ?elast?f, False}, default ?efirst?fDetermines which duplicates (if any) to mark.first: Mark duplicates asTrueexcept for the first occurrence.last: Mark duplicates asTrueexcept for the last occurrence.False : Mark all duplicates asTrue.Returns:SeriesBoolean series for each duplicated rows.See alsoIndex.duplicatedEquivalent method on index.Series.duplicatedEquivalent method on Series.Series.drop_duplicatesRemove duplicate values from Series.DataFrame.drop_duplicatesRemove duplicate values from DataFrame.ExamplesConsider dataset containing ramen rating.>>>df=pd.DataFrame({...'brand':['Yum Yum','Yum Yum','Indomie','Indomie','Indomie'],...'style':['cup','cup','cup','pack','pack'],...'rating':[4,4,3.5,15,5]...})>>>dfbrand style  rating0  Yum Yum   cup     4.01  Yum Yum   cup     4.02  Indomie   cup     3.53  Indomie  pack    15.04  Indomie  pack     5.0By default, for each set of duplicated values, the first occurrence\nis set on False and all others on True.>>>df.duplicated()0    False1     True2    False3    False4    Falsedtype: boolBy using ?elast?f, the last occurrence of each set of duplicated values\nis set on False and all others on True.>>>df.duplicated(keep='last')0     True1    False2    False3    False4    Falsedtype: boolBy settingkeepon False, all duplicates are True.>>>df.duplicated(keep=False)0     True1     True2    False3    False4    Falsedtype: boolTo find duplicates on specific column(s), usesubset.>>>df.duplicated(subset=['brand'])0    False1     True2    False3     True4     Truedtype: bool", "doc_id": "147facc3-24e8-4143-b79f-0596ccbf7e70", "embedding": null, "doc_hash": "48d87fa631c492536142df149c45d6918ef05ee7776e4a772005ac475ca0c2b0", "extra_info": null, "node_info": {"start": 0, "end": 1943, "_node_type": "1"}, "relationships": {"1": "9bf200ed-1e6f-4bd1-b685-3bbfa09b3931"}}, "__type__": "1"}, "57003b76-e2cf-4136-912c-804a970d6483": {"__data__": {"text": "\u3010Name\u3011Pandas\u3010Chapter\u3011DataFrame\u3010Section\u3011pandas.DataFrame.equals\u3010Content\u3011pandas.DataFrame.equals#DataFrame.equals(other)[source]#Test whether two objects contain the same elements.This function allows two Series or DataFrames to be compared against\neach other to see if they have the same shape and elements. NaNs in\nthe same location are considered equal.The row/column index do not need to have the same type, as long\nas the values are considered equal. Corresponding columns must be of\nthe same dtype.Parameters:otherSeries or DataFrameThe other Series or DataFrame to be compared with the first.Returns:boolTrue if all elements are the same in both objects, False\notherwise.See alsoSeries.eqCompare two Series objects of the same length and return a Series where each element is True if the element in each Series is equal, False otherwise.DataFrame.eqCompare two DataFrame objects of the same shape and return a DataFrame where each element is True if the respective element in each DataFrame is equal, False otherwise.testing.assert_series_equalRaises an AssertionError if left and right are not equal. Provides an easy interface to ignore inequality in dtypes, indexes and precision among others.testing.assert_frame_equalLike assert_series_equal, but targets DataFrames.numpy.array_equalReturn True if two arrays have the same shape and elements, False otherwise.Examples>>>df=pd.DataFrame({1:[10],2:[20]})>>>df1   20  10  20DataFrames df and exactly_equal have the same types and values for\ntheir elements and column labels, which will return True.>>>exactly_equal=pd.DataFrame({1:[10],2:[20]})>>>exactly_equal1   20  10  20>>>df.equals(exactly_equal)TrueDataFrames df and different_column_type have the same element\ntypes and values, but have different types for the column labels,\nwhich will still return True.>>>different_column_type=pd.DataFrame({1.0:[10],2.0:[20]})>>>different_column_type1.0  2.00   10   20>>>df.equals(different_column_type)TrueDataFrames df and different_data_type have different types for the\nsame values for their elements, and will return False even though\ntheir column labels are the same values and types.>>>different_data_type=pd.DataFrame({1:[10.0],2:[20.0]})>>>different_data_type1     20  10.0  20.0>>>df.equals(different_data_type)False", "doc_id": "57003b76-e2cf-4136-912c-804a970d6483", "embedding": null, "doc_hash": "8e367a7f53ff193fccbe4224b3cb646ac36bad597088ca0f4cbdd70a995867d3", "extra_info": null, "node_info": {"start": 0, "end": 2278, "_node_type": "1"}, "relationships": {"1": "3ce0f070-e518-4da5-95cf-f5cc68136f9b"}}, "__type__": "1"}}}